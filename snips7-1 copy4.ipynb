{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        cnn_out=self.fc1(pooled)\n",
    " \n",
    "        cnn_out = self.dropout(cnn_out)\n",
    "        out=self.fc(cnn_out) \n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "'''定义Bert生成模型。通过在一个OOD数据集训练让其输入噪声后可以输出在该OOD上的词汇集'''\n",
    "class Bert_Gen(nn.Module):  #Bert生成模型\n",
    "    def __init__(self, Bert_config): #tokens_len表示生成数据的长度,即最后bert要生成这么长的文本\n",
    "        super(Bert_Gen,self).__init__()\n",
    "        self.device = Bert_config.device\n",
    "        self.fc1 = nn.Linear(1, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 30522)\n",
    "        \n",
    "        self.bert1=BertModel.from_pretrained(Bert_config.bertmini_path)  #从路径加载预训练模型\n",
    "        for param in self.bert1.parameters():\n",
    "            param.requires_grad = True # 使参数可更新\n",
    "        \n",
    "        self.fc3= nn.Linear(Bert_config.hidden_size, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 30522)\n",
    "    \n",
    "    def forward(self, z): #tokens表示dataloader中的一个batch的tokens，即去掉label部分的token tensor\n",
    "        \n",
    "        out=self.fc1(z*0.01) \n",
    "        out = F.gumbel_softmax(out, 10, False)\n",
    "        out = torch.argmax(out, dim=1, keepdim=False).long()#将经过线性层将正态分布z变为long型整数输入到bert\n",
    "        \n",
    "        out, pool = self.bert1(out.view(1,-1), output_all_encoded_layers=False) #得到每个token的向量表示\n",
    "        \n",
    "        out = self.fc3(out.squeeze())  \n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)  #经过线性层处理生成新的向量，和bert词表大小相同\n",
    "        out = F.gumbel_softmax(out, 10, True)\n",
    "        \n",
    "        return out  #输出一个batch的softmax [batch_size, 类别的softmax得分]\n",
    "\n",
    "\n",
    "'''用于生成DI数据印象的模型'''\n",
    "class DI_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super(DI_Gen_model,self).__init__()\n",
    "        \n",
    "        self.bert_gen = torch.load('./model/bert_genMINI3')\n",
    "        for param in self.bert_gen.parameters():    \n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.bert_cnn = teacher_model\n",
    "        for param in self.bert_cnn.parameters():    \n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, z):\n",
    "        \n",
    "        \n",
    "        tokens = self.bert_gen(z)\n",
    "        tokens = torch.argmax(tokens, dim=1, keepdim=False).long().view(1,-1)\n",
    "        \n",
    "        tokens = tokens.squeeze().tolist()\n",
    "        tokens.append(102)#添加sep符号\n",
    "        tokens.insert(0, 101) #添加cls符号\n",
    "        tokens = torch.tensor(tokens).view(1,-1).to('cuda:1')  #感觉加了之后要好一些\n",
    "        \n",
    "        self.bert_cnn.eval()\n",
    "        out = self.bert_cnn(tokens) #输入(batch_size=1, token_len)的tokens, 输出(batch_size=1, num_classes)的out\n",
    "        \n",
    "        return out, tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        #self.fc1 = nn.Linear(256,128)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        cnn_out=self.fc(pooled)\n",
    "        cnn_out = self.dropout(cnn_out)\n",
    "        #cnn_out = self.fc(cnn_out)\n",
    "        \n",
    "        return cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:56<00:00, 101.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9779411764705882, 0.9909620098039216, 0.9944087009803921, 0.9949448529411765, 0.9964767156862745, 0.9977787990196079, 0.9990808823529411, 0.9988511029411765, 0.9994638480392157, 0.9996170343137255]\n",
      "验证集最终精度0.984375\n",
      "测试集最终精度0.9734375\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train().my_train(teacher_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(teacher_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(teacher_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:53<00:00, 17.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9217218137254902, 0.9650735294117647, 0.9728094362745098, 0.9789368872549019, 0.9826133578431373, 0.9865962009803921, 0.9888939950980392, 0.9899662990196079, 0.9915747549019608, 0.9915747549019608]\n",
      "验证集最终精度0.9859375\n",
      "测试集最终精度0.9796875\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train().my_train(student_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model.fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:42<00:00, 612.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15774\n"
     ]
    }
   ],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')\n",
    "\n",
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)\n",
    "\n",
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练DI生成模型'''\n",
    "def train_DI_gen(dir_samples, ood_data, DI_gen, optimizer, loss_func, loss_func2, label, temper=10, error=1.2, max_iter=True):\n",
    "    device = 'cuda:1'\n",
    "    DI_gen = DI_gen.to(device)\n",
    "    loss_num=999\n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "    DI_gen.train()\n",
    "    for i in range(len(dir_samples)):\n",
    "        count = 0\n",
    "        ood_data = ood_data.view(-1,1).to(device)\n",
    "        #z = torch.randn(30,1).to(device)\n",
    "        tokens_gens=torch.tensor([]).to(device) #选择最小损失的tokens\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            label = label.to(device).long()\n",
    "            dir_sample = dir_samples[i].to(device).view(1,-1)\n",
    "            \n",
    "            probs, tokens_gen = DI_gen(ood_data)\n",
    "            \n",
    "            #loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample)\n",
    "            #loss = 0.6*loss_func2(probs, label)\n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample) + 0.6*loss_func2(probs, label) #如果不加后面的硬性指标会使得预测的标签混乱\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokens_gens = torch.cat([tokens_gens, tokens_gen], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中bert_cnn的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "    if max_iter == True and len(tokens_gens) > 0:\n",
    "        tokens_gen = tokens_gens[torch.argmin(losses).item()]  #选择loss最小的\n",
    "            \n",
    "    return tokens_gen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义理想情况，DI数据应该对应的真实标签'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_labels = torch.tensor([])\n",
    "for i in range(len(train_original_labels)):\n",
    "    for k in [1,5]:\n",
    "        for j in range(int(DI_num/len(train_original_labels)/2)):\n",
    "            DI_labels = torch.cat([DI_labels, torch.tensor([i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1126 [00:00<?, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 1126/1126 [2:09:35<00:00,  6.91s/it] \n",
      "100%|██████████| 1126/1126 [2:01:02<00:00,  6.45s/it] \n",
      "100%|██████████| 1126/1126 [12:40<00:00,  1.48it/s]\n",
      "100%|██████████| 1126/1126 [11:50<00:00,  1.59it/s]\n",
      "100%|██████████| 1126/1126 [2:27:04<00:00,  7.84s/it] \n",
      "100%|██████████| 1126/1126 [2:26:35<00:00,  7.81s/it] \n",
      "100%|██████████| 1126/1126 [16:18<00:00,  1.15it/s]\n",
      "100%|██████████| 1126/1126 [15:31<00:00,  1.21it/s]\n",
      "100%|██████████| 1126/1126 [1:31:34<00:00,  4.88s/it]\n",
      "100%|██████████| 1126/1126 [1:28:59<00:00,  4.74s/it]\n",
      "100%|██████████| 1126/1126 [08:19<00:00,  2.25it/s]\n",
      "100%|██████████| 1126/1126 [08:25<00:00,  2.23it/s]\n",
      "100%|██████████| 1126/1126 [04:08<00:00,  4.53it/s]\n",
      "100%|██████████| 1126/1126 [04:09<00:00,  4.50it/s]\n"
     ]
    }
   ],
   "source": [
    "'''定义DI的生成模型，以及损失函数和优化器'''\n",
    "DI_gen = DI_Gen_model(teacher_model)\n",
    "loss_func = nn.KLDivLoss(reduction = 'mean')\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "\n",
    "'''生成训练集的DI'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_datas = torch.tensor([])\n",
    "ood_idx = 0\n",
    "for i in range(len(train_original_labels)):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [0.5,0.8]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in tqdm(range(int(DI_num/len(train_original_labels)/2))):\n",
    "            x = m.sample().view(1,-1)\n",
    "            \n",
    "            DI_gen = DI_Gen_model(teacher_model)\n",
    "            optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "            \n",
    "            tokens = train_DI_gen(x, torch.tensor(ood_datas[ood_idx]), DI_gen, optimizer, loss_func, loss_func2, torch.tensor([i]))\n",
    "            ood_idx += 1\n",
    "            \n",
    "            tokens = tokens.squeeze().tolist()\n",
    "            while len(tokens)<100:\n",
    "                tokens.append(0)  #padding到100\n",
    "        \n",
    "            tokens = torch.tensor(tokens)\n",
    "            DI_datas = torch.cat([DI_datas, tokens.to('cpu').view(1,-1)], dim=0)\n",
    "            \n",
    "            '''\n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(tokens.to('cuda:1').long().view(1,-1))\n",
    "                print('当前bert_cnn对本token的预测情况'+str(torch.argmax(F.softmax(out), dim=1)))\n",
    "            \n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(DI_datas.to('cuda:1').long())\n",
    "                print(torch.argmax(F.softmax(out), dim=1))\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '##wing', 'neared', '##bry', 'iata', 'ft', 'indus', 'cardiff', 'carefully', '[unused265]', 'accompanying', '##nse', 'mixer', 'hereditary', 'hear', 'teaser', 'lil', 'crowns', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 181, 1: 856, 2: 274, 3: 1814, 4: 105, 5: 4267, 6: 8267}\n"
     ]
    }
   ],
   "source": [
    "'''随机测试DI对应的英文'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "text = tokenizer.convert_ids_to_tokens(DI_datas[10].tolist())\n",
    "print(text)\n",
    "\n",
    "DI_datasets = TensorDataset(DI_datas.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "'''观察生成DI数据的预测标签特性'''\n",
    "teacher_model.eval()\n",
    "teacher_model = teacher_model.to('cuda:1')\n",
    "DI_pred_labels = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(DI_datasets):\n",
    "        out = teacher_model(data[0].to('cuda:1').long())\n",
    "        DI_pred = torch.argmax(F.softmax(out), dim=1) #DI数据输入到bert_cnn中对应的标签\n",
    "        DI_pred_labels = torch.cat([DI_pred_labels, DI_pred.to('cpu')])\n",
    "\n",
    "DI_pred_dict = {} #记录DI预测的不同种类标签个数\n",
    "for i in range(len(train_original_labels)):\n",
    "    DI_pred_dict[i] = 0\n",
    "for i in range(len(DI_pred_labels)):\n",
    "    DI_pred_dict[DI_pred_labels[i].item()] += 1 \n",
    "print(DI_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''将DI文件装入Dataloader中'''\n",
    "DI_datasets = TensorDataset(DI_datas.long(), DI_pred_labels.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        x = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 2, 6, 1, 2, 3, 6, 6, 4, 4, 1, 4, 6, 6,\n",
      "        2, 6, 6, 6, 6, 5, 6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 4,\n",
      "        1, 6, 1, 1, 1, 4, 1, 6, 6, 1, 2, 6, 1, 6, 1, 1, 1, 0, 2, 1, 3, 1, 3, 6,\n",
      "        1, 6, 6, 6, 1, 6, 6, 4, 1, 1, 3, 4, 1, 3, 2, 1, 4, 2, 6, 6, 4, 6, 2, 6,\n",
      "        6, 6, 6, 0, 6, 1, 1, 1, 6, 1, 1, 1, 6, 6, 4, 6, 6, 6, 6, 1, 1, 1, 2, 0,\n",
      "        6, 6, 6, 6, 1, 6, 2, 6], device='cuda:1')\n",
      "tensor([[0.0553, 0.2640, 0.0895, 0.0497, 0.0754, 0.0230, 0.4431],\n",
      "        [0.1599, 0.1461, 0.0306, 0.1152, 0.0254, 0.0352, 0.4877],\n",
      "        [0.0594, 0.1260, 0.1983, 0.1856, 0.0251, 0.0205, 0.3851],\n",
      "        [0.0537, 0.1401, 0.0985, 0.0327, 0.0534, 0.0140, 0.6075],\n",
      "        [0.0357, 0.0611, 0.4207, 0.0579, 0.0229, 0.2111, 0.1905],\n",
      "        [0.0332, 0.2140, 0.0598, 0.0249, 0.0405, 0.0577, 0.5699],\n",
      "        [0.0302, 0.2355, 0.0545, 0.0243, 0.0295, 0.0160, 0.6100],\n",
      "        [0.0404, 0.0354, 0.0514, 0.0427, 0.0263, 0.0190, 0.7848],\n",
      "        [0.0908, 0.2683, 0.0563, 0.0904, 0.1516, 0.0178, 0.3249],\n",
      "        [0.1954, 0.1035, 0.0226, 0.0265, 0.0446, 0.0280, 0.5795],\n",
      "        [0.0619, 0.1419, 0.0550, 0.0605, 0.0449, 0.0165, 0.6193],\n",
      "        [0.0273, 0.0656, 0.4768, 0.0801, 0.1091, 0.0246, 0.2165],\n",
      "        [0.0423, 0.1532, 0.1033, 0.0937, 0.1184, 0.0189, 0.4703],\n",
      "        [0.0338, 0.3470, 0.2553, 0.0795, 0.0532, 0.0192, 0.2120],\n",
      "        [0.0404, 0.1163, 0.4409, 0.1465, 0.0707, 0.0247, 0.1606],\n",
      "        [0.0288, 0.0651, 0.2719, 0.2898, 0.0389, 0.0190, 0.2865],\n",
      "        [0.0547, 0.2163, 0.0601, 0.0445, 0.0352, 0.0192, 0.5699],\n",
      "        [0.0327, 0.0446, 0.0640, 0.0796, 0.0264, 0.0214, 0.7313],\n",
      "        [0.0293, 0.1355, 0.0544, 0.2636, 0.3315, 0.1066, 0.0791],\n",
      "        [0.0190, 0.1781, 0.0761, 0.1514, 0.2539, 0.0760, 0.2455],\n",
      "        [0.0470, 0.6431, 0.0689, 0.0477, 0.0407, 0.0253, 0.1273],\n",
      "        [0.0773, 0.2268, 0.0805, 0.0733, 0.2793, 0.0631, 0.1996],\n",
      "        [0.0161, 0.0618, 0.0365, 0.1034, 0.0218, 0.0146, 0.7459],\n",
      "        [0.0288, 0.0581, 0.0692, 0.1204, 0.0537, 0.0346, 0.6351],\n",
      "        [0.0157, 0.0807, 0.7051, 0.0406, 0.0234, 0.0243, 0.1102],\n",
      "        [0.0233, 0.1091, 0.2227, 0.0308, 0.0275, 0.0372, 0.5493],\n",
      "        [0.0644, 0.0871, 0.0765, 0.2592, 0.1555, 0.0168, 0.3405],\n",
      "        [0.0186, 0.0303, 0.0556, 0.0305, 0.0401, 0.0793, 0.7456],\n",
      "        [0.0403, 0.0453, 0.1083, 0.0504, 0.0847, 0.0509, 0.6202],\n",
      "        [0.0510, 0.0626, 0.1612, 0.0578, 0.1231, 0.2905, 0.2539],\n",
      "        [0.0259, 0.1450, 0.0506, 0.0611, 0.0242, 0.0134, 0.6798],\n",
      "        [0.0474, 0.4437, 0.0525, 0.0325, 0.0677, 0.0201, 0.3360],\n",
      "        [0.0445, 0.0618, 0.0539, 0.0408, 0.0396, 0.0233, 0.7362],\n",
      "        [0.0335, 0.1595, 0.0571, 0.0359, 0.0322, 0.0197, 0.6621],\n",
      "        [0.0676, 0.5600, 0.0564, 0.0246, 0.0420, 0.0150, 0.2344],\n",
      "        [0.0255, 0.3817, 0.1996, 0.0256, 0.0982, 0.0277, 0.2417],\n",
      "        [0.0421, 0.2877, 0.0564, 0.0418, 0.0652, 0.0167, 0.4901],\n",
      "        [0.0440, 0.2027, 0.1646, 0.0718, 0.0243, 0.0139, 0.4787],\n",
      "        [0.0282, 0.1048, 0.1374, 0.0840, 0.1152, 0.0585, 0.4719],\n",
      "        [0.1171, 0.3793, 0.0394, 0.0305, 0.1264, 0.0174, 0.2900],\n",
      "        [0.1938, 0.4902, 0.0316, 0.0304, 0.0760, 0.0230, 0.1550],\n",
      "        [0.0348, 0.0785, 0.0290, 0.0428, 0.0212, 0.0153, 0.7783],\n",
      "        [0.0804, 0.0985, 0.0278, 0.0374, 0.0314, 0.0233, 0.7013],\n",
      "        [0.0275, 0.1214, 0.0478, 0.0194, 0.0187, 0.0116, 0.7536],\n",
      "        [0.0494, 0.1353, 0.0783, 0.1085, 0.0347, 0.0171, 0.5768],\n",
      "        [0.0363, 0.1159, 0.1245, 0.2074, 0.0389, 0.0123, 0.4647],\n",
      "        [0.0649, 0.3013, 0.2325, 0.0649, 0.0670, 0.0317, 0.2377],\n",
      "        [0.0257, 0.0382, 0.0727, 0.2505, 0.4109, 0.0604, 0.1416],\n",
      "        [0.0712, 0.4357, 0.0786, 0.0756, 0.1056, 0.0156, 0.2177],\n",
      "        [0.0220, 0.1418, 0.1078, 0.1424, 0.0372, 0.0178, 0.5309],\n",
      "        [0.0631, 0.5075, 0.0580, 0.0329, 0.0478, 0.0149, 0.2758],\n",
      "        [0.2143, 0.3118, 0.1879, 0.0511, 0.0861, 0.0234, 0.1254],\n",
      "        [0.0354, 0.5002, 0.1093, 0.0399, 0.0340, 0.0312, 0.2501],\n",
      "        [0.0350, 0.0676, 0.0323, 0.1040, 0.6564, 0.0262, 0.0785],\n",
      "        [0.0855, 0.3971, 0.0736, 0.0496, 0.0619, 0.0150, 0.3174],\n",
      "        [0.0724, 0.2577, 0.0501, 0.0222, 0.0260, 0.0138, 0.5578],\n",
      "        [0.0988, 0.0790, 0.0373, 0.1292, 0.0325, 0.0189, 0.6042],\n",
      "        [0.0381, 0.7322, 0.0308, 0.0239, 0.0557, 0.0370, 0.0823],\n",
      "        [0.0313, 0.0830, 0.6817, 0.0421, 0.0793, 0.0286, 0.0540],\n",
      "        [0.0768, 0.1522, 0.0504, 0.1256, 0.0319, 0.0168, 0.5463],\n",
      "        [0.1148, 0.3277, 0.1532, 0.0404, 0.1163, 0.0212, 0.2266],\n",
      "        [0.1048, 0.1606, 0.1742, 0.1596, 0.0210, 0.0187, 0.3611],\n",
      "        [0.0997, 0.4019, 0.0547, 0.0353, 0.0735, 0.0192, 0.3158],\n",
      "        [0.0884, 0.4467, 0.0520, 0.1007, 0.0723, 0.0202, 0.2197],\n",
      "        [0.0546, 0.4437, 0.1461, 0.0517, 0.1640, 0.0361, 0.1036],\n",
      "        [0.7906, 0.0290, 0.0241, 0.0174, 0.0249, 0.0136, 0.1005],\n",
      "        [0.0110, 0.0260, 0.8538, 0.0560, 0.0195, 0.0137, 0.0200],\n",
      "        [0.1413, 0.3809, 0.0451, 0.0604, 0.1526, 0.0257, 0.1939],\n",
      "        [0.0303, 0.0534, 0.0546, 0.6326, 0.0926, 0.0217, 0.1148],\n",
      "        [0.0572, 0.6480, 0.0640, 0.0392, 0.0353, 0.0140, 0.1423],\n",
      "        [0.0303, 0.0665, 0.1312, 0.3375, 0.0469, 0.0683, 0.3193],\n",
      "        [0.0846, 0.2729, 0.1649, 0.0578, 0.0780, 0.0328, 0.3090],\n",
      "        [0.0711, 0.4323, 0.1177, 0.0598, 0.0334, 0.0125, 0.2731],\n",
      "        [0.0568, 0.2892, 0.1457, 0.0572, 0.0860, 0.0714, 0.2937],\n",
      "        [0.0226, 0.0261, 0.0314, 0.0264, 0.0136, 0.0172, 0.8627],\n",
      "        [0.0461, 0.0945, 0.2141, 0.2645, 0.0352, 0.0289, 0.3167],\n",
      "        [0.0514, 0.5085, 0.0599, 0.0624, 0.0347, 0.0244, 0.2586],\n",
      "        [0.0185, 0.0774, 0.0777, 0.0654, 0.0216, 0.0129, 0.7266],\n",
      "        [0.0971, 0.2004, 0.1155, 0.0604, 0.0898, 0.0228, 0.4140],\n",
      "        [0.0769, 0.1347, 0.0811, 0.1470, 0.2811, 0.0212, 0.2581],\n",
      "        [0.0454, 0.8175, 0.0171, 0.0260, 0.0201, 0.0132, 0.0607],\n",
      "        [0.0469, 0.6458, 0.0346, 0.0287, 0.0305, 0.0167, 0.1968],\n",
      "        [0.0404, 0.0290, 0.0760, 0.7675, 0.0180, 0.0140, 0.0550],\n",
      "        [0.0616, 0.1085, 0.0663, 0.0596, 0.4366, 0.0893, 0.1781],\n",
      "        [0.1489, 0.4555, 0.0692, 0.0277, 0.0515, 0.0145, 0.2328],\n",
      "        [0.0573, 0.1150, 0.2403, 0.3465, 0.0625, 0.0166, 0.1618],\n",
      "        [0.0262, 0.0906, 0.4527, 0.0461, 0.0327, 0.0442, 0.3076],\n",
      "        [0.0980, 0.5083, 0.1023, 0.0782, 0.0406, 0.0132, 0.1596],\n",
      "        [0.0217, 0.0353, 0.2849, 0.0618, 0.5315, 0.0509, 0.0139],\n",
      "        [0.0323, 0.1154, 0.4610, 0.1380, 0.0834, 0.0782, 0.0918],\n",
      "        [0.0398, 0.2426, 0.0378, 0.0267, 0.0293, 0.0207, 0.6031],\n",
      "        [0.0389, 0.1563, 0.0739, 0.0958, 0.0340, 0.0352, 0.5660],\n",
      "        [0.0443, 0.1089, 0.0875, 0.0182, 0.4266, 0.0489, 0.2655],\n",
      "        [0.0365, 0.0697, 0.0550, 0.0427, 0.0344, 0.0141, 0.7475],\n",
      "        [0.0400, 0.0535, 0.2558, 0.1674, 0.0753, 0.1661, 0.2419],\n",
      "        [0.0875, 0.1922, 0.1730, 0.1545, 0.0491, 0.0113, 0.3323],\n",
      "        [0.0801, 0.2840, 0.0773, 0.0655, 0.1129, 0.0213, 0.3589],\n",
      "        [0.0225, 0.0957, 0.2663, 0.0423, 0.0572, 0.0250, 0.4911],\n",
      "        [0.0506, 0.2591, 0.1437, 0.1066, 0.0534, 0.0240, 0.3626],\n",
      "        [0.7837, 0.0273, 0.0197, 0.0195, 0.0254, 0.0132, 0.1113],\n",
      "        [0.0318, 0.1520, 0.1075, 0.0629, 0.0341, 0.0219, 0.5898],\n",
      "        [0.2284, 0.4408, 0.0464, 0.0525, 0.0527, 0.0206, 0.1585],\n",
      "        [0.0529, 0.3366, 0.0357, 0.1230, 0.2376, 0.0427, 0.1714],\n",
      "        [0.1257, 0.3046, 0.1294, 0.1066, 0.0611, 0.0146, 0.2580],\n",
      "        [0.0220, 0.1003, 0.1272, 0.0484, 0.0389, 0.0453, 0.6180],\n",
      "        [0.1226, 0.4055, 0.0483, 0.0186, 0.0576, 0.0149, 0.3326],\n",
      "        [0.0418, 0.3656, 0.0896, 0.0460, 0.0755, 0.0207, 0.3608],\n",
      "        [0.0639, 0.2940, 0.0573, 0.0950, 0.1796, 0.0301, 0.2801],\n",
      "        [0.0168, 0.0246, 0.0265, 0.0584, 0.0155, 0.0147, 0.8436],\n",
      "        [0.0270, 0.0540, 0.0253, 0.0183, 0.0228, 0.0155, 0.8373],\n",
      "        [0.0306, 0.0966, 0.0471, 0.0611, 0.4450, 0.0322, 0.2873],\n",
      "        [0.0344, 0.2051, 0.0354, 0.0745, 0.0588, 0.0245, 0.5673],\n",
      "        [0.0448, 0.2428, 0.1217, 0.0396, 0.0207, 0.0221, 0.5084],\n",
      "        [0.0883, 0.1347, 0.1508, 0.1904, 0.1363, 0.0177, 0.2818],\n",
      "        [0.0489, 0.3021, 0.0902, 0.0883, 0.0264, 0.0216, 0.4226],\n",
      "        [0.0514, 0.2833, 0.2211, 0.0843, 0.0533, 0.0252, 0.2814],\n",
      "        [0.0652, 0.3851, 0.0513, 0.0342, 0.0652, 0.0240, 0.3751],\n",
      "        [0.0985, 0.2978, 0.0722, 0.0923, 0.2049, 0.0564, 0.1779],\n",
      "        [0.0463, 0.1210, 0.5375, 0.0398, 0.0288, 0.0144, 0.2121],\n",
      "        [0.8164, 0.0401, 0.0188, 0.0205, 0.0223, 0.0186, 0.0633],\n",
      "        [0.0325, 0.1091, 0.1351, 0.1956, 0.0320, 0.0654, 0.4303],\n",
      "        [0.0182, 0.0587, 0.0517, 0.0887, 0.0194, 0.0256, 0.7375],\n",
      "        [0.0979, 0.3173, 0.0758, 0.0262, 0.0618, 0.0198, 0.4013],\n",
      "        [0.0329, 0.1667, 0.0198, 0.2299, 0.2266, 0.0281, 0.2960],\n",
      "        [0.0716, 0.4685, 0.0568, 0.0705, 0.1835, 0.0207, 0.1284],\n",
      "        [0.1312, 0.1542, 0.1137, 0.1873, 0.1079, 0.0469, 0.2588],\n",
      "        [0.0460, 0.3322, 0.3630, 0.0295, 0.0469, 0.0534, 0.1290],\n",
      "        [0.0913, 0.3381, 0.0988, 0.0478, 0.0474, 0.0266, 0.3501]],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(F.softmax(test_output, dim=1), dim=1))\n",
    "indexs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "print(F.softmax(test_output, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4431, device='cuda:1')\n",
      "tensor(0.4877, device='cuda:1')\n",
      "tensor(0.3851, device='cuda:1')\n",
      "tensor(0.6075, device='cuda:1')\n",
      "tensor(0.4207, device='cuda:1')\n",
      "tensor(0.5699, device='cuda:1')\n",
      "tensor(0.6100, device='cuda:1')\n",
      "tensor(0.7848, device='cuda:1')\n",
      "tensor(0.3249, device='cuda:1')\n",
      "tensor(0.5795, device='cuda:1')\n",
      "tensor(0.6193, device='cuda:1')\n",
      "tensor(0.4768, device='cuda:1')\n",
      "tensor(0.4703, device='cuda:1')\n",
      "tensor(0.3470, device='cuda:1')\n",
      "tensor(0.4409, device='cuda:1')\n",
      "tensor(0.2898, device='cuda:1')\n",
      "tensor(0.5699, device='cuda:1')\n",
      "tensor(0.7313, device='cuda:1')\n",
      "tensor(0.3315, device='cuda:1')\n",
      "tensor(0.2539, device='cuda:1')\n",
      "tensor(0.6431, device='cuda:1')\n",
      "tensor(0.2793, device='cuda:1')\n",
      "tensor(0.7459, device='cuda:1')\n",
      "tensor(0.6351, device='cuda:1')\n",
      "tensor(0.7051, device='cuda:1')\n",
      "tensor(0.5493, device='cuda:1')\n",
      "tensor(0.3405, device='cuda:1')\n",
      "tensor(0.7456, device='cuda:1')\n",
      "tensor(0.6202, device='cuda:1')\n",
      "tensor(0.2905, device='cuda:1')\n",
      "tensor(0.6798, device='cuda:1')\n",
      "tensor(0.4437, device='cuda:1')\n",
      "tensor(0.7362, device='cuda:1')\n",
      "tensor(0.6621, device='cuda:1')\n",
      "tensor(0.5600, device='cuda:1')\n",
      "tensor(0.3817, device='cuda:1')\n",
      "tensor(0.4901, device='cuda:1')\n",
      "tensor(0.4787, device='cuda:1')\n",
      "tensor(0.4719, device='cuda:1')\n",
      "tensor(0.3793, device='cuda:1')\n",
      "tensor(0.4902, device='cuda:1')\n",
      "tensor(0.7783, device='cuda:1')\n",
      "tensor(0.7013, device='cuda:1')\n",
      "tensor(0.7536, device='cuda:1')\n",
      "tensor(0.5768, device='cuda:1')\n",
      "tensor(0.4647, device='cuda:1')\n",
      "tensor(0.3013, device='cuda:1')\n",
      "tensor(0.4109, device='cuda:1')\n",
      "tensor(0.4357, device='cuda:1')\n",
      "tensor(0.5309, device='cuda:1')\n",
      "tensor(0.5075, device='cuda:1')\n",
      "tensor(0.3118, device='cuda:1')\n",
      "tensor(0.5002, device='cuda:1')\n",
      "tensor(0.6564, device='cuda:1')\n",
      "tensor(0.3971, device='cuda:1')\n",
      "tensor(0.5578, device='cuda:1')\n",
      "tensor(0.6042, device='cuda:1')\n",
      "tensor(0.7322, device='cuda:1')\n",
      "tensor(0.6817, device='cuda:1')\n",
      "tensor(0.5463, device='cuda:1')\n",
      "tensor(0.3277, device='cuda:1')\n",
      "tensor(0.3611, device='cuda:1')\n",
      "tensor(0.4019, device='cuda:1')\n",
      "tensor(0.4467, device='cuda:1')\n",
      "tensor(0.4437, device='cuda:1')\n",
      "tensor(0.7906, device='cuda:1')\n",
      "tensor(0.8538, device='cuda:1')\n",
      "tensor(0.3809, device='cuda:1')\n",
      "tensor(0.6326, device='cuda:1')\n",
      "tensor(0.6480, device='cuda:1')\n",
      "tensor(0.3375, device='cuda:1')\n",
      "tensor(0.3090, device='cuda:1')\n",
      "tensor(0.4323, device='cuda:1')\n",
      "tensor(0.2937, device='cuda:1')\n",
      "tensor(0.8627, device='cuda:1')\n",
      "tensor(0.3167, device='cuda:1')\n",
      "tensor(0.5085, device='cuda:1')\n",
      "tensor(0.7266, device='cuda:1')\n",
      "tensor(0.4140, device='cuda:1')\n",
      "tensor(0.2811, device='cuda:1')\n",
      "tensor(0.8175, device='cuda:1')\n",
      "tensor(0.6458, device='cuda:1')\n",
      "tensor(0.7675, device='cuda:1')\n",
      "tensor(0.4366, device='cuda:1')\n",
      "tensor(0.4555, device='cuda:1')\n",
      "tensor(0.3465, device='cuda:1')\n",
      "tensor(0.4527, device='cuda:1')\n",
      "tensor(0.5083, device='cuda:1')\n",
      "tensor(0.5315, device='cuda:1')\n",
      "tensor(0.4610, device='cuda:1')\n",
      "tensor(0.6031, device='cuda:1')\n",
      "tensor(0.5660, device='cuda:1')\n",
      "tensor(0.4266, device='cuda:1')\n",
      "tensor(0.7475, device='cuda:1')\n",
      "tensor(0.2558, device='cuda:1')\n",
      "tensor(0.3323, device='cuda:1')\n",
      "tensor(0.3589, device='cuda:1')\n",
      "tensor(0.4911, device='cuda:1')\n",
      "tensor(0.3626, device='cuda:1')\n",
      "tensor(0.7837, device='cuda:1')\n",
      "tensor(0.5898, device='cuda:1')\n",
      "tensor(0.4408, device='cuda:1')\n",
      "tensor(0.3366, device='cuda:1')\n",
      "tensor(0.3046, device='cuda:1')\n",
      "tensor(0.6180, device='cuda:1')\n",
      "tensor(0.4055, device='cuda:1')\n",
      "tensor(0.3656, device='cuda:1')\n",
      "tensor(0.2940, device='cuda:1')\n",
      "tensor(0.8436, device='cuda:1')\n",
      "tensor(0.8373, device='cuda:1')\n",
      "tensor(0.4450, device='cuda:1')\n",
      "tensor(0.5673, device='cuda:1')\n",
      "tensor(0.5084, device='cuda:1')\n",
      "tensor(0.2818, device='cuda:1')\n",
      "tensor(0.4226, device='cuda:1')\n",
      "tensor(0.2833, device='cuda:1')\n",
      "tensor(0.3851, device='cuda:1')\n",
      "tensor(0.2978, device='cuda:1')\n",
      "tensor(0.5375, device='cuda:1')\n",
      "tensor(0.8164, device='cuda:1')\n",
      "tensor(0.4303, device='cuda:1')\n",
      "tensor(0.7375, device='cuda:1')\n",
      "tensor(0.4013, device='cuda:1')\n",
      "tensor(0.2960, device='cuda:1')\n",
      "tensor(0.4685, device='cuda:1')\n",
      "tensor(0.2588, device='cuda:1')\n",
      "tensor(0.3630, device='cuda:1')\n",
      "tensor(0.3501, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(indexs)):\n",
    "    print(F.softmax(test_output, dim=1)[i][indexs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "15744\n"
     ]
    }
   ],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    test_num = 0\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        idxs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "        for j in range(len(idxs)):\n",
    "            if F.softmax(test_output, dim=1)[j][idxs[j]] > 0.80:\n",
    "                count+=1\n",
    "            test_num += 1\n",
    "print(count)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:1'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward()  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            print(loss.item())\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.15785845588235295\n",
      "0.146875\n",
      "0.1890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02571248821914196\n",
      "0.01910116709768772\n",
      "0.018585555255413055\n",
      "0.016676798462867737\n",
      "0.015812424942851067\n",
      "0.0162481851875782\n",
      "0.015829753130674362\n",
      "0.016160668805241585\n",
      "0.017536470666527748\n",
      "0.014748819172382355\n",
      "0.0148018728941679\n",
      "0.015269242227077484\n",
      "0.015016848221421242\n",
      "0.014523966237902641\n",
      "0.015858180820941925\n",
      "0.015951400622725487\n",
      "0.016102775931358337\n",
      "0.01661938987672329\n",
      "0.014664294198155403\n",
      "0.01503952406346798\n",
      "0.014029497280716896\n",
      "0.017308970913290977\n",
      "0.014625558629631996\n",
      "0.015420431271195412\n",
      "0.01516978070139885\n",
      "0.015532506629824638\n",
      "0.01561178732663393\n",
      "0.013138297013938427\n",
      "0.014398972503840923\n",
      "0.016364162787795067\n",
      "0.015509906224906445\n",
      "0.016938326880335808\n",
      "0.014288539066910744\n",
      "0.015298273414373398\n",
      "0.015448315069079399\n",
      "0.015274960547685623\n",
      "0.014468126930296421\n",
      "0.01564685069024563\n",
      "0.01577610708773136\n",
      "0.016215994954109192\n",
      "0.01531071588397026\n",
      "0.015447360463440418\n",
      "0.014463823288679123\n",
      "0.015722282230854034\n",
      "0.014824886806309223\n",
      "0.01375756785273552\n",
      "0.014837557449936867\n",
      "0.015196917578577995\n",
      "0.01349675003439188\n",
      "0.014254236593842506\n",
      "0.01405886560678482\n",
      "0.01451476663351059\n",
      "0.015011053532361984\n",
      "0.014468069188296795\n",
      "0.014943272806704044\n",
      "0.013913172297179699\n",
      "0.014750951901078224\n",
      "0.014847706072032452\n",
      "0.015245386399328709\n",
      "0.01600017212331295\n",
      "0.014427083544433117\n",
      "0.015504280105233192\n",
      "0.01650920882821083\n",
      "0.014996523037552834\n",
      "0.015325100161135197\n",
      "0.015459729358553886\n",
      "0.017409397289156914\n",
      "0.016009608283638954\n",
      "0.014978856779634953\n",
      "0.017230136319994926\n",
      "0.01455980259925127\n",
      "0.015905914828181267\n",
      "0.014595536515116692\n",
      "0.014167570509016514\n",
      "0.01598183438181877\n",
      "0.015257035382091999\n",
      "0.01633613556623459\n",
      "0.015510590746998787\n",
      "0.017241083085536957\n",
      "0.015186253003776073\n",
      "0.01576455682516098\n",
      "0.01448038499802351\n",
      "0.015549172647297382\n",
      "0.015065474435687065\n",
      "0.015434195287525654\n",
      "0.015737036243081093\n",
      "0.015920007601380348\n",
      "0.014717343263328075\n",
      "0.016338692978024483\n",
      "0.014584970660507679\n",
      "0.014562350697815418\n",
      "0.015674201771616936\n",
      "0.015436436980962753\n",
      "0.014099771156907082\n",
      "0.014819763600826263\n",
      "0.015604675747454166\n",
      "0.016019290313124657\n",
      "0.01562618464231491\n",
      "0.01602965220808983\n",
      "0.014634857885539532\n",
      "0.014159005135297775\n",
      "0.013945816084742546\n",
      "0.014363748952746391\n",
      "0.014699555933475494\n",
      "0.014287454076111317\n",
      "0.014342774637043476\n",
      "0.01574772037565708\n",
      "0.014458456076681614\n",
      "0.015452787280082703\n",
      "0.014339224435389042\n",
      "0.015716223046183586\n",
      "0.015578377060592175\n",
      "0.014850029721856117\n",
      "0.013860143721103668\n",
      "0.014125656336545944\n",
      "0.014608096331357956\n",
      "0.015008452348411083\n",
      "0.014981679618358612\n",
      "0.01457265391945839\n",
      "0.013931212946772575\n",
      "0.014416293241083622\n",
      "0.014949657954275608\n",
      "0.014881700277328491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [01:41<49:11, 101.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.21576286764705882\n",
      "验证集精度0.2140625\n",
      "测试集精度0.221875\n",
      "0.014216997660696507\n",
      "0.01594926416873932\n",
      "0.014981255866587162\n",
      "0.014498132281005383\n",
      "0.014492022804915905\n",
      "0.01495371200144291\n",
      "0.014104021713137627\n",
      "0.013701241463422775\n",
      "0.012816151604056358\n",
      "0.013382398523390293\n",
      "0.01428559236228466\n",
      "0.013368814252316952\n",
      "0.014364279806613922\n",
      "0.013937268406152725\n",
      "0.014200049452483654\n",
      "0.013363425619900227\n",
      "0.013389921747148037\n",
      "0.014548186212778091\n",
      "0.013250594027340412\n",
      "0.015323543921113014\n",
      "0.01243915967643261\n",
      "0.01414564624428749\n",
      "0.015464527532458305\n",
      "0.013938860036432743\n",
      "0.012417887337505817\n",
      "0.015046665444970131\n",
      "0.013772288337349892\n",
      "0.012721171602606773\n",
      "0.013259081169962883\n",
      "0.013034659437835217\n",
      "0.013174089603126049\n",
      "0.013966151513159275\n",
      "0.013243007473647594\n",
      "0.015291236340999603\n",
      "0.013928729109466076\n",
      "0.013180122710764408\n",
      "0.01392343919724226\n",
      "0.01339713018387556\n",
      "0.01316882949322462\n",
      "0.013620519079267979\n",
      "0.013270925730466843\n",
      "0.012220705859363079\n",
      "0.014177271164953709\n",
      "0.013528556562960148\n",
      "0.014235477894544601\n",
      "0.012714660726487637\n",
      "0.01278564054518938\n",
      "0.014192263595759869\n",
      "0.013366595841944218\n",
      "0.01252832356840372\n",
      "0.01252105925232172\n",
      "0.012514572590589523\n",
      "0.013294273987412453\n",
      "0.012676113285124302\n",
      "0.0124598303809762\n",
      "0.014409122988581657\n",
      "0.012774953618645668\n",
      "0.013301913626492023\n",
      "0.014080528169870377\n",
      "0.013504999689757824\n",
      "0.012932178564369678\n",
      "0.013476185500621796\n",
      "0.012598891742527485\n",
      "0.013121198862791061\n",
      "0.012816132046282291\n",
      "0.012568033300340176\n",
      "0.0149392643943429\n",
      "0.012819242663681507\n",
      "0.01336547639220953\n",
      "0.01408049650490284\n",
      "0.01362713985145092\n",
      "0.011719288304448128\n",
      "0.012255330570042133\n",
      "0.011713836342096329\n",
      "0.01275571994483471\n",
      "0.01297407504171133\n",
      "0.014396424405276775\n",
      "0.01384100690484047\n",
      "0.012119097635149956\n",
      "0.013563977554440498\n",
      "0.012708025053143501\n",
      "0.013271410018205643\n",
      "0.013664968311786652\n",
      "0.013627906329929829\n",
      "0.013409332372248173\n",
      "0.012254016473889351\n",
      "0.01178246084600687\n",
      "0.01166872400790453\n",
      "0.013283045031130314\n",
      "0.013058357872068882\n",
      "0.01210158970206976\n",
      "0.01329280249774456\n",
      "0.013470352627336979\n",
      "0.013089616782963276\n",
      "0.012413891963660717\n",
      "0.01439669355750084\n",
      "0.013161959126591682\n",
      "0.012768748216331005\n",
      "0.012663603760302067\n",
      "0.014514540322124958\n",
      "0.012974758632481098\n",
      "0.014368624426424503\n",
      "0.0131802624091506\n",
      "0.012985157780349255\n",
      "0.013434999622404575\n",
      "0.011930260807275772\n",
      "0.012526515871286392\n",
      "0.013798752799630165\n",
      "0.01220646034926176\n",
      "0.012446210719645023\n",
      "0.01369118969887495\n",
      "0.013185461983084679\n",
      "0.012682403437793255\n",
      "0.01232894603163004\n",
      "0.012788666412234306\n",
      "0.013527204282581806\n",
      "0.013362337835133076\n",
      "0.011170726269483566\n",
      "0.012477553449571133\n",
      "0.013885659165680408\n",
      "0.012638905085623264\n",
      "0.011852861382067204\n",
      "0.01350330375134945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [04:05<59:04, 126.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.48651960784313725\n",
      "验证集精度0.5203125\n",
      "测试集精度0.490625\n",
      "0.012078351341187954\n",
      "0.013045265339314938\n",
      "0.012573414482176304\n",
      "0.013343824073672295\n",
      "0.01142587885260582\n",
      "0.013338396325707436\n",
      "0.01325952634215355\n",
      "0.013215754181146622\n",
      "0.0129786292091012\n",
      "0.011795801110565662\n",
      "0.01322492677718401\n",
      "0.011861169710755348\n",
      "0.013196561485528946\n",
      "0.012516746297478676\n",
      "0.012341323308646679\n",
      "0.012431592680513859\n",
      "0.013149772770702839\n",
      "0.01165821123868227\n",
      "0.012027299031615257\n",
      "0.0107567198574543\n",
      "0.011851919814944267\n",
      "0.011907086707651615\n",
      "0.013070636428892612\n",
      "0.01313210092484951\n",
      "0.01297077164053917\n",
      "0.012968268245458603\n",
      "0.013207504525780678\n",
      "0.011919003911316395\n",
      "0.012753043323755264\n",
      "0.012346772477030754\n",
      "0.011679518967866898\n",
      "0.01200845930725336\n",
      "0.01234533078968525\n",
      "0.011831509880721569\n",
      "0.011535423807799816\n",
      "0.010767376981675625\n",
      "0.011872961185872555\n",
      "0.013254634104669094\n",
      "0.012320431880652905\n",
      "0.011646530590951443\n",
      "0.011797952465713024\n",
      "0.012202653102576733\n",
      "0.012536836788058281\n",
      "0.012611777521669865\n",
      "0.013112564571201801\n",
      "0.01282459031790495\n",
      "0.012784627266228199\n",
      "0.011936899274587631\n",
      "0.012016082182526588\n",
      "0.014380288310348988\n",
      "0.01190111692994833\n",
      "0.012491447851061821\n",
      "0.011364315636456013\n",
      "0.012624644674360752\n",
      "0.011481666937470436\n",
      "0.011929979547858238\n",
      "0.011795342899858952\n",
      "0.012350659817457199\n",
      "0.012052221223711967\n",
      "0.011483458802103996\n",
      "0.01159159280359745\n",
      "0.011893502436578274\n",
      "0.012717031873762608\n",
      "0.01102791540324688\n",
      "0.012893566861748695\n",
      "0.011318271979689598\n",
      "0.012848252430558205\n",
      "0.013136709108948708\n",
      "0.012360888533294201\n",
      "0.012330329045653343\n",
      "0.011939571239054203\n",
      "0.01183632854372263\n",
      "0.012632532976567745\n",
      "0.01346396654844284\n",
      "0.012402909807860851\n",
      "0.013843083754181862\n",
      "0.011602971702814102\n",
      "0.011825726367533207\n",
      "0.011870929971337318\n",
      "0.012230821885168552\n",
      "0.011529292911291122\n",
      "0.011271973140537739\n",
      "0.011191152967512608\n",
      "0.012114952318370342\n",
      "0.01369935367256403\n",
      "0.012304481118917465\n",
      "0.012220142409205437\n",
      "0.013314158655703068\n",
      "0.012728776782751083\n",
      "0.012146593071520329\n",
      "0.01217427384108305\n",
      "0.010836978442966938\n",
      "0.013354392722249031\n",
      "0.01150608342140913\n",
      "0.012908714823424816\n",
      "0.013216112740337849\n",
      "0.013482045382261276\n",
      "0.01174416858702898\n",
      "0.011282057501375675\n",
      "0.0123662780970335\n",
      "0.011843424290418625\n",
      "0.01194398757070303\n",
      "0.012644132599234581\n",
      "0.01208339910954237\n",
      "0.012061557732522488\n",
      "0.013136335648596287\n",
      "0.013313357718288898\n",
      "0.012111193500459194\n",
      "0.011673842556774616\n",
      "0.012638390995562077\n",
      "0.012981155887246132\n",
      "0.011081820353865623\n",
      "0.012604305520653725\n",
      "0.012250752188265324\n",
      "0.011131862178444862\n",
      "0.012624063529074192\n",
      "0.01077322382479906\n",
      "0.013239753432571888\n",
      "0.012914781458675861\n",
      "0.011721525341272354\n",
      "0.010323437862098217\n",
      "0.012923379428684711\n",
      "0.012284379452466965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [06:21<58:52, 130.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7090992647058824\n",
      "验证集精度0.7140625\n",
      "测试集精度0.6953125\n",
      "0.01083403266966343\n",
      "0.011008286848664284\n",
      "0.012614638544619083\n",
      "0.011927071027457714\n",
      "0.012449598871171474\n",
      "0.011916467919945717\n",
      "0.01125070359557867\n",
      "0.01227556262165308\n",
      "0.011765901930630207\n",
      "0.012021590024232864\n",
      "0.010979963466525078\n",
      "0.010870346799492836\n",
      "0.011349129490554333\n",
      "0.01048305444419384\n",
      "0.01137826032936573\n",
      "0.013507585972547531\n",
      "0.01217105332762003\n",
      "0.011361303739249706\n",
      "0.011926984414458275\n",
      "0.010874231345951557\n",
      "0.012158219702541828\n",
      "0.012849061749875546\n",
      "0.012972978875041008\n",
      "0.011721504852175713\n",
      "0.010829772800207138\n",
      "0.011633319780230522\n",
      "0.012005343101918697\n",
      "0.012372879311442375\n",
      "0.01169623527675867\n",
      "0.01135179027915001\n",
      "0.011400512419641018\n",
      "0.00999376643449068\n",
      "0.011469509452581406\n",
      "0.011762739159166813\n",
      "0.011494269594550133\n",
      "0.012290740385651588\n",
      "0.010793598368763924\n",
      "0.011391597799956799\n",
      "0.011923292651772499\n",
      "0.012226875871419907\n",
      "0.011655236594378948\n",
      "0.011087807826697826\n",
      "0.011682369746267796\n",
      "0.01257597841322422\n",
      "0.011963955126702785\n",
      "0.01103852316737175\n",
      "0.011935417540371418\n",
      "0.01256444863975048\n",
      "0.012469006702303886\n",
      "0.011504444293677807\n",
      "0.012090287171304226\n",
      "0.012576461769640446\n",
      "0.011172785423696041\n",
      "0.012817776761949062\n",
      "0.013075793161988258\n",
      "0.010634045116603374\n",
      "0.012180374003946781\n",
      "0.012202870100736618\n",
      "0.011304977349936962\n",
      "0.011656356044113636\n",
      "0.012438020668923855\n",
      "0.010691911913454533\n",
      "0.011755920015275478\n",
      "0.011522331275045872\n",
      "0.012207930907607079\n",
      "0.012242521159350872\n",
      "0.012679838575422764\n",
      "0.011420054361224174\n",
      "0.010212844237685204\n",
      "0.011340106837451458\n",
      "0.010989661328494549\n",
      "0.010487920604646206\n",
      "0.012164472602307796\n",
      "0.01210845448076725\n",
      "0.010945222340524197\n",
      "0.011402366682887077\n",
      "0.011832713149487972\n",
      "0.0114445136860013\n",
      "0.010644079186022282\n",
      "0.011550833471119404\n",
      "0.012149176560342312\n",
      "0.011197525076568127\n",
      "0.012564766220748425\n",
      "0.011624920181930065\n",
      "0.012553419917821884\n",
      "0.010886271484196186\n",
      "0.011732054874300957\n",
      "0.011644434183835983\n",
      "0.011956503614783287\n",
      "0.010233694687485695\n",
      "0.011930417269468307\n",
      "0.011163229122757912\n",
      "0.012859879992902279\n",
      "0.010171395726501942\n",
      "0.011951470747590065\n",
      "0.011542442254722118\n",
      "0.013275159522891045\n",
      "0.011942998506128788\n",
      "0.012306167744100094\n",
      "0.011540878564119339\n",
      "0.01158586423844099\n",
      "0.011178998276591301\n",
      "0.012722369283437729\n",
      "0.011217226274311543\n",
      "0.012178350239992142\n",
      "0.010897929780185223\n",
      "0.012269941158592701\n",
      "0.012333372607827187\n",
      "0.011706057004630566\n",
      "0.011661293916404247\n",
      "0.01325701642781496\n",
      "0.011290322989225388\n",
      "0.011731467209756374\n",
      "0.0117188086733222\n",
      "0.010946283116936684\n",
      "0.013033601455390453\n",
      "0.011207619681954384\n",
      "0.0110476678237319\n",
      "0.01312137208878994\n",
      "0.012043365277349949\n",
      "0.011241690255701542\n",
      "0.010276377201080322\n",
      "0.012126380577683449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [08:08<52:31, 121.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7621017156862745\n",
      "验证集精度0.7671875\n",
      "测试集精度0.759375\n",
      "0.011684746481478214\n",
      "0.01181316003203392\n",
      "0.01256705541163683\n",
      "0.00992601364850998\n",
      "0.010640661232173443\n",
      "0.011576375924050808\n",
      "0.011294293217360973\n",
      "0.011539792641997337\n",
      "0.010943680070340633\n",
      "0.011875970289111137\n",
      "0.010809489525854588\n",
      "0.011050725355744362\n",
      "0.01198747381567955\n",
      "0.011435536667704582\n",
      "0.011265653185546398\n",
      "0.011270730756223202\n",
      "0.011916802264750004\n",
      "0.010991568677127361\n",
      "0.010611982084810734\n",
      "0.010565007105469704\n",
      "0.010815885849297047\n",
      "0.010656689293682575\n",
      "0.011239421553909779\n",
      "0.010813507251441479\n",
      "0.011816785670816898\n",
      "0.01210733875632286\n",
      "0.012068766169250011\n",
      "0.009969155304133892\n",
      "0.012036992236971855\n",
      "0.012643123045563698\n",
      "0.010004988871514797\n",
      "0.010728604160249233\n",
      "0.012388368137180805\n",
      "0.010978451929986477\n",
      "0.011509732343256474\n",
      "0.011611574329435825\n",
      "0.011466508731245995\n",
      "0.011079388670623302\n",
      "0.011245803907513618\n",
      "0.01050021592527628\n",
      "0.01077487226575613\n",
      "0.011334332637488842\n",
      "0.011778313666582108\n",
      "0.010228225961327553\n",
      "0.010318380780518055\n",
      "0.010805953294038773\n",
      "0.010154028423130512\n",
      "0.010749663226306438\n",
      "0.011504660360515118\n",
      "0.011001331731677055\n",
      "0.011025446467101574\n",
      "0.010868045501410961\n",
      "0.01041153073310852\n",
      "0.010309522971510887\n",
      "0.011824962683022022\n",
      "0.012211372144520283\n",
      "0.010548766702413559\n",
      "0.012011471204459667\n",
      "0.01147010363638401\n",
      "0.0111707067117095\n",
      "0.010260316543281078\n",
      "0.011221794411540031\n",
      "0.010852876119315624\n",
      "0.011622047983109951\n",
      "0.011042920872569084\n",
      "0.011144164949655533\n",
      "0.010736635886132717\n",
      "0.010372002609074116\n",
      "0.010397292673587799\n",
      "0.011637545190751553\n",
      "0.012699214741587639\n",
      "0.011798818595707417\n",
      "0.010891956277191639\n",
      "0.012064670212566853\n",
      "0.013766877353191376\n",
      "0.011889160610735416\n",
      "0.010788504034280777\n",
      "0.011251852847635746\n",
      "0.011162038892507553\n",
      "0.011154500767588615\n",
      "0.010942851193249226\n",
      "0.01080898568034172\n",
      "0.010782740078866482\n",
      "0.01185826025903225\n",
      "0.011133341118693352\n",
      "0.010539158247411251\n",
      "0.011640097945928574\n",
      "0.011555946432054043\n",
      "0.010496665723621845\n",
      "0.011794399470090866\n",
      "0.010561459697782993\n",
      "0.012140034697949886\n",
      "0.012088951654732227\n",
      "0.011591998860239983\n",
      "0.011719832196831703\n",
      "0.012430715374648571\n",
      "0.010872130282223225\n",
      "0.010315712541341782\n",
      "0.01197279803454876\n",
      "0.011427166871726513\n",
      "0.010880923829972744\n",
      "0.010507339611649513\n",
      "0.012239204719662666\n",
      "0.011872909031808376\n",
      "0.012103992514312267\n",
      "0.011824531480669975\n",
      "0.011066264472901821\n",
      "0.012595855630934238\n",
      "0.010755435563623905\n",
      "0.012150442227721214\n",
      "0.01105268020182848\n",
      "0.010872213169932365\n",
      "0.012639147229492664\n",
      "0.011406196281313896\n",
      "0.012605846859514713\n",
      "0.011444236151874065\n",
      "0.011404989287257195\n",
      "0.010787729173898697\n",
      "0.012093605473637581\n",
      "0.0113349799066782\n",
      "0.012277165427803993\n",
      "0.01180282048881054\n",
      "0.011745106428861618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [09:54<48:14, 115.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7715226715686274\n",
      "验证集精度0.7734375\n",
      "测试集精度0.746875\n",
      "0.010414588265120983\n",
      "0.01196594163775444\n",
      "0.011224319227039814\n",
      "0.011015471071004868\n",
      "0.010806748643517494\n",
      "0.010115480050444603\n",
      "0.01058635301887989\n",
      "0.011525082401931286\n",
      "0.01179027371108532\n",
      "0.011156255379319191\n",
      "0.012458818964660168\n",
      "0.011889043264091015\n",
      "0.011960775591433048\n",
      "0.012146464549005032\n",
      "0.011644823476672173\n",
      "0.010934267193078995\n",
      "0.011241326108574867\n",
      "0.011979210190474987\n",
      "0.011816231533885002\n",
      "0.012034859508275986\n",
      "0.011669730767607689\n",
      "0.011119622737169266\n",
      "0.011015789583325386\n",
      "0.010295342653989792\n",
      "0.009912941604852676\n",
      "0.011099617928266525\n",
      "0.012021570466458797\n",
      "0.011885765008628368\n",
      "0.011457918211817741\n",
      "0.011284658685326576\n",
      "0.01092187687754631\n",
      "0.011369760148227215\n",
      "0.010656480677425861\n",
      "0.011118843220174313\n",
      "0.010278625413775444\n",
      "0.010625693015754223\n",
      "0.010954962112009525\n",
      "0.01019410602748394\n",
      "0.011446909047663212\n",
      "0.010970809496939182\n",
      "0.011996482498943806\n",
      "0.011762174777686596\n",
      "0.011480452492833138\n",
      "0.010591013357043266\n",
      "0.010240700095891953\n",
      "0.010432388633489609\n",
      "0.011481882072985172\n",
      "0.013624247163534164\n",
      "0.010631954297423363\n",
      "0.011443558149039745\n",
      "0.011707860045135021\n",
      "0.010701147839426994\n",
      "0.010797109454870224\n",
      "0.010196240618824959\n",
      "0.009764239192008972\n",
      "0.011714727617800236\n",
      "0.010761143639683723\n",
      "0.010952667333185673\n",
      "0.010375377722084522\n",
      "0.011386553756892681\n",
      "0.012870687060058117\n",
      "0.012363838031888008\n",
      "0.011392781510949135\n",
      "0.01106566283851862\n",
      "0.012548807077109814\n",
      "0.01112848799675703\n",
      "0.010645062662661076\n",
      "0.012484387494623661\n",
      "0.010812838561832905\n",
      "0.010102974250912666\n",
      "0.0119240777567029\n",
      "0.011797028593719006\n",
      "0.011403629556298256\n",
      "0.013123678043484688\n",
      "0.011665938422083855\n",
      "0.010244801640510559\n",
      "0.010746261104941368\n",
      "0.010188779793679714\n",
      "0.011669247411191463\n",
      "0.010851862840354443\n",
      "0.01035869400948286\n",
      "0.010249379090964794\n",
      "0.011346470564603806\n",
      "0.0116035221144557\n",
      "0.011527913622558117\n",
      "0.011203289963304996\n",
      "0.010099872946739197\n",
      "0.011064146645367146\n",
      "0.010726013220846653\n",
      "0.011108217760920525\n",
      "0.01144044753164053\n",
      "0.011923294514417648\n",
      "0.010602889582514763\n",
      "0.012017625384032726\n",
      "0.012148195877671242\n",
      "0.01020738109946251\n",
      "0.012187168933451176\n",
      "0.011293302290141582\n",
      "0.01164350938051939\n",
      "0.009390721097588539\n",
      "0.010515346191823483\n",
      "0.012504469603300095\n",
      "0.011994213797152042\n",
      "0.011456947773694992\n",
      "0.011715990491211414\n",
      "0.011461117304861546\n",
      "0.01061825081706047\n",
      "0.010648909024894238\n",
      "0.010235312394797802\n",
      "0.010040908120572567\n",
      "0.011332953348755836\n",
      "0.01219100784510374\n",
      "0.011325481347739697\n",
      "0.010525697842240334\n",
      "0.010994361713528633\n",
      "0.010879289358854294\n",
      "0.01156765129417181\n",
      "0.011496351100504398\n",
      "0.011464630253612995\n",
      "0.011715244501829147\n",
      "0.010727210901677608\n",
      "0.011856033466756344\n",
      "0.010780409909784794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [11:47<45:59, 114.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8311121323529411\n",
      "验证集精度0.853125\n",
      "测试集精度0.8171875\n",
      "0.011636817827820778\n",
      "0.0096191531047225\n",
      "0.01067641656845808\n",
      "0.010082167573273182\n",
      "0.010821997188031673\n",
      "0.00981762632727623\n",
      "0.009734243154525757\n",
      "0.012017940171062946\n",
      "0.009765800088644028\n",
      "0.01210195291787386\n",
      "0.010542456991970539\n",
      "0.010033409111201763\n",
      "0.010847707279026508\n",
      "0.010766587220132351\n",
      "0.011314726434648037\n",
      "0.01041066087782383\n",
      "0.010547121055424213\n",
      "0.011043081060051918\n",
      "0.010671067051589489\n",
      "0.011710520833730698\n",
      "0.010622969828546047\n",
      "0.011697573587298393\n",
      "0.011109109036624432\n",
      "0.011684434488415718\n",
      "0.010924236848950386\n",
      "0.009507851675152779\n",
      "0.01008562371134758\n",
      "0.010712860152125359\n",
      "0.011151213198900223\n",
      "0.01171976700425148\n",
      "0.010946557857096195\n",
      "0.01099895779043436\n",
      "0.011210435070097446\n",
      "0.011158839799463749\n",
      "0.011908303014934063\n",
      "0.01099089439958334\n",
      "0.01121914479881525\n",
      "0.012533235363662243\n",
      "0.01115402765572071\n",
      "0.011448553763329983\n",
      "0.009975492022931576\n",
      "0.010198460891842842\n",
      "0.010546265169978142\n",
      "0.012469913810491562\n",
      "0.011046167463064194\n",
      "0.011051202192902565\n",
      "0.011233136989176273\n",
      "0.01091493759304285\n",
      "0.010918030515313148\n",
      "0.010476901195943356\n",
      "0.01118108257651329\n",
      "0.010714972391724586\n",
      "0.009917388670146465\n",
      "0.012385058216750622\n",
      "0.009491395205259323\n",
      "0.01095316931605339\n",
      "0.011933529749512672\n",
      "0.009871305897831917\n",
      "0.00910264067351818\n",
      "0.01104521844536066\n",
      "0.011540601029992104\n",
      "0.010155352763831615\n",
      "0.010424754582345486\n",
      "0.00957701075822115\n",
      "0.012132002040743828\n",
      "0.010769565589725971\n",
      "0.010719452984631062\n",
      "0.010578860528767109\n",
      "0.01104852743446827\n",
      "0.01079774834215641\n",
      "0.011437159031629562\n",
      "0.010847313329577446\n",
      "0.011788995936512947\n",
      "0.010643912479281425\n",
      "0.01198070403188467\n",
      "0.009762732312083244\n",
      "0.010536021552979946\n",
      "0.009920869953930378\n",
      "0.011361886747181416\n",
      "0.010793013498187065\n",
      "0.010165068320930004\n",
      "0.011097249574959278\n",
      "0.010399646125733852\n",
      "0.010746534913778305\n",
      "0.010772822424769402\n",
      "0.011326408945024014\n",
      "0.011312681250274181\n",
      "0.011129484511911869\n",
      "0.01039680652320385\n",
      "0.010465767234563828\n",
      "0.012405839748680592\n",
      "0.012320146895945072\n",
      "0.01036439836025238\n",
      "0.011000534519553185\n",
      "0.011094902642071247\n",
      "0.012271844781935215\n",
      "0.010219465009868145\n",
      "0.011040332727134228\n",
      "0.010464536026120186\n",
      "0.011599715799093246\n",
      "0.011125613935291767\n",
      "0.010274812579154968\n",
      "0.01007871888577938\n",
      "0.011354944668710232\n",
      "0.010556823574006557\n",
      "0.012192903086543083\n",
      "0.01003032736480236\n",
      "0.01199161633849144\n",
      "0.011165295727550983\n",
      "0.011639540083706379\n",
      "0.011285706423223019\n",
      "0.010446848347783089\n",
      "0.011805460788309574\n",
      "0.010912084020674229\n",
      "0.010503587312996387\n",
      "0.010591915808618069\n",
      "0.011765598319470882\n",
      "0.011049041524529457\n",
      "0.010859822854399681\n",
      "0.010571069084107876\n",
      "0.01094968430697918\n",
      "0.010619747452437878\n",
      "0.01127372495830059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [13:36<43:19, 113.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8385416666666666\n",
      "验证集精度0.8546875\n",
      "测试集精度0.8265625\n",
      "0.010512365028262138\n",
      "0.010187743231654167\n",
      "0.011131610721349716\n",
      "0.00972731877118349\n",
      "0.012287352234125137\n",
      "0.012465898878872395\n",
      "0.01054264884442091\n",
      "0.011330575682222843\n",
      "0.009701031260192394\n",
      "0.010270101949572563\n",
      "0.010544941760599613\n",
      "0.01108559314161539\n",
      "0.01065037865191698\n",
      "0.01063169352710247\n",
      "0.009097072295844555\n",
      "0.011513405479490757\n",
      "0.011277156881988049\n",
      "0.010768208652734756\n",
      "0.010614651255309582\n",
      "0.011483301408588886\n",
      "0.010719059966504574\n",
      "0.010831090621650219\n",
      "0.00993423443287611\n",
      "0.011307301931083202\n",
      "0.011763965710997581\n",
      "0.010827523656189442\n",
      "0.009958302602171898\n",
      "0.010234443470835686\n",
      "0.010347372852265835\n",
      "0.010046829469501972\n",
      "0.010837775655090809\n",
      "0.010204247198998928\n",
      "0.011150235310196877\n",
      "0.011168623343110085\n",
      "0.010128681547939777\n",
      "0.012131313793361187\n",
      "0.010841960087418556\n",
      "0.012676739133894444\n",
      "0.009881552308797836\n",
      "0.010672749020159245\n",
      "0.010787677019834518\n",
      "0.009801937267184258\n",
      "0.010468645952641964\n",
      "0.009720309637486935\n",
      "0.00997451227158308\n",
      "0.00942004844546318\n",
      "0.010735882446169853\n",
      "0.011499480344355106\n",
      "0.01065054815262556\n",
      "0.010345627553761005\n",
      "0.011308591812849045\n",
      "0.011309297755360603\n",
      "0.010576925240457058\n",
      "0.011669905856251717\n",
      "0.011456558480858803\n",
      "0.010954701341688633\n",
      "0.010273358784615993\n",
      "0.011848565191030502\n",
      "0.010319043882191181\n",
      "0.010599524714052677\n",
      "0.010121424682438374\n",
      "0.010838462971150875\n",
      "0.011090252548456192\n",
      "0.010052962228655815\n",
      "0.011692207306623459\n",
      "0.010842579416930676\n",
      "0.010837377049028873\n",
      "0.010693076066672802\n",
      "0.010137345641851425\n",
      "0.011542748659849167\n",
      "0.011287174187600613\n",
      "0.01007474958896637\n",
      "0.011763873510062695\n",
      "0.01128045842051506\n",
      "0.009489776566624641\n",
      "0.010889587923884392\n",
      "0.011197845451533794\n",
      "0.010010205209255219\n",
      "0.011333278380334377\n",
      "0.00998514611274004\n",
      "0.012424481101334095\n",
      "0.011874372139573097\n",
      "0.012269900180399418\n",
      "0.010910162702202797\n",
      "0.010303161107003689\n",
      "0.010049290955066681\n",
      "0.01102638803422451\n",
      "0.010583139024674892\n",
      "0.00971576850861311\n",
      "0.010926317423582077\n",
      "0.01132096815854311\n",
      "0.011088026687502861\n",
      "0.010741249658167362\n",
      "0.011007113382220268\n",
      "0.009962283074855804\n",
      "0.011466589756309986\n",
      "0.010545195080339909\n",
      "0.01095276977866888\n",
      "0.010583118535578251\n",
      "0.011292568407952785\n",
      "0.012798563577234745\n",
      "0.011285278014838696\n",
      "0.010249344632029533\n",
      "0.010491319932043552\n",
      "0.010129893198609352\n",
      "0.011309588328003883\n",
      "0.011426053009927273\n",
      "0.010784647427499294\n",
      "0.010845190845429897\n",
      "0.011053011752665043\n",
      "0.010914762504398823\n",
      "0.009965527802705765\n",
      "0.01078871265053749\n",
      "0.011270957998931408\n",
      "0.011000732891261578\n",
      "0.01290618535131216\n",
      "0.011673273518681526\n",
      "0.011413621716201305\n",
      "0.011791651137173176\n",
      "0.011287879198789597\n",
      "0.009960372932255268\n",
      "0.009770995937287807\n",
      "0.011167628690600395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [15:16<39:55, 108.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8348651960784313\n",
      "验证集精度0.846875\n",
      "测试集精度0.828125\n",
      "0.010680449195206165\n",
      "0.010256989859044552\n",
      "0.010853911750018597\n",
      "0.011038567870855331\n",
      "0.010917711071670055\n",
      "0.01187821850180626\n",
      "0.010461588390171528\n",
      "0.011432716622948647\n",
      "0.01133250817656517\n",
      "0.011323150247335434\n",
      "0.010821116156876087\n",
      "0.010819745250046253\n",
      "0.010488159023225307\n",
      "0.010723325423896313\n",
      "0.01006161980330944\n",
      "0.01003061793744564\n",
      "0.01044419500976801\n",
      "0.009646805003285408\n",
      "0.009869290515780449\n",
      "0.010057544335722923\n",
      "0.010584408417344093\n",
      "0.009429576806724072\n",
      "0.009434682317078114\n",
      "0.011932270601391792\n",
      "0.011816506274044514\n",
      "0.010679132305085659\n",
      "0.01216620672494173\n",
      "0.010159674100577831\n",
      "0.011731956154108047\n",
      "0.011125669814646244\n",
      "0.011463457718491554\n",
      "0.01039858814328909\n",
      "0.011461267247796059\n",
      "0.010901909321546555\n",
      "0.010536516085267067\n",
      "0.011529160663485527\n",
      "0.010367043316364288\n",
      "0.010235357098281384\n",
      "0.010700042359530926\n",
      "0.010025492869317532\n",
      "0.009998118504881859\n",
      "0.009938712231814861\n",
      "0.010166466236114502\n",
      "0.010631310753524303\n",
      "0.0100887231528759\n",
      "0.010571473278105259\n",
      "0.010249242186546326\n",
      "0.01104542426764965\n",
      "0.00976539310067892\n",
      "0.010237489826977253\n",
      "0.010166223160922527\n",
      "0.011909144930541515\n",
      "0.011422506533563137\n",
      "0.010627519339323044\n",
      "0.010556674562394619\n",
      "0.010368587449193\n",
      "0.01058788038790226\n",
      "0.010610979050397873\n",
      "0.01099859643727541\n",
      "0.010347515344619751\n",
      "0.01127138826996088\n",
      "0.010491441935300827\n",
      "0.010033171623945236\n",
      "0.010953725315630436\n",
      "0.012252495624125004\n",
      "0.010824308730661869\n",
      "0.012635604478418827\n",
      "0.010742170736193657\n",
      "0.010699091479182243\n",
      "0.01047466229647398\n",
      "0.011256054975092411\n",
      "0.010138330981135368\n",
      "0.010274703614413738\n",
      "0.010109331458806992\n",
      "0.012239260599017143\n",
      "0.010758358053863049\n",
      "0.00953918881714344\n",
      "0.009985534474253654\n",
      "0.011544222012162209\n",
      "0.011343920603394508\n",
      "0.010879991576075554\n",
      "0.01203895267099142\n",
      "0.011590334586799145\n",
      "0.01034480333328247\n",
      "0.010708240792155266\n",
      "0.010689165443181992\n",
      "0.010604526847600937\n",
      "0.011848779395222664\n",
      "0.009782765060663223\n",
      "0.010765684768557549\n",
      "0.009683285839855671\n",
      "0.010212558321654797\n",
      "0.009651750326156616\n",
      "0.011474622413516045\n",
      "0.01045734342187643\n",
      "0.010217292234301567\n",
      "0.011453527957201004\n",
      "0.01165790669620037\n",
      "0.010350441560149193\n",
      "0.011777710169553757\n",
      "0.01095727737993002\n",
      "0.009173711761832237\n",
      "0.01034445222467184\n",
      "0.011257723905146122\n",
      "0.011401345022022724\n",
      "0.00882720947265625\n",
      "0.011809251271188259\n",
      "0.011116904206573963\n",
      "0.011413262225687504\n",
      "0.010900227352976799\n",
      "0.009748411364853382\n",
      "0.010719042271375656\n",
      "0.01042611338198185\n",
      "0.010314008221030235\n",
      "0.010249991901218891\n",
      "0.00939736794680357\n",
      "0.010974827222526073\n",
      "0.011098826304078102\n",
      "0.012417617253959179\n",
      "0.011334703303873539\n",
      "0.01018226146697998\n",
      "0.010019676759839058\n",
      "0.011142384260892868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [16:53<36:44, 104.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8465839460784313\n",
      "验证集精度0.859375\n",
      "测试集精度0.8421875\n",
      "0.011227373965084553\n",
      "0.010705904103815556\n",
      "0.010473070666193962\n",
      "0.01020355150103569\n",
      "0.011456144973635674\n",
      "0.010468677617609501\n",
      "0.009684707969427109\n",
      "0.01040344126522541\n",
      "0.010697061195969582\n",
      "0.01172487810254097\n",
      "0.010457935743033886\n",
      "0.011780121363699436\n",
      "0.010493398644030094\n",
      "0.011466721072793007\n",
      "0.01223744172602892\n",
      "0.009963737800717354\n",
      "0.012140193954110146\n",
      "0.010907473042607307\n",
      "0.011330107226967812\n",
      "0.009909356012940407\n",
      "0.011418977752327919\n",
      "0.010794046334922314\n",
      "0.011514331214129925\n",
      "0.011632234789431095\n",
      "0.009402072988450527\n",
      "0.011328269727528095\n",
      "0.01053455751389265\n",
      "0.010905285365879536\n",
      "0.01019174512475729\n",
      "0.010808466002345085\n",
      "0.009774582460522652\n",
      "0.009525245986878872\n",
      "0.010354924015700817\n",
      "0.009820337407290936\n",
      "0.011162121780216694\n",
      "0.011798350140452385\n",
      "0.009918472729623318\n",
      "0.010374028235673904\n",
      "0.010776529088616371\n",
      "0.01136434730142355\n",
      "0.011553140357136726\n",
      "0.009888420812785625\n",
      "0.010132568888366222\n",
      "0.010382194072008133\n",
      "0.010619661770761013\n",
      "0.009876949712634087\n",
      "0.011456016451120377\n",
      "0.008926098234951496\n",
      "0.010051657445728779\n",
      "0.010903061367571354\n",
      "0.009518403559923172\n",
      "0.011865363456308842\n",
      "0.010431594215333462\n",
      "0.011351915076375008\n",
      "0.011407198384404182\n",
      "0.009692803025245667\n",
      "0.010033397004008293\n",
      "0.011326160281896591\n",
      "0.01018010638654232\n",
      "0.010913071222603321\n",
      "0.01084245927631855\n",
      "0.011280040256679058\n",
      "0.009854694828391075\n",
      "0.011433320119976997\n",
      "0.009517497383058071\n",
      "0.009929057210683823\n",
      "0.010030274279415607\n",
      "0.00983813963830471\n",
      "0.010494322516024113\n",
      "0.011400419287383556\n",
      "0.011671153828501701\n",
      "0.011166246607899666\n",
      "0.010708475485444069\n",
      "0.011122923344373703\n",
      "0.010918782092630863\n",
      "0.010883783921599388\n",
      "0.010131578892469406\n",
      "0.010752517729997635\n",
      "0.011617569252848625\n",
      "0.009341766126453876\n",
      "0.010436255484819412\n",
      "0.011080303229391575\n",
      "0.00996789988130331\n",
      "0.010787101462483406\n",
      "0.010586628690361977\n",
      "0.010001551359891891\n",
      "0.008723258040845394\n",
      "0.011379406787455082\n",
      "0.01103325467556715\n",
      "0.010410447604954243\n",
      "0.010122586973011494\n",
      "0.009853389114141464\n",
      "0.010521914809942245\n",
      "0.010583858005702496\n",
      "0.011707217432558537\n",
      "0.010181181132793427\n",
      "0.011292550712823868\n",
      "0.009972350671887398\n",
      "0.010109697468578815\n",
      "0.011710429564118385\n",
      "0.010059850290417671\n",
      "0.010663969442248344\n",
      "0.011288619600236416\n",
      "0.009233098477125168\n",
      "0.012477952055633068\n",
      "0.009933187626302242\n",
      "0.009767829440534115\n",
      "0.010609135963022709\n",
      "0.010922613553702831\n",
      "0.009833604097366333\n",
      "0.009991049766540527\n",
      "0.010745076462626457\n",
      "0.010107923299074173\n",
      "0.010128728114068508\n",
      "0.009896908886730671\n",
      "0.010398605838418007\n",
      "0.010530638508498669\n",
      "0.011588298715651035\n",
      "0.010789242573082447\n",
      "0.009593714959919453\n",
      "0.009987309575080872\n",
      "0.012438099831342697\n",
      "0.010182651691138744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [18:39<35:09, 105.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.867953431372549\n",
      "验证集精度0.8703125\n",
      "测试集精度0.853125\n",
      "0.010087145492434502\n",
      "0.011158806271851063\n",
      "0.009960871189832687\n",
      "0.011702288873493671\n",
      "0.011832163669168949\n",
      "0.010194465517997742\n",
      "0.00986681692302227\n",
      "0.010551009327173233\n",
      "0.010793296620249748\n",
      "0.009790996089577675\n",
      "0.010123802348971367\n",
      "0.011041897349059582\n",
      "0.009832987561821938\n",
      "0.009013763628900051\n",
      "0.011673329398036003\n",
      "0.010149521753191948\n",
      "0.01020733080804348\n",
      "0.011581904254853725\n",
      "0.009145285934209824\n",
      "0.010457942262291908\n",
      "0.012292402796447277\n",
      "0.010532640852034092\n",
      "0.00973624549806118\n",
      "0.009418129920959473\n",
      "0.01060883142054081\n",
      "0.010427895933389664\n",
      "0.01020132564008236\n",
      "0.010240553878247738\n",
      "0.010360809974372387\n",
      "0.01155105885118246\n",
      "0.010393261909484863\n",
      "0.008946261368691921\n",
      "0.010141781531274319\n",
      "0.010323632508516312\n",
      "0.009414197877049446\n",
      "0.010524417273700237\n",
      "0.01064325962215662\n",
      "0.011875064112246037\n",
      "0.010464509017765522\n",
      "0.010568100027740002\n",
      "0.011678474023938179\n",
      "0.01066560111939907\n",
      "0.010006201453506947\n",
      "0.010288042947649956\n",
      "0.009168876335024834\n",
      "0.01081312820315361\n",
      "0.010515442118048668\n",
      "0.011145349591970444\n",
      "0.010757318697869778\n",
      "0.010027025826275349\n",
      "0.011044644750654697\n",
      "0.010628636926412582\n",
      "0.01069109421223402\n",
      "0.011846036650240421\n",
      "0.010963546112179756\n",
      "0.010011277161538601\n",
      "0.010903959162533283\n",
      "0.010284094139933586\n",
      "0.011183726601302624\n",
      "0.009651867672801018\n",
      "0.009492632001638412\n",
      "0.01061688270419836\n",
      "0.01096280012279749\n",
      "0.010584050789475441\n",
      "0.010610328987240791\n",
      "0.010209009051322937\n",
      "0.010122979059815407\n",
      "0.011023092083632946\n",
      "0.01044889260083437\n",
      "0.010603608563542366\n",
      "0.010830936953425407\n",
      "0.010886544361710548\n",
      "0.0103291105479002\n",
      "0.011204265989363194\n",
      "0.009553192183375359\n",
      "0.010706068016588688\n",
      "0.01082017831504345\n",
      "0.010668586939573288\n",
      "0.011561206541955471\n",
      "0.010136399418115616\n",
      "0.011049281805753708\n",
      "0.010173184797167778\n",
      "0.010429722256958485\n",
      "0.010506809689104557\n",
      "0.011664397083222866\n",
      "0.010807282291352749\n",
      "0.011543495580554008\n",
      "0.010419514030218124\n",
      "0.010831339284777641\n",
      "0.010178832337260246\n",
      "0.009016480296850204\n",
      "0.009172506630420685\n",
      "0.01001029647886753\n",
      "0.0105168167501688\n",
      "0.00998452864587307\n",
      "0.010836522094905376\n",
      "0.01046719215810299\n",
      "0.010990963317453861\n",
      "0.010456881485879421\n",
      "0.010610167868435383\n",
      "0.010073564015328884\n",
      "0.010489544831216335\n",
      "0.009495321661233902\n",
      "0.011066323146224022\n",
      "0.010774512775242329\n",
      "0.010936317034065723\n",
      "0.010701180435717106\n",
      "0.011090517975389957\n",
      "0.009432865306735039\n",
      "0.011625658720731735\n",
      "0.01064523495733738\n",
      "0.01076038833707571\n",
      "0.011035572737455368\n",
      "0.00966124702244997\n",
      "0.00960121676325798\n",
      "0.009548011235892773\n",
      "0.01052326150238514\n",
      "0.011510813608765602\n",
      "0.010500499978661537\n",
      "0.01023240014910698\n",
      "0.011510778218507767\n",
      "0.010673267766833305\n",
      "0.00933406688272953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [20:11<32:05, 101.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8570006127450981\n",
      "验证集精度0.871875\n",
      "测试集精度0.8546875\n",
      "0.009983660653233528\n",
      "0.009999755769968033\n",
      "0.010844316333532333\n",
      "0.010208827443420887\n",
      "0.010073858313262463\n",
      "0.009459792636334896\n",
      "0.010649449191987514\n",
      "0.010753670707345009\n",
      "0.010181210935115814\n",
      "0.009669622406363487\n",
      "0.01136109884828329\n",
      "0.010354178957641125\n",
      "0.011616573669016361\n",
      "0.009950865991413593\n",
      "0.010314379818737507\n",
      "0.010286842472851276\n",
      "0.010171730071306229\n",
      "0.010203617624938488\n",
      "0.010536272078752518\n",
      "0.010867652483284473\n",
      "0.009936675429344177\n",
      "0.01006606686860323\n",
      "0.010414806194603443\n",
      "0.011582176201045513\n",
      "0.010291270911693573\n",
      "0.011723693460226059\n",
      "0.010218439623713493\n",
      "0.00993155688047409\n",
      "0.009941956028342247\n",
      "0.010941488668322563\n",
      "0.011211786419153214\n",
      "0.011710463091731071\n",
      "0.010726108215749264\n",
      "0.012119541876018047\n",
      "0.01150360144674778\n",
      "0.011494548059999943\n",
      "0.010091735050082207\n",
      "0.010630724020302296\n",
      "0.011070228181779385\n",
      "0.010284226387739182\n",
      "0.011715861968696117\n",
      "0.011410851031541824\n",
      "0.010214022360742092\n",
      "0.010898630134761333\n",
      "0.010919547639787197\n",
      "0.009484812617301941\n",
      "0.010424520820379257\n",
      "0.010103895328938961\n",
      "0.010700120590627193\n",
      "0.01118266861885786\n",
      "0.009946814738214016\n",
      "0.010996394790709019\n",
      "0.010590380989015102\n",
      "0.00934282410889864\n",
      "0.010800794698297977\n",
      "0.01132728811353445\n",
      "0.01062830351293087\n",
      "0.010576988570392132\n",
      "0.011734848842024803\n",
      "0.01030378695577383\n",
      "0.010910669341683388\n",
      "0.011311065405607224\n",
      "0.008781125769019127\n",
      "0.010360058397054672\n",
      "0.01215085294097662\n",
      "0.010583484545350075\n",
      "0.010155325755476952\n",
      "0.009906130842864513\n",
      "0.009198359213769436\n",
      "0.011155571788549423\n",
      "0.010528487153351307\n",
      "0.009836450219154358\n",
      "0.010193596594035625\n",
      "0.010510692372918129\n",
      "0.009045488201081753\n",
      "0.009015820920467377\n",
      "0.01048052404075861\n",
      "0.009624645113945007\n",
      "0.011012363247573376\n",
      "0.010841833427548409\n",
      "0.010057903826236725\n",
      "0.011800230480730534\n",
      "0.010867629200220108\n",
      "0.011311803013086319\n",
      "0.011121204122900963\n",
      "0.008881065994501114\n",
      "0.009371860884130001\n",
      "0.010725850239396095\n",
      "0.009405980817973614\n",
      "0.009302007965743542\n",
      "0.011411397717893124\n",
      "0.010984429158270359\n",
      "0.01108724158257246\n",
      "0.010538546368479729\n",
      "0.010330650955438614\n",
      "0.009133069775998592\n",
      "0.008802101016044617\n",
      "0.009765185415744781\n",
      "0.010433793999254704\n",
      "0.010709311813116074\n",
      "0.01114138774573803\n",
      "0.01214685570448637\n",
      "0.010814455337822437\n",
      "0.009812614880502224\n",
      "0.011187280528247356\n",
      "0.011231458745896816\n",
      "0.009959821589291096\n",
      "0.010880159214138985\n",
      "0.009295484982430935\n",
      "0.010573017410933971\n",
      "0.009397154673933983\n",
      "0.011239210143685341\n",
      "0.011792839504778385\n",
      "0.009305494837462902\n",
      "0.009796123951673508\n",
      "0.011494358070194721\n",
      "0.010384049266576767\n",
      "0.009505792520940304\n",
      "0.010730923153460026\n",
      "0.010316608473658562\n",
      "0.010008087381720543\n",
      "0.010460132732987404\n",
      "0.009936481714248657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [21:58<30:51, 102.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8780637254901961\n",
      "验证集精度0.884375\n",
      "测试集精度0.8640625\n",
      "0.011437768116593361\n",
      "0.010952349752187729\n",
      "0.010678724385797977\n",
      "0.010203306563198566\n",
      "0.009340967983007431\n",
      "0.01060240063816309\n",
      "0.009886465966701508\n",
      "0.010519024915993214\n",
      "0.011497790925204754\n",
      "0.010474239476025105\n",
      "0.01038440503180027\n",
      "0.010793600231409073\n",
      "0.010606674477458\n",
      "0.0099877268075943\n",
      "0.011186880990862846\n",
      "0.011298884637653828\n",
      "0.010736998170614243\n",
      "0.010209346190094948\n",
      "0.010943650268018246\n",
      "0.009855847805738449\n",
      "0.009747559204697609\n",
      "0.010688637383282185\n",
      "0.009074795991182327\n",
      "0.009865427389740944\n",
      "0.009393407963216305\n",
      "0.011256452649831772\n",
      "0.010667280294001102\n",
      "0.00999574176967144\n",
      "0.009989913552999496\n",
      "0.008032101206481457\n",
      "0.010651386342942715\n",
      "0.010779132135212421\n",
      "0.012471427209675312\n",
      "0.009720362722873688\n",
      "0.009951261803507805\n",
      "0.011536152102053165\n",
      "0.010893047787249088\n",
      "0.009825387969613075\n",
      "0.012355875223875046\n",
      "0.010016112588346004\n",
      "0.010303715243935585\n",
      "0.010068871080875397\n",
      "0.009825235232710838\n",
      "0.011071575805544853\n",
      "0.010560300201177597\n",
      "0.009533355012536049\n",
      "0.01213779766112566\n",
      "0.010595325380563736\n",
      "0.011192272417247295\n",
      "0.011087175458669662\n",
      "0.010973677970468998\n",
      "0.009781712666153908\n",
      "0.010131853632628918\n",
      "0.01093965396285057\n",
      "0.011539042927324772\n",
      "0.010960136540234089\n",
      "0.010537364520132542\n",
      "0.011446434073150158\n",
      "0.010262083262205124\n",
      "0.011867140419781208\n",
      "0.011148533783853054\n",
      "0.009024671278893948\n",
      "0.010637643747031689\n",
      "0.011156740598380566\n",
      "0.010631789453327656\n",
      "0.009788674302399158\n",
      "0.010314214043319225\n",
      "0.010300248861312866\n",
      "0.010421110317111015\n",
      "0.010721739381551743\n",
      "0.010028328746557236\n",
      "0.010871282778680325\n",
      "0.0101628378033638\n",
      "0.009908195585012436\n",
      "0.010041452944278717\n",
      "0.011323858052492142\n",
      "0.009192315861582756\n",
      "0.010148147121071815\n",
      "0.01072531659156084\n",
      "0.010099205188453197\n",
      "0.011129978112876415\n",
      "0.010929902084171772\n",
      "0.009652584791183472\n",
      "0.012225777842104435\n",
      "0.010303131304681301\n",
      "0.010993828065693378\n",
      "0.009642580524086952\n",
      "0.008968538604676723\n",
      "0.010781113989651203\n",
      "0.011433661915361881\n",
      "0.01069182250648737\n",
      "0.010836542584002018\n",
      "0.010230648331344128\n",
      "0.011736657470464706\n",
      "0.010871274396777153\n",
      "0.011180528439581394\n",
      "0.010255741886794567\n",
      "0.010970230214297771\n",
      "0.010898162610828876\n",
      "0.01003245823085308\n",
      "0.009750287979841232\n",
      "0.010083884000778198\n",
      "0.010635395534336567\n",
      "0.011374497786164284\n",
      "0.010929564014077187\n",
      "0.009674247354269028\n",
      "0.011056543327867985\n",
      "0.008714912459254265\n",
      "0.009522037580609322\n",
      "0.010794674046337605\n",
      "0.009935669600963593\n",
      "0.0096943574026227\n",
      "0.010204430669546127\n",
      "0.011777308769524097\n",
      "0.010313430801033974\n",
      "0.01094677671790123\n",
      "0.009599290788173676\n",
      "0.009398928843438625\n",
      "0.010129939764738083\n",
      "0.010371362790465355\n",
      "0.010157683864235878\n",
      "0.010797309689223766\n",
      "0.01022326946258545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [23:28<28:02, 98.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8620557598039216\n",
      "验证集精度0.86875\n",
      "测试集精度0.846875\n",
      "0.010511296801269054\n",
      "0.011577026918530464\n",
      "0.010781724937260151\n",
      "0.011483399197459221\n",
      "0.010754677467048168\n",
      "0.01105432491749525\n",
      "0.01007887627929449\n",
      "0.010311642661690712\n",
      "0.010479173623025417\n",
      "0.01008798461407423\n",
      "0.010610301047563553\n",
      "0.010282540693879128\n",
      "0.009730709716677666\n",
      "0.010110421106219292\n",
      "0.011428499594330788\n",
      "0.01176548469811678\n",
      "0.008804172277450562\n",
      "0.010212554596364498\n",
      "0.010921810753643513\n",
      "0.012331528589129448\n",
      "0.010184218175709248\n",
      "0.010170204564929008\n",
      "0.00972056109458208\n",
      "0.010535449720919132\n",
      "0.010187762789428234\n",
      "0.00978474598377943\n",
      "0.010993225499987602\n",
      "0.009865264408290386\n",
      "0.010031825862824917\n",
      "0.010510860942304134\n",
      "0.010791626758873463\n",
      "0.011291862465441227\n",
      "0.011202347464859486\n",
      "0.011087063699960709\n",
      "0.009912088513374329\n",
      "0.009897472336888313\n",
      "0.010049630887806416\n",
      "0.01126012671738863\n",
      "0.009340768679976463\n",
      "0.010465024039149284\n",
      "0.009913762100040913\n",
      "0.009939970448613167\n",
      "0.010077977553009987\n",
      "0.009686904028058052\n",
      "0.009902690537273884\n",
      "0.011324655264616013\n",
      "0.011964691802859306\n",
      "0.010759307071566582\n",
      "0.011350763961672783\n",
      "0.00990099087357521\n",
      "0.010965255089104176\n",
      "0.011575103737413883\n",
      "0.009535667486488819\n",
      "0.009857120923697948\n",
      "0.011000577360391617\n",
      "0.010228125378489494\n",
      "0.010505781508982182\n",
      "0.010463206097483635\n",
      "0.011406556703150272\n",
      "0.010196899063885212\n",
      "0.009391299448907375\n",
      "0.010623187758028507\n",
      "0.010797939263284206\n",
      "0.010542778298258781\n",
      "0.009373175911605358\n",
      "0.011270390823483467\n",
      "0.009756437502801418\n",
      "0.010323396883904934\n",
      "0.009524083696305752\n",
      "0.009987701661884785\n",
      "0.01113868411630392\n",
      "0.010785127989947796\n",
      "0.010637586005032063\n",
      "0.009230835363268852\n",
      "0.011138269677758217\n",
      "0.010782929137349129\n",
      "0.010275466367602348\n",
      "0.010861324146389961\n",
      "0.010262059979140759\n",
      "0.010898682288825512\n",
      "0.010137390345335007\n",
      "0.010625284165143967\n",
      "0.010575678199529648\n",
      "0.009644935838878155\n",
      "0.011120368726551533\n",
      "0.011933463625609875\n",
      "0.010868323966860771\n",
      "0.009497115388512611\n",
      "0.010761691257357597\n",
      "0.011501383036375046\n",
      "0.011483377777040005\n",
      "0.009770509786903858\n",
      "0.010370451025664806\n",
      "0.009753716178238392\n",
      "0.010107144713401794\n",
      "0.010562446899712086\n",
      "0.011055384762585163\n",
      "0.00924037303775549\n",
      "0.009785901755094528\n",
      "0.009718528017401695\n",
      "0.010220417752861977\n",
      "0.009735917672514915\n",
      "0.010011373087763786\n",
      "0.010641107335686684\n",
      "0.01032237708568573\n",
      "0.010370093397796154\n",
      "0.01048099435865879\n",
      "0.01042878720909357\n",
      "0.010001006536185741\n",
      "0.010088945738971233\n",
      "0.010134575888514519\n",
      "0.010607611387968063\n",
      "0.010205177590250969\n",
      "0.010591897182166576\n",
      "0.010697559453547001\n",
      "0.010358264669775963\n",
      "0.011372542008757591\n",
      "0.010508541949093342\n",
      "0.00962873362004757\n",
      "0.009839756414294243\n",
      "0.00973503477871418\n",
      "0.010709506459534168\n",
      "0.011105726473033428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [25:23<27:41, 103.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8883272058823529\n",
      "验证集精度0.8984375\n",
      "测试集精度0.86875\n",
      "0.009832669049501419\n",
      "0.011077474802732468\n",
      "0.01047146413475275\n",
      "0.010618791915476322\n",
      "0.010634428821504116\n",
      "0.009489905089139938\n",
      "0.009285506792366505\n",
      "0.012059380300343037\n",
      "0.01082160510122776\n",
      "0.01086762361228466\n",
      "0.010564068332314491\n",
      "0.010390195064246655\n",
      "0.011292064562439919\n",
      "0.010121039114892483\n",
      "0.010874049738049507\n",
      "0.011530110612511635\n",
      "0.010126963257789612\n",
      "0.010904534719884396\n",
      "0.010228922590613365\n",
      "0.010189289227128029\n",
      "0.00949145294725895\n",
      "0.00958225131034851\n",
      "0.010316668078303337\n",
      "0.008950266055762768\n",
      "0.01003214530646801\n",
      "0.011227082461118698\n",
      "0.009984946809709072\n",
      "0.011789422482252121\n",
      "0.009899399243295193\n",
      "0.009570680558681488\n",
      "0.009577151387929916\n",
      "0.009704147465527058\n",
      "0.0116373710334301\n",
      "0.009228236973285675\n",
      "0.010172033682465553\n",
      "0.01010541245341301\n",
      "0.010260484181344509\n",
      "0.010340881533920765\n",
      "0.010635978542268276\n",
      "0.010681930929422379\n",
      "0.011587942019104958\n",
      "0.009744780138134956\n",
      "0.012068367563188076\n",
      "0.010242590680718422\n",
      "0.010893972590565681\n",
      "0.010061601176857948\n",
      "0.010381213389337063\n",
      "0.010503814555704594\n",
      "0.009770754724740982\n",
      "0.01056604366749525\n",
      "0.011478180065751076\n",
      "0.010464427061378956\n",
      "0.01079751830548048\n",
      "0.010207004845142365\n",
      "0.010428360663354397\n",
      "0.010112270712852478\n",
      "0.010701518505811691\n",
      "0.010271555744111538\n",
      "0.009513978846371174\n",
      "0.009612721391022205\n",
      "0.010323124937713146\n",
      "0.01032317616045475\n",
      "0.01025453582406044\n",
      "0.010135564021766186\n",
      "0.010093284770846367\n",
      "0.011265482753515244\n",
      "0.010398974642157555\n",
      "0.009780006483197212\n",
      "0.010799629613757133\n",
      "0.01012888178229332\n",
      "0.010657726787030697\n",
      "0.010464130900800228\n",
      "0.01094601396471262\n",
      "0.010320333763957024\n",
      "0.01051891129463911\n",
      "0.010033320635557175\n",
      "0.009463830851018429\n",
      "0.011146705597639084\n",
      "0.011047965846955776\n",
      "0.010386775247752666\n",
      "0.009911942295730114\n",
      "0.010307000949978828\n",
      "0.009962070733308792\n",
      "0.009550233371555805\n",
      "0.01034852396696806\n",
      "0.010630271397531033\n",
      "0.01028669998049736\n",
      "0.008811531588435173\n",
      "0.012475373223423958\n",
      "0.010681417770683765\n",
      "0.01138954795897007\n",
      "0.010091481730341911\n",
      "0.011635533533990383\n",
      "0.010334583930671215\n",
      "0.01027899980545044\n",
      "0.010196558199822903\n",
      "0.010259876027703285\n",
      "0.010060791857540607\n",
      "0.009769314900040627\n",
      "0.010327844880521297\n",
      "0.011393616907298565\n",
      "0.008852716535329819\n",
      "0.01038336381316185\n",
      "0.009967237710952759\n",
      "0.01049900520592928\n",
      "0.010583939962089062\n",
      "0.009130507707595825\n",
      "0.009996877983212471\n",
      "0.010813677683472633\n",
      "0.010460691526532173\n",
      "0.010638546198606491\n",
      "0.012058914639055729\n",
      "0.010554601438343525\n",
      "0.01058867760002613\n",
      "0.009621130302548409\n",
      "0.01080325897783041\n",
      "0.009443296119570732\n",
      "0.010360505431890488\n",
      "0.010200610384345055\n",
      "0.009158683940768242\n",
      "0.010885671712458134\n",
      "0.010712695308029652\n",
      "0.010555106215178967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [26:59<25:22, 101.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8741574754901961\n",
      "验证集精度0.8859375\n",
      "测试集精度0.8546875\n",
      "0.010053429752588272\n",
      "0.010945410467684269\n",
      "0.009300007484853268\n",
      "0.009254630655050278\n",
      "0.008600827306509018\n",
      "0.010129550471901894\n",
      "0.01041578408330679\n",
      "0.010150532238185406\n",
      "0.0105313491076231\n",
      "0.010445458814501762\n",
      "0.011572974734008312\n",
      "0.009897938929498196\n",
      "0.010758926160633564\n",
      "0.010380417108535767\n",
      "0.011195708066225052\n",
      "0.009698424488306046\n",
      "0.011232306249439716\n",
      "0.009944085963070393\n",
      "0.010712926276028156\n",
      "0.011303480714559555\n",
      "0.009781250730156898\n",
      "0.009562588296830654\n",
      "0.011222067289054394\n",
      "0.01065701525658369\n",
      "0.010652923956513405\n",
      "0.010052836500108242\n",
      "0.010601017624139786\n",
      "0.012007064186036587\n",
      "0.009575853124260902\n",
      "0.01152487751096487\n",
      "0.010277565568685532\n",
      "0.01156499795615673\n",
      "0.012538514100015163\n",
      "0.010857300832867622\n",
      "0.010599062778055668\n",
      "0.011080301366746426\n",
      "0.010173672810196877\n",
      "0.009462420828640461\n",
      "0.010212326422333717\n",
      "0.009854251518845558\n",
      "0.010718469507992268\n",
      "0.009380728006362915\n",
      "0.010720370337367058\n",
      "0.0095753138884902\n",
      "0.010544238612055779\n",
      "0.009477819316089153\n",
      "0.011436818167567253\n",
      "0.010662967339158058\n",
      "0.010717584751546383\n",
      "0.009654834866523743\n",
      "0.010577966459095478\n",
      "0.010794968344271183\n",
      "0.010873603634536266\n",
      "0.009671803563833237\n",
      "0.010836326517164707\n",
      "0.010973633266985416\n",
      "0.009901152923703194\n",
      "0.010715887881815434\n",
      "0.009821644984185696\n",
      "0.00987872015684843\n",
      "0.010405289940536022\n",
      "0.009763065725564957\n",
      "0.01051231101155281\n",
      "0.01173008605837822\n",
      "0.010090398602187634\n",
      "0.010458311066031456\n",
      "0.009898888878524303\n",
      "0.009909801185131073\n",
      "0.011220140382647514\n",
      "0.008938184939324856\n",
      "0.011717470362782478\n",
      "0.011009537614881992\n",
      "0.009206458926200867\n",
      "0.010449090041220188\n",
      "0.011072191409766674\n",
      "0.010438590310513973\n",
      "0.010457430966198444\n",
      "0.010280728340148926\n",
      "0.010815837420523167\n",
      "0.010680271312594414\n",
      "0.00942795630544424\n",
      "0.009418477304279804\n",
      "0.009346449747681618\n",
      "0.00918523408472538\n",
      "0.010503259487450123\n",
      "0.010105181485414505\n",
      "0.009849883615970612\n",
      "0.010092614218592644\n",
      "0.010673221200704575\n",
      "0.010138004086911678\n",
      "0.010393640957772732\n",
      "0.010099200531840324\n",
      "0.01110256090760231\n",
      "0.009248226881027222\n",
      "0.011195930652320385\n",
      "0.010059203021228313\n",
      "0.010766593739390373\n",
      "0.0103391632437706\n",
      "0.010585678741335869\n",
      "0.009921295568346977\n",
      "0.010271649807691574\n",
      "0.010177144780755043\n",
      "0.00916321575641632\n",
      "0.009844569489359856\n",
      "0.010915418155491352\n",
      "0.00996537134051323\n",
      "0.010614725761115551\n",
      "0.009803866036236286\n",
      "0.01024545542895794\n",
      "0.010644165799021721\n",
      "0.01096443459391594\n",
      "0.010953432880342007\n",
      "0.011561260558664799\n",
      "0.010076731443405151\n",
      "0.009330252185463905\n",
      "0.00987380649894476\n",
      "0.010759888216853142\n",
      "0.010465268976986408\n",
      "0.010886271484196186\n",
      "0.01103168074041605\n",
      "0.01106792502105236\n",
      "0.013016995042562485\n",
      "0.009180579334497452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [28:41<23:44, 101.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8642769607843137\n",
      "验证集精度0.8703125\n",
      "测试集精度0.8546875\n",
      "0.009073952212929726\n",
      "0.008769359439611435\n",
      "0.009740251116454601\n",
      "0.010385188274085522\n",
      "0.010226286016404629\n",
      "0.00955996848642826\n",
      "0.009295761585235596\n",
      "0.010519764386117458\n",
      "0.010987718589603901\n",
      "0.009410426020622253\n",
      "0.011733775027096272\n",
      "0.011757533997297287\n",
      "0.009591607376933098\n",
      "0.009950768202543259\n",
      "0.011214791797101498\n",
      "0.01069915946573019\n",
      "0.010159803554415703\n",
      "0.011205589398741722\n",
      "0.010188567452132702\n",
      "0.01116278674453497\n",
      "0.010704418644309044\n",
      "0.011723378673195839\n",
      "0.012081785127520561\n",
      "0.010757672600448132\n",
      "0.009827769361436367\n",
      "0.010973145253956318\n",
      "0.010331335477530956\n",
      "0.010388624854385853\n",
      "0.0103556327521801\n",
      "0.010399705730378628\n",
      "0.009762055240571499\n",
      "0.009661017917096615\n",
      "0.01063954271376133\n",
      "0.0096906628459692\n",
      "0.010030522011220455\n",
      "0.00881129503250122\n",
      "0.009270334616303444\n",
      "0.010528855957090855\n",
      "0.011821005493402481\n",
      "0.010114176198840141\n",
      "0.010145541280508041\n",
      "0.010191654786467552\n",
      "0.011085004545748234\n",
      "0.011243290267884731\n",
      "0.009730598889291286\n",
      "0.01088995672762394\n",
      "0.010220985859632492\n",
      "0.009475136175751686\n",
      "0.009963035583496094\n",
      "0.010241417214274406\n",
      "0.010651465505361557\n",
      "0.011917083524167538\n",
      "0.009571264497935772\n",
      "0.010312313213944435\n",
      "0.009591305628418922\n",
      "0.011422911658883095\n",
      "0.010904270224273205\n",
      "0.010270378552377224\n",
      "0.01179425697773695\n",
      "0.00983511470258236\n",
      "0.009648983366787434\n",
      "0.010989729315042496\n",
      "0.010269062593579292\n",
      "0.010404973290860653\n",
      "0.010972416959702969\n",
      "0.010723602026700974\n",
      "0.011563039384782314\n",
      "0.009550589136779308\n",
      "0.011225936003029346\n",
      "0.009904866106808186\n",
      "0.010575542226433754\n",
      "0.010212485678493977\n",
      "0.0111245634034276\n",
      "0.010045892558991909\n",
      "0.0114359799772501\n",
      "0.010190380737185478\n",
      "0.009588468819856644\n",
      "0.011316221207380295\n",
      "0.009360987693071365\n",
      "0.010466114617884159\n",
      "0.008944999426603317\n",
      "0.011089482344686985\n",
      "0.009859353303909302\n",
      "0.010054369457066059\n",
      "0.01084383949637413\n",
      "0.008755632676184177\n",
      "0.01010227669030428\n",
      "0.009617316536605358\n",
      "0.009946238249540329\n",
      "0.011731745675206184\n",
      "0.009573466144502163\n",
      "0.009449418634176254\n",
      "0.00988009199500084\n",
      "0.011327524669468403\n",
      "0.01046955119818449\n",
      "0.009210017509758472\n",
      "0.00983862578868866\n",
      "0.010834888555109501\n",
      "0.009627670049667358\n",
      "0.010199031792581081\n",
      "0.008696259930729866\n",
      "0.009551155380904675\n",
      "0.010190744884312153\n",
      "0.010457846336066723\n",
      "0.01071897242218256\n",
      "0.010123170912265778\n",
      "0.009251505136489868\n",
      "0.010648789815604687\n",
      "0.010884755291044712\n",
      "0.010705385357141495\n",
      "0.01066376082599163\n",
      "0.010137230157852173\n",
      "0.011313864961266518\n",
      "0.010692166164517403\n",
      "0.009971424005925655\n",
      "0.011312920600175858\n",
      "0.010015521198511124\n",
      "0.010316133499145508\n",
      "0.01108844019472599\n",
      "0.009920145384967327\n",
      "0.010745735839009285\n",
      "0.010983015410602093\n",
      "0.009650427848100662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [30:17<21:39, 99.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8780637254901961\n",
      "验证集精度0.88125\n",
      "测试集精度0.8671875\n",
      "0.008583614602684975\n",
      "0.010217869654297829\n",
      "0.009666148573160172\n",
      "0.009985989890992641\n",
      "0.010671411640942097\n",
      "0.010266122408211231\n",
      "0.01028301753103733\n",
      "0.009764154441654682\n",
      "0.010383970104157925\n",
      "0.010342496447265148\n",
      "0.010174822062253952\n",
      "0.009693610481917858\n",
      "0.011171911843121052\n",
      "0.010013272985816002\n",
      "0.011492879129946232\n",
      "0.0101563585922122\n",
      "0.011125901713967323\n",
      "0.011033667251467705\n",
      "0.00981412548571825\n",
      "0.010439968667924404\n",
      "0.010147174820303917\n",
      "0.01034524105489254\n",
      "0.010633827187120914\n",
      "0.01309741660952568\n",
      "0.008361960761249065\n",
      "0.009688188321888447\n",
      "0.010228509083390236\n",
      "0.010140052996575832\n",
      "0.01033286564052105\n",
      "0.010347062721848488\n",
      "0.010743885301053524\n",
      "0.01059798989444971\n",
      "0.011476878076791763\n",
      "0.009618564508855343\n",
      "0.010751367546617985\n",
      "0.010715288110077381\n",
      "0.009798765182495117\n",
      "0.010379085317254066\n",
      "0.009869529865682125\n",
      "0.010964355431497097\n",
      "0.010797780007123947\n",
      "0.010383165441453457\n",
      "0.00981057807803154\n",
      "0.012133627198636532\n",
      "0.009771867655217648\n",
      "0.009334600530564785\n",
      "0.010692590847611427\n",
      "0.010174408555030823\n",
      "0.011454596184194088\n",
      "0.010829376988112926\n",
      "0.010696614161133766\n",
      "0.0094454912468791\n",
      "0.010052389465272427\n",
      "0.009357157163321972\n",
      "0.01032167486846447\n",
      "0.010482406243681908\n",
      "0.010521487332880497\n",
      "0.010357188992202282\n",
      "0.008334064856171608\n",
      "0.009975023567676544\n",
      "0.009311157278716564\n",
      "0.010305074974894524\n",
      "0.008823774755001068\n",
      "0.011387426406145096\n",
      "0.010507117956876755\n",
      "0.011140668764710426\n",
      "0.009256109595298767\n",
      "0.01082413736730814\n",
      "0.01004352979362011\n",
      "0.009805375710129738\n",
      "0.010733311995863914\n",
      "0.009643387980759144\n",
      "0.009994249790906906\n",
      "0.012146984227001667\n",
      "0.009525712579488754\n",
      "0.011704158037900925\n",
      "0.009862497448921204\n",
      "0.00994550995528698\n",
      "0.009917338378727436\n",
      "0.010257618501782417\n",
      "0.01128904614597559\n",
      "0.00936338771134615\n",
      "0.0106769148260355\n",
      "0.010622263886034489\n",
      "0.0105807576328516\n",
      "0.012055610306560993\n",
      "0.010913779959082603\n",
      "0.010049531236290932\n",
      "0.010681605897843838\n",
      "0.01065152045339346\n",
      "0.01009414903819561\n",
      "0.011327396146953106\n",
      "0.010562405921518803\n",
      "0.009735650382936\n",
      "0.009424193762242794\n",
      "0.010116039775311947\n",
      "0.008521445095539093\n",
      "0.011538461782038212\n",
      "0.00944477692246437\n",
      "0.009647822938859463\n",
      "0.010041926987469196\n",
      "0.010240991599857807\n",
      "0.010614649392664433\n",
      "0.01048786100000143\n",
      "0.011838200502097607\n",
      "0.011579984799027443\n",
      "0.011497722007334232\n",
      "0.011574465781450272\n",
      "0.009491393342614174\n",
      "0.011079108342528343\n",
      "0.010128449648618698\n",
      "0.01066003367304802\n",
      "0.009519538842141628\n",
      "0.010530253872275352\n",
      "0.010332874022424221\n",
      "0.011677720583975315\n",
      "0.01024696510285139\n",
      "0.008776908740401268\n",
      "0.010757606476545334\n",
      "0.011320636607706547\n",
      "0.009588539600372314\n",
      "0.01078915037214756\n",
      "0.011133653111755848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [32:03<20:22, 101.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8814338235294118\n",
      "验证集精度0.9015625\n",
      "测试集精度0.859375\n",
      "0.010548604652285576\n",
      "0.009463239461183548\n",
      "0.010432439856231213\n",
      "0.009034563787281513\n",
      "0.011573749594390392\n",
      "0.009958261623978615\n",
      "0.01129157654941082\n",
      "0.00967482291162014\n",
      "0.010384555906057358\n",
      "0.00930815190076828\n",
      "0.011083308607339859\n",
      "0.01184543501585722\n",
      "0.011434546671807766\n",
      "0.010442594066262245\n",
      "0.010474967770278454\n",
      "0.01066630519926548\n",
      "0.009738629683852196\n",
      "0.011147118173539639\n",
      "0.010111728683114052\n",
      "0.011217941530048847\n",
      "0.009303825907409191\n",
      "0.010473249480128288\n",
      "0.009059902280569077\n",
      "0.011706165038049221\n",
      "0.011363621801137924\n",
      "0.009193961508572102\n",
      "0.010762783698737621\n",
      "0.007930636405944824\n",
      "0.009187418036162853\n",
      "0.01005387119948864\n",
      "0.010152299888432026\n",
      "0.010853258892893791\n",
      "0.009691135957837105\n",
      "0.010468204505741596\n",
      "0.010978024452924728\n",
      "0.010439572855830193\n",
      "0.009878687560558319\n",
      "0.009796341881155968\n",
      "0.010232679545879364\n",
      "0.010045669041574001\n",
      "0.011147205717861652\n",
      "0.011337515898048878\n",
      "0.01028076559305191\n",
      "0.009594862349331379\n",
      "0.009385272860527039\n",
      "0.010117392055690289\n",
      "0.010244677774608135\n",
      "0.010789167135953903\n",
      "0.010503816418349743\n",
      "0.00898175872862339\n",
      "0.01087149791419506\n",
      "0.010886412113904953\n",
      "0.009577600285410881\n",
      "0.010870072990655899\n",
      "0.009633692912757397\n",
      "0.01102297380566597\n",
      "0.009533762000501156\n",
      "0.009820436127483845\n",
      "0.011209995485842228\n",
      "0.010402556508779526\n",
      "0.009812593460083008\n",
      "0.00998456310480833\n",
      "0.011690736748278141\n",
      "0.012112830765545368\n",
      "0.009977479465305805\n",
      "0.010004473850131035\n",
      "0.00968028511852026\n",
      "0.009917420335114002\n",
      "0.010444019921123981\n",
      "0.008901882916688919\n",
      "0.011088266037404537\n",
      "0.010496500879526138\n",
      "0.011194190941751003\n",
      "0.010752780362963676\n",
      "0.01073966734111309\n",
      "0.00995023176074028\n",
      "0.01056529302150011\n",
      "0.009720089845359325\n",
      "0.010759825818240643\n",
      "0.010293846018612385\n",
      "0.009978015907108784\n",
      "0.009743306785821915\n",
      "0.009018545038998127\n",
      "0.010145110078155994\n",
      "0.00953502394258976\n",
      "0.009725202806293964\n",
      "0.009462139569222927\n",
      "0.01174099836498499\n",
      "0.009516648948192596\n",
      "0.010979820974171162\n",
      "0.01043976005166769\n",
      "0.010609576478600502\n",
      "0.009495539590716362\n",
      "0.010757427662611008\n",
      "0.009855613112449646\n",
      "0.010334011167287827\n",
      "0.010222231037914753\n",
      "0.00997703243046999\n",
      "0.010158633813261986\n",
      "0.011886151507496834\n",
      "0.01153385080397129\n",
      "0.01075576152652502\n",
      "0.010578881949186325\n",
      "0.011295325122773647\n",
      "0.011393816210329533\n",
      "0.01032202411442995\n",
      "0.009934086352586746\n",
      "0.010263709351420403\n",
      "0.011409427970647812\n",
      "0.009367323480546474\n",
      "0.009232843294739723\n",
      "0.01103503629565239\n",
      "0.010153505019843578\n",
      "0.010085951536893845\n",
      "0.01038154773414135\n",
      "0.009426400065422058\n",
      "0.011643950827419758\n",
      "0.011056981049478054\n",
      "0.011027202941477299\n",
      "0.010211631655693054\n",
      "0.011313023045659065\n",
      "0.0107633201405406\n",
      "0.00928513240069151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [33:59<19:26, 106.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8803615196078431\n",
      "验证集精度0.896875\n",
      "测试集精度0.8703125\n",
      "0.011599194258451462\n",
      "0.010749530047178268\n",
      "0.010833848267793655\n",
      "0.011877967976033688\n",
      "0.009947900660336018\n",
      "0.010819414630532265\n",
      "0.009837238118052483\n",
      "0.00938434898853302\n",
      "0.011066997423768044\n",
      "0.01019996590912342\n",
      "0.010779759846627712\n",
      "0.009045585058629513\n",
      "0.010084550827741623\n",
      "0.010311645455658436\n",
      "0.010775428265333176\n",
      "0.009105744771659374\n",
      "0.009775897487998009\n",
      "0.010016520507633686\n",
      "0.010392667725682259\n",
      "0.010071411728858948\n",
      "0.01210075244307518\n",
      "0.009532427415251732\n",
      "0.010480651631951332\n",
      "0.010368610732257366\n",
      "0.010477217845618725\n",
      "0.010613489896059036\n",
      "0.009408093988895416\n",
      "0.008749416097998619\n",
      "0.010524166747927666\n",
      "0.01005870383232832\n",
      "0.01063865702599287\n",
      "0.010672950185835361\n",
      "0.010616263374686241\n",
      "0.010890251956880093\n",
      "0.010864678770303726\n",
      "0.010170198045670986\n",
      "0.010839497670531273\n",
      "0.010365709662437439\n",
      "0.010095387697219849\n",
      "0.0102772181853652\n",
      "0.010959433391690254\n",
      "0.010094552300870419\n",
      "0.010198943316936493\n",
      "0.011725624091923237\n",
      "0.011324075050652027\n",
      "0.01013252604752779\n",
      "0.011891267262399197\n",
      "0.010040555149316788\n",
      "0.010487881489098072\n",
      "0.0109874177724123\n",
      "0.010198824107646942\n",
      "0.010415076278150082\n",
      "0.009159240871667862\n",
      "0.010664691217243671\n",
      "0.010306808166205883\n",
      "0.01047781016677618\n",
      "0.008400779217481613\n",
      "0.010171322152018547\n",
      "0.010470842011272907\n",
      "0.009714965708553791\n",
      "0.010131178423762321\n",
      "0.009641168639063835\n",
      "0.01085568591952324\n",
      "0.009741198271512985\n",
      "0.011078511364758015\n",
      "0.011035523377358913\n",
      "0.011919019743800163\n",
      "0.009373324923217297\n",
      "0.010244998149573803\n",
      "0.01097839791327715\n",
      "0.011174985207617283\n",
      "0.009102222509682178\n",
      "0.010638407431542873\n",
      "0.011175226420164108\n",
      "0.009191224351525307\n",
      "0.011828465387225151\n",
      "0.00882656592875719\n",
      "0.009497938677668571\n",
      "0.009355423972010612\n",
      "0.009327913634479046\n",
      "0.009708038531243801\n",
      "0.009288127534091473\n",
      "0.009977377951145172\n",
      "0.0106304120272398\n",
      "0.008955865167081356\n",
      "0.01050210278481245\n",
      "0.010162877850234509\n",
      "0.010982752777636051\n",
      "0.008912941440939903\n",
      "0.009546827524900436\n",
      "0.011604290455579758\n",
      "0.009488227777183056\n",
      "0.009692588821053505\n",
      "0.010606059804558754\n",
      "0.011097831651568413\n",
      "0.010055407881736755\n",
      "0.010321895591914654\n",
      "0.010103151202201843\n",
      "0.00883137620985508\n",
      "0.011121290735900402\n",
      "0.009906013496220112\n",
      "0.010553686879575253\n",
      "0.010234001092612743\n",
      "0.00981074571609497\n",
      "0.010340205393731594\n",
      "0.010386595502495766\n",
      "0.01135424617677927\n",
      "0.011240274645388126\n",
      "0.010715316981077194\n",
      "0.011461657471954823\n",
      "0.009641116484999657\n",
      "0.01074345875531435\n",
      "0.009461437352001667\n",
      "0.010528967715799809\n",
      "0.01123600360006094\n",
      "0.010375110432505608\n",
      "0.01112306211143732\n",
      "0.009736480191349983\n",
      "0.010992499999701977\n",
      "0.010104270651936531\n",
      "0.010631154291331768\n",
      "0.009875589981675148\n",
      "0.011155636049807072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [35:33<17:04, 102.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8894761029411765\n",
      "验证集精度0.8875\n",
      "测试集精度0.86875\n",
      "0.009496410377323627\n",
      "0.010481479577720165\n",
      "0.010343438014388084\n",
      "0.010451116599142551\n",
      "0.01170555129647255\n",
      "0.010542088188230991\n",
      "0.011379499919712543\n",
      "0.011096058413386345\n",
      "0.010547850281000137\n",
      "0.009822245687246323\n",
      "0.011873336508870125\n",
      "0.009337862022221088\n",
      "0.010241907089948654\n",
      "0.011509472504258156\n",
      "0.009550314396619797\n",
      "0.010317051783204079\n",
      "0.010697690770030022\n",
      "0.009748818352818489\n",
      "0.010497968643903732\n",
      "0.009589283727109432\n",
      "0.01041458360850811\n",
      "0.010529072023928165\n",
      "0.010304316878318787\n",
      "0.010466216132044792\n",
      "0.009820574894547462\n",
      "0.010452226735651493\n",
      "0.009650756604969501\n",
      "0.00987208541482687\n",
      "0.01005290262401104\n",
      "0.00977382529526949\n",
      "0.009531376883387566\n",
      "0.010282044298946857\n",
      "0.010032599791884422\n",
      "0.010310648009181023\n",
      "0.009018219076097012\n",
      "0.009299363940954208\n",
      "0.01140561792999506\n",
      "0.010107642970979214\n",
      "0.009575865231454372\n",
      "0.009686052799224854\n",
      "0.010116062127053738\n",
      "0.010750417597591877\n",
      "0.009064268320798874\n",
      "0.009979228489100933\n",
      "0.009393666870892048\n",
      "0.010877983644604683\n",
      "0.009804187342524529\n",
      "0.009530702605843544\n",
      "0.00889982283115387\n",
      "0.011828569695353508\n",
      "0.009589253924787045\n",
      "0.010727941058576107\n",
      "0.01016982365399599\n",
      "0.00892072357237339\n",
      "0.009094711393117905\n",
      "0.010571684688329697\n",
      "0.00995925348252058\n",
      "0.009448467753827572\n",
      "0.009920518845319748\n",
      "0.010612390004098415\n",
      "0.011040114797651768\n",
      "0.010994475334882736\n",
      "0.010496001690626144\n",
      "0.010788002982735634\n",
      "0.011952145025134087\n",
      "0.009489687159657478\n",
      "0.011535256169736385\n",
      "0.010113254189491272\n",
      "0.0107813635841012\n",
      "0.010921308770775795\n",
      "0.010498245246708393\n",
      "0.009599213488399982\n",
      "0.010392601601779461\n",
      "0.009525499306619167\n",
      "0.010603467933833599\n",
      "0.009385112673044205\n",
      "0.009660725481808186\n",
      "0.011522923596203327\n",
      "0.011292030103504658\n",
      "0.010229586623609066\n",
      "0.010550100356340408\n",
      "0.009793040342628956\n",
      "0.010028948076069355\n",
      "0.010230663232505322\n",
      "0.010745528154075146\n",
      "0.011228610761463642\n",
      "0.010087196715176105\n",
      "0.009483367204666138\n",
      "0.010441062971949577\n",
      "0.010983112268149853\n",
      "0.010359412059187889\n",
      "0.01014535129070282\n",
      "0.009263262152671814\n",
      "0.010110911913216114\n",
      "0.011583671905100346\n",
      "0.009520214982330799\n",
      "0.009981760755181313\n",
      "0.011174787767231464\n",
      "0.01148601807653904\n",
      "0.010459604673087597\n",
      "0.01011719275265932\n",
      "0.010415509343147278\n",
      "0.011105178855359554\n",
      "0.01076514646410942\n",
      "0.009781597182154655\n",
      "0.011243250221014023\n",
      "0.010013456456363201\n",
      "0.009332256391644478\n",
      "0.009606797248125076\n",
      "0.01117843296378851\n",
      "0.00932709313929081\n",
      "0.010102261789143085\n",
      "0.010629062540829182\n",
      "0.00983454566448927\n",
      "0.009788875468075275\n",
      "0.010469871573150158\n",
      "0.01075748447328806\n",
      "0.010122165083885193\n",
      "0.009516045451164246\n",
      "0.010050944052636623\n",
      "0.011411885730922222\n",
      "0.009332602843642235\n",
      "0.009163024835288525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [37:05<14:53, 99.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8761488970588235\n",
      "验证集精度0.88125\n",
      "测试集精度0.86875\n",
      "0.011226928792893887\n",
      "0.011091220192611217\n",
      "0.009890755638480186\n",
      "0.009699776768684387\n",
      "0.009778427891433239\n",
      "0.010924953036010265\n",
      "0.010670225135982037\n",
      "0.010663690976798534\n",
      "0.010233374312520027\n",
      "0.01041176076978445\n",
      "0.01086872536689043\n",
      "0.010083409026265144\n",
      "0.01012708805501461\n",
      "0.010230747051537037\n",
      "0.010337102226912975\n",
      "0.010975110344588757\n",
      "0.011019105091691017\n",
      "0.010377569124102592\n",
      "0.011034037917852402\n",
      "0.010202070698142052\n",
      "0.010001404210925102\n",
      "0.010573395527899265\n",
      "0.010383282788097858\n",
      "0.010507161729037762\n",
      "0.00910712406039238\n",
      "0.01079135574400425\n",
      "0.010780224576592445\n",
      "0.009188566356897354\n",
      "0.010252400301396847\n",
      "0.009587563574314117\n",
      "0.011165221221745014\n",
      "0.008936208672821522\n",
      "0.010997430421411991\n",
      "0.010354212485253811\n",
      "0.010812921449542046\n",
      "0.010414345189929008\n",
      "0.010119656100869179\n",
      "0.011179749853909016\n",
      "0.010210439562797546\n",
      "0.01021563820540905\n",
      "0.010574148036539555\n",
      "0.00987370777875185\n",
      "0.010597760789096355\n",
      "0.010126537643373013\n",
      "0.009833193384110928\n",
      "0.012091939337551594\n",
      "0.010934988968074322\n",
      "0.010204563848674297\n",
      "0.00953234639018774\n",
      "0.011977761052548885\n",
      "0.010198365896940231\n",
      "0.009831502102315426\n",
      "0.009940107353031635\n",
      "0.009244825690984726\n",
      "0.010366477072238922\n",
      "0.01070922240614891\n",
      "0.009947547689080238\n",
      "0.008933218196034431\n",
      "0.011272381991147995\n",
      "0.010350021533668041\n",
      "0.010413325391709805\n",
      "0.010566256009042263\n",
      "0.009324749000370502\n",
      "0.010982380248606205\n",
      "0.010383334010839462\n",
      "0.01051823329180479\n",
      "0.011114818975329399\n",
      "0.01032550260424614\n",
      "0.011020378209650517\n",
      "0.01033043023198843\n",
      "0.010226232931017876\n",
      "0.011014140211045742\n",
      "0.011490995064377785\n",
      "0.009722815826535225\n",
      "0.010750806890428066\n",
      "0.009437796659767628\n",
      "0.010869352146983147\n",
      "0.010369285009801388\n",
      "0.010916893370449543\n",
      "0.009351132437586784\n",
      "0.009873111732304096\n",
      "0.00979330763220787\n",
      "0.009841551072895527\n",
      "0.009926828555762768\n",
      "0.010944447480142117\n",
      "0.010529794730246067\n",
      "0.008808709681034088\n",
      "0.01102221105247736\n",
      "0.010177909396588802\n",
      "0.008844999596476555\n",
      "0.009873118251562119\n",
      "0.009450753219425678\n",
      "0.009401854127645493\n",
      "0.010291731916368008\n",
      "0.009603983722627163\n",
      "0.01039657648652792\n",
      "0.00925609190016985\n",
      "0.010958722792565823\n",
      "0.010388517752289772\n",
      "0.010614732280373573\n",
      "0.010776775889098644\n",
      "0.010100136511027813\n",
      "0.01055415254086256\n",
      "0.01002356968820095\n",
      "0.009640864096581936\n",
      "0.009525512345135212\n",
      "0.009447647258639336\n",
      "0.010137194767594337\n",
      "0.009809238836169243\n",
      "0.00980027299374342\n",
      "0.009012565016746521\n",
      "0.010693137533962727\n",
      "0.01116667315363884\n",
      "0.010209022089838982\n",
      "0.01041810866445303\n",
      "0.009065902791917324\n",
      "0.011529689654707909\n",
      "0.011393868364393711\n",
      "0.009794555604457855\n",
      "0.009485661052167416\n",
      "0.011536341160535812\n",
      "0.010118587873876095\n",
      "0.00950878020375967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [38:47<13:21, 100.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8903952205882353\n",
      "验证集精度0.9046875\n",
      "测试集精度0.86875\n",
      "0.011054063215851784\n",
      "0.010446508415043354\n",
      "0.009371642023324966\n",
      "0.009621239267289639\n",
      "0.011269772425293922\n",
      "0.010714631527662277\n",
      "0.00985806342214346\n",
      "0.010872283950448036\n",
      "0.010385164991021156\n",
      "0.00984923355281353\n",
      "0.010438001714646816\n",
      "0.010125654749572277\n",
      "0.009623244404792786\n",
      "0.010892770253121853\n",
      "0.009941304102540016\n",
      "0.01017578411847353\n",
      "0.011194068938493729\n",
      "0.011166990734636784\n",
      "0.009190578944981098\n",
      "0.011376670561730862\n",
      "0.010097677819430828\n",
      "0.010651071555912495\n",
      "0.010247522965073586\n",
      "0.009347017854452133\n",
      "0.010759779252111912\n",
      "0.01170263160020113\n",
      "0.00988439004868269\n",
      "0.011007162742316723\n",
      "0.010504243895411491\n",
      "0.009098827838897705\n",
      "0.011434407904744148\n",
      "0.010927113704383373\n",
      "0.00945289433002472\n",
      "0.010331006720662117\n",
      "0.00891908723860979\n",
      "0.009311359375715256\n",
      "0.010990390554070473\n",
      "0.009763737209141254\n",
      "0.009677504189312458\n",
      "0.009768682532012463\n",
      "0.009800723753869534\n",
      "0.01050157006829977\n",
      "0.011327367275953293\n",
      "0.009813502430915833\n",
      "0.010880488902330399\n",
      "0.010281390510499477\n",
      "0.010923581197857857\n",
      "0.010936509817838669\n",
      "0.01068214699625969\n",
      "0.010910539887845516\n",
      "0.010491399094462395\n",
      "0.010231769643723965\n",
      "0.00984992552548647\n",
      "0.010732250288128853\n",
      "0.009637860581278801\n",
      "0.010382388718426228\n",
      "0.010051954537630081\n",
      "0.00971183180809021\n",
      "0.010331484489142895\n",
      "0.009763006120920181\n",
      "0.01023690402507782\n",
      "0.009024735540151596\n",
      "0.009698059409856796\n",
      "0.010113773867487907\n",
      "0.009827322326600552\n",
      "0.01089419238269329\n",
      "0.010643880814313889\n",
      "0.010184913873672485\n",
      "0.010862668044865131\n",
      "0.011703964322805405\n",
      "0.009321733377873898\n",
      "0.011099412105977535\n",
      "0.010222893208265305\n",
      "0.010734666138887405\n",
      "0.010396663099527359\n",
      "0.009930932894349098\n",
      "0.00956246629357338\n",
      "0.00962061807513237\n",
      "0.010180795565247536\n",
      "0.010733406990766525\n",
      "0.008839095011353493\n",
      "0.010660136118531227\n",
      "0.010700090788304806\n",
      "0.011586396023631096\n",
      "0.01109500601887703\n",
      "0.010509134270250797\n",
      "0.010540289804339409\n",
      "0.008755541406571865\n",
      "0.010537276044487953\n",
      "0.010633504949510098\n",
      "0.01024975348263979\n",
      "0.010762011632323265\n",
      "0.012243005447089672\n",
      "0.00932152196764946\n",
      "0.008817758411169052\n",
      "0.010870734229683876\n",
      "0.010176816955208778\n",
      "0.010422991588711739\n",
      "0.009904039092361927\n",
      "0.009968772530555725\n",
      "0.011392248794436455\n",
      "0.011261451989412308\n",
      "0.009802471846342087\n",
      "0.009654194116592407\n",
      "0.00936049409210682\n",
      "0.010972592048346996\n",
      "0.011393881402909756\n",
      "0.009904257021844387\n",
      "0.010483912192285061\n",
      "0.010922872461378574\n",
      "0.010461771860718727\n",
      "0.009488667361438274\n",
      "0.008847473189234734\n",
      "0.01006659772247076\n",
      "0.011270878836512566\n",
      "0.00973698403686285\n",
      "0.009269719943404198\n",
      "0.009941522032022476\n",
      "0.009068286046385765\n",
      "0.009564969688653946\n",
      "0.0103472750633955\n",
      "0.011398499831557274\n",
      "0.010353599674999714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [40:29<11:45, 100.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8952205882352942\n",
      "验证集精度0.90625\n",
      "测试集精度0.884375\n",
      "0.010327284224331379\n",
      "0.011092028580605984\n",
      "0.010500390082597733\n",
      "0.008335083723068237\n",
      "0.009930530562996864\n",
      "0.011969790793955326\n",
      "0.010425476357340813\n",
      "0.010362181812524796\n",
      "0.009914732538163662\n",
      "0.010284717194736004\n",
      "0.010840563103556633\n",
      "0.009853510186076164\n",
      "0.009748855605721474\n",
      "0.010262591764330864\n",
      "0.010012349113821983\n",
      "0.0115234749391675\n",
      "0.011247571557760239\n",
      "0.010950280353426933\n",
      "0.012007228098809719\n",
      "0.010028187185525894\n",
      "0.01096969936043024\n",
      "0.009461660869419575\n",
      "0.010744723491370678\n",
      "0.010672560892999172\n",
      "0.010325983166694641\n",
      "0.00997269805520773\n",
      "0.009429298341274261\n",
      "0.010564999654889107\n",
      "0.01013102289289236\n",
      "0.011476404033601284\n",
      "0.011248639784753323\n",
      "0.009111043065786362\n",
      "0.008808638900518417\n",
      "0.010318335145711899\n",
      "0.008915749378502369\n",
      "0.011246412061154842\n",
      "0.01064680889248848\n",
      "0.009504011832177639\n",
      "0.009409639984369278\n",
      "0.010569754056632519\n",
      "0.009641358628869057\n",
      "0.011287878267467022\n",
      "0.011424077674746513\n",
      "0.008495462127029896\n",
      "0.009514321573078632\n",
      "0.009076004847884178\n",
      "0.009545702487230301\n",
      "0.009548990055918694\n",
      "0.010790158994495869\n",
      "0.011551326140761375\n",
      "0.010475192219018936\n",
      "0.01107223890721798\n",
      "0.010458271950483322\n",
      "0.01072145439684391\n",
      "0.009230940602719784\n",
      "0.00942426547408104\n",
      "0.0096050463616848\n",
      "0.010305285453796387\n",
      "0.009724177420139313\n",
      "0.009121287614107132\n",
      "0.01133322436362505\n",
      "0.01174797210842371\n",
      "0.010245606303215027\n",
      "0.010260220617055893\n",
      "0.011043274775147438\n",
      "0.010522379539906979\n",
      "0.008950704708695412\n",
      "0.010541783645749092\n",
      "0.010681857354938984\n",
      "0.010159541852772236\n",
      "0.010907302610576153\n",
      "0.010034674778580666\n",
      "0.01066785492002964\n",
      "0.0099937804043293\n",
      "0.010652776807546616\n",
      "0.009748796001076698\n",
      "0.009238984435796738\n",
      "0.009720128029584885\n",
      "0.009468483738601208\n",
      "0.010344046168029308\n",
      "0.009802763350307941\n",
      "0.010026689618825912\n",
      "0.009829381480813026\n",
      "0.009394451044499874\n",
      "0.010267752222716808\n",
      "0.010396863333880901\n",
      "0.00974102970212698\n",
      "0.009848710149526596\n",
      "0.009749623015522957\n",
      "0.010845855809748173\n",
      "0.01033020205795765\n",
      "0.010073189623653889\n",
      "0.010679797269403934\n",
      "0.009281891398131847\n",
      "0.010055114515125751\n",
      "0.010389151982963085\n",
      "0.011608059518039227\n",
      "0.00995166227221489\n",
      "0.009833700954914093\n",
      "0.010530097410082817\n",
      "0.008586117997765541\n",
      "0.009888398461043835\n",
      "0.009992538020014763\n",
      "0.010061949491500854\n",
      "0.011041377671062946\n",
      "0.00908755324780941\n",
      "0.010476053692400455\n",
      "0.009591421112418175\n",
      "0.010257367976009846\n",
      "0.01048385538160801\n",
      "0.009748679585754871\n",
      "0.011546825058758259\n",
      "0.010373758152127266\n",
      "0.010287625715136528\n",
      "0.01006710808724165\n",
      "0.010686920955777168\n",
      "0.010481534525752068\n",
      "0.010546347126364708\n",
      "0.010005563497543335\n",
      "0.010297590866684914\n",
      "0.009491944685578346\n",
      "0.009267551824450493\n",
      "0.011071708053350449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [42:07<09:59, 99.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8864889705882353\n",
      "验证集精度0.890625\n",
      "测试集精度0.8765625\n",
      "0.010326053015887737\n",
      "0.010653960518538952\n",
      "0.010154115036129951\n",
      "0.011073639616370201\n",
      "0.010127383284270763\n",
      "0.010200286284089088\n",
      "0.009519587270915508\n",
      "0.009814557619392872\n",
      "0.01139699388295412\n",
      "0.010197608731687069\n",
      "0.01088059600442648\n",
      "0.010646111331880093\n",
      "0.010402936488389969\n",
      "0.010264039039611816\n",
      "0.01033503096550703\n",
      "0.009956172667443752\n",
      "0.01036516111344099\n",
      "0.010495541617274284\n",
      "0.009983761236071587\n",
      "0.010142963379621506\n",
      "0.0108590517193079\n",
      "0.010456649586558342\n",
      "0.010271301493048668\n",
      "0.009115156717598438\n",
      "0.010903524234890938\n",
      "0.009682703763246536\n",
      "0.010887781158089638\n",
      "0.010698423720896244\n",
      "0.011647586710751057\n",
      "0.009339823387563229\n",
      "0.011888482607901096\n",
      "0.010352126322686672\n",
      "0.008920266292989254\n",
      "0.01046071108430624\n",
      "0.010740756057202816\n",
      "0.01007184199988842\n",
      "0.009736595675349236\n",
      "0.009803345426917076\n",
      "0.009294955059885979\n",
      "0.00945285428315401\n",
      "0.00942918285727501\n",
      "0.00997355580329895\n",
      "0.010618169791996479\n",
      "0.010310638695955276\n",
      "0.010014886036515236\n",
      "0.008953779004514217\n",
      "0.010396457277238369\n",
      "0.009896489791572094\n",
      "0.00936664454638958\n",
      "0.00874257367104292\n",
      "0.010702559724450111\n",
      "0.009645220823585987\n",
      "0.010905894450843334\n",
      "0.010309843346476555\n",
      "0.009371679276227951\n",
      "0.009284170344471931\n",
      "0.011000341735780239\n",
      "0.01025913655757904\n",
      "0.010100826621055603\n",
      "0.010196767747402191\n",
      "0.011438170447945595\n",
      "0.009155608713626862\n",
      "0.008932000026106834\n",
      "0.009854978881776333\n",
      "0.009532973170280457\n",
      "0.00967860035598278\n",
      "0.010714580304920673\n",
      "0.011437111534178257\n",
      "0.010505766607820988\n",
      "0.011135333217680454\n",
      "0.00965992733836174\n",
      "0.009701509028673172\n",
      "0.010610071942210197\n",
      "0.009704184718430042\n",
      "0.00877815205603838\n",
      "0.0115734301507473\n",
      "0.010019991546869278\n",
      "0.010304111056029797\n",
      "0.009042990393936634\n",
      "0.010254030115902424\n",
      "0.010160147212445736\n",
      "0.011323810555040836\n",
      "0.010611316189169884\n",
      "0.009619553573429585\n",
      "0.009420267306268215\n",
      "0.010355058126151562\n",
      "0.010920106433331966\n",
      "0.009943781420588493\n",
      "0.010653841309249401\n",
      "0.009647512808442116\n",
      "0.010176096111536026\n",
      "0.010510100051760674\n",
      "0.009562614373862743\n",
      "0.01017245277762413\n",
      "0.009769462049007416\n",
      "0.010829279199242592\n",
      "0.009750938974320889\n",
      "0.010554533451795578\n",
      "0.010158521123230457\n",
      "0.00927008967846632\n",
      "0.009385943412780762\n",
      "0.010191382840275764\n",
      "0.009771722368896008\n",
      "0.008785826154053211\n",
      "0.009859498590230942\n",
      "0.00990215502679348\n",
      "0.01042664609849453\n",
      "0.009489129297435284\n",
      "0.010407134890556335\n",
      "0.010302749462425709\n",
      "0.011367576196789742\n",
      "0.009818971157073975\n",
      "0.01044966746121645\n",
      "0.010535783134400845\n",
      "0.010915730148553848\n",
      "0.01005641557276249\n",
      "0.008965669199824333\n",
      "0.009273448958992958\n",
      "0.010411515831947327\n",
      "0.010280342772603035\n",
      "0.011032583191990852\n",
      "0.01160217635333538\n",
      "0.009571182541549206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [43:45<08:17, 99.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8929993872549019\n",
      "验证集精度0.9\n",
      "测试集精度0.8859375\n",
      "0.010247524827718735\n",
      "0.010652716271579266\n",
      "0.010209030471742153\n",
      "0.010534572415053844\n",
      "0.011297841556370258\n",
      "0.010164986364543438\n",
      "0.011349586769938469\n",
      "0.010213767178356647\n",
      "0.010108044371008873\n",
      "0.009955404326319695\n",
      "0.009820697829127312\n",
      "0.009026936255395412\n",
      "0.009113539941608906\n",
      "0.009046480059623718\n",
      "0.009739948436617851\n",
      "0.009647009894251823\n",
      "0.011408057995140553\n",
      "0.010428878478705883\n",
      "0.010541582480072975\n",
      "0.009417569264769554\n",
      "0.011424604803323746\n",
      "0.011136136017739773\n",
      "0.008783131837844849\n",
      "0.009628626517951488\n",
      "0.008910538628697395\n",
      "0.010574506595730782\n",
      "0.01030714437365532\n",
      "0.00973014160990715\n",
      "0.009321391582489014\n",
      "0.009279715828597546\n",
      "0.01035264041274786\n",
      "0.009123268537223339\n",
      "0.010136407800018787\n",
      "0.010127861984074116\n",
      "0.010060729458928108\n",
      "0.009872624650597572\n",
      "0.00921107642352581\n",
      "0.010042141191661358\n",
      "0.011721977964043617\n",
      "0.009682867676019669\n",
      "0.009576580487191677\n",
      "0.011178633198142052\n",
      "0.00993590708822012\n",
      "0.01002941932529211\n",
      "0.010149619542062283\n",
      "0.009637643583118916\n",
      "0.009092403575778008\n",
      "0.010105563327670097\n",
      "0.009250703267753124\n",
      "0.011904345825314522\n",
      "0.010354697704315186\n",
      "0.00955564808100462\n",
      "0.009021970443427563\n",
      "0.010207179002463818\n",
      "0.00877867080271244\n",
      "0.009967883117496967\n",
      "0.00911511480808258\n",
      "0.009366650134325027\n",
      "0.011054424569010735\n",
      "0.011829378083348274\n",
      "0.00988431554287672\n",
      "0.008372576907277107\n",
      "0.010298337787389755\n",
      "0.01060093380510807\n",
      "0.01084255613386631\n",
      "0.01005131471902132\n",
      "0.009340327233076096\n",
      "0.01070670410990715\n",
      "0.010523820295929909\n",
      "0.009765300899744034\n",
      "0.011198660358786583\n",
      "0.009599816054105759\n",
      "0.010539819486439228\n",
      "0.009636053815484047\n",
      "0.009036388248205185\n",
      "0.010648061521351337\n",
      "0.009987441822886467\n",
      "0.010629754513502121\n",
      "0.009992278181016445\n",
      "0.009671327657997608\n",
      "0.010490523651242256\n",
      "0.010346985422074795\n",
      "0.010681716725230217\n",
      "0.010715787298977375\n",
      "0.009026847779750824\n",
      "0.01059996709227562\n",
      "0.009815697558224201\n",
      "0.009538051672279835\n",
      "0.010370256379246712\n",
      "0.011080264113843441\n",
      "0.010627401061356068\n",
      "0.011465010233223438\n",
      "0.010707670822739601\n",
      "0.01001910399645567\n",
      "0.009919441305100918\n",
      "0.011545050889253616\n",
      "0.010203341953456402\n",
      "0.009950446896255016\n",
      "0.01100092101842165\n",
      "0.010107454843819141\n",
      "0.0089308712631464\n",
      "0.009778819046914577\n",
      "0.010577941313385963\n",
      "0.01077278796583414\n",
      "0.01001905556768179\n",
      "0.009613586589694023\n",
      "0.01034845132380724\n",
      "0.009706374257802963\n",
      "0.008896369487047195\n",
      "0.010016068816184998\n",
      "0.009885946288704872\n",
      "0.011147263459861279\n",
      "0.010479280725121498\n",
      "0.011917746625840664\n",
      "0.01001258846372366\n",
      "0.009899499826133251\n",
      "0.009841461665928364\n",
      "0.009429201483726501\n",
      "0.009404761716723442\n",
      "0.01015753485262394\n",
      "0.010901612229645252\n",
      "0.009429454803466797\n",
      "0.01116056926548481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [45:30<06:43, 100.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8890931372549019\n",
      "验证集精度0.8953125\n",
      "测试集精度0.878125\n",
      "0.009608888998627663\n",
      "0.010301606729626656\n",
      "0.011219813488423824\n",
      "0.010174294002354145\n",
      "0.010671509429812431\n",
      "0.009673263877630234\n",
      "0.008418174460530281\n",
      "0.010260729119181633\n",
      "0.009747377596795559\n",
      "0.00995724368840456\n",
      "0.009648287668824196\n",
      "0.010316353291273117\n",
      "0.010792236775159836\n",
      "0.00998721458017826\n",
      "0.01137231569737196\n",
      "0.008499828167259693\n",
      "0.010460330173373222\n",
      "0.010391811840236187\n",
      "0.010659501887857914\n",
      "0.009752701036632061\n",
      "0.009235810488462448\n",
      "0.011730990372598171\n",
      "0.010290620848536491\n",
      "0.010993114672601223\n",
      "0.010594496503472328\n",
      "0.010173829272389412\n",
      "0.009962363168597221\n",
      "0.008783874101936817\n",
      "0.009560607373714447\n",
      "0.010594434104859829\n",
      "0.010892238467931747\n",
      "0.009510665200650692\n",
      "0.010145350359380245\n",
      "0.009967383928596973\n",
      "0.010157223790884018\n",
      "0.00979774259030819\n",
      "0.008294717408716679\n",
      "0.009066913276910782\n",
      "0.009718854911625385\n",
      "0.008672267198562622\n",
      "0.00963579025119543\n",
      "0.009380239993333817\n",
      "0.010261914692819118\n",
      "0.011257371865212917\n",
      "0.009415658190846443\n",
      "0.011411628685891628\n",
      "0.00952718686312437\n",
      "0.010647420771420002\n",
      "0.011358358897268772\n",
      "0.01059753354638815\n",
      "0.010524514131247997\n",
      "0.01099212747067213\n",
      "0.010649779811501503\n",
      "0.010308943688869476\n",
      "0.011329617351293564\n",
      "0.01070436742156744\n",
      "0.011448772624135017\n",
      "0.010651576332747936\n",
      "0.01062170322984457\n",
      "0.010309213772416115\n",
      "0.009956764057278633\n",
      "0.01008909847587347\n",
      "0.009632403030991554\n",
      "0.009153475984930992\n",
      "0.010847506113350391\n",
      "0.010102770291268826\n",
      "0.009490352123975754\n",
      "0.008666054345667362\n",
      "0.010780161246657372\n",
      "0.010777655988931656\n",
      "0.009421467781066895\n",
      "0.009891178458929062\n",
      "0.011448916979134083\n",
      "0.010179988108575344\n",
      "0.009345540776848793\n",
      "0.009636838920414448\n",
      "0.01014728657901287\n",
      "0.009565768763422966\n",
      "0.010278504341840744\n",
      "0.010434161871671677\n",
      "0.009136351756751537\n",
      "0.010977637022733688\n",
      "0.009717123582959175\n",
      "0.00993816927075386\n",
      "0.01091270986944437\n",
      "0.010268500074744225\n",
      "0.01017056219279766\n",
      "0.010213056579232216\n",
      "0.011001570150256157\n",
      "0.00966356135904789\n",
      "0.009537914767861366\n",
      "0.009160485118627548\n",
      "0.0101683484390378\n",
      "0.009534776210784912\n",
      "0.009086799807846546\n",
      "0.010187141597270966\n",
      "0.010849399492144585\n",
      "0.011277955956757069\n",
      "0.009850303642451763\n",
      "0.010643558576703072\n",
      "0.009022071957588196\n",
      "0.010265461169183254\n",
      "0.010578255169093609\n",
      "0.009944041259586811\n",
      "0.009477130137383938\n",
      "0.010432178154587746\n",
      "0.010205700993537903\n",
      "0.010983999818563461\n",
      "0.010810229927301407\n",
      "0.01056506298482418\n",
      "0.010125428438186646\n",
      "0.010261508636176586\n",
      "0.010144936852157116\n",
      "0.009886529296636581\n",
      "0.010061495006084442\n",
      "0.010690469294786453\n",
      "0.009728013537824154\n",
      "0.01103647705167532\n",
      "0.009985028766095638\n",
      "0.009887320920825005\n",
      "0.009752842597663403\n",
      "0.009630492888391018\n",
      "0.010759486816823483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [47:00<04:52, 97.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.905484068627451\n",
      "验证集精度0.9171875\n",
      "测试集精度0.884375\n",
      "0.010589218698441982\n",
      "0.010109308175742626\n",
      "0.010515933856368065\n",
      "0.009846231900155544\n",
      "0.008835832588374615\n",
      "0.009395873174071312\n",
      "0.008494006469845772\n",
      "0.009998311288654804\n",
      "0.01022726483643055\n",
      "0.010840998031198978\n",
      "0.010206160135567188\n",
      "0.010289120487868786\n",
      "0.011271114461123943\n",
      "0.010349322110414505\n",
      "0.010759891010820866\n",
      "0.009096678346395493\n",
      "0.009463927708566189\n",
      "0.009819697588682175\n",
      "0.009917052462697029\n",
      "0.010646265000104904\n",
      "0.011675597168505192\n",
      "0.009909102693200111\n",
      "0.009024272672832012\n",
      "0.009039286524057388\n",
      "0.009391856379806995\n",
      "0.009634295478463173\n",
      "0.011219261214137077\n",
      "0.008560682646930218\n",
      "0.010745849460363388\n",
      "0.010137464851140976\n",
      "0.009230459108948708\n",
      "0.00980856642127037\n",
      "0.010438857600092888\n",
      "0.010414378717541695\n",
      "0.010875379666686058\n",
      "0.009918618015944958\n",
      "0.010324927978217602\n",
      "0.010607829317450523\n",
      "0.00993520487099886\n",
      "0.009970319457352161\n",
      "0.00969994068145752\n",
      "0.009301419369876385\n",
      "0.008655330166220665\n",
      "0.00965685211122036\n",
      "0.00884622149169445\n",
      "0.01178764272481203\n",
      "0.010780860669910908\n",
      "0.01069940347224474\n",
      "0.010383345186710358\n",
      "0.010183468461036682\n",
      "0.01078164391219616\n",
      "0.009005147032439709\n",
      "0.011532208882272243\n",
      "0.009469537064433098\n",
      "0.009287133812904358\n",
      "0.008993125520646572\n",
      "0.009749354794621468\n",
      "0.010503927245736122\n",
      "0.010782754980027676\n",
      "0.009665644727647305\n",
      "0.009293098002672195\n",
      "0.00955868512392044\n",
      "0.0086565762758255\n",
      "0.009372249245643616\n",
      "0.009506849572062492\n",
      "0.009760810062289238\n",
      "0.00954719539731741\n",
      "0.010643037036061287\n",
      "0.009730007499456406\n",
      "0.011002079583704472\n",
      "0.010358517058193684\n",
      "0.00906696729362011\n",
      "0.009829500690102577\n",
      "0.010256952606141567\n",
      "0.009856041520833969\n",
      "0.011783132329583168\n",
      "0.009964643977582455\n",
      "0.010096155107021332\n",
      "0.010024040937423706\n",
      "0.009425312280654907\n",
      "0.01003589853644371\n",
      "0.010504786856472492\n",
      "0.012500773184001446\n",
      "0.010123014450073242\n",
      "0.010871163569390774\n",
      "0.009181302040815353\n",
      "0.009294137358665466\n",
      "0.010353012010455132\n",
      "0.011209041811525822\n",
      "0.010527512058615685\n",
      "0.009296244941651821\n",
      "0.010143800638616085\n",
      "0.01010645367205143\n",
      "0.009559127502143383\n",
      "0.01023081224411726\n",
      "0.00968714989721775\n",
      "0.010818686336278915\n",
      "0.009551736526191235\n",
      "0.010314826853573322\n",
      "0.010866362601518631\n",
      "0.009420561604201794\n",
      "0.010042075999081135\n",
      "0.010361398570239544\n",
      "0.010002422146499157\n",
      "0.009877774864435196\n",
      "0.009237995371222496\n",
      "0.009583520703017712\n",
      "0.011309965513646603\n",
      "0.009093631990253925\n",
      "0.011664248071610928\n",
      "0.009902307763695717\n",
      "0.01097070798277855\n",
      "0.009884661994874477\n",
      "0.009771568700671196\n",
      "0.010615670122206211\n",
      "0.012012642808258533\n",
      "0.010500365868210793\n",
      "0.010598340071737766\n",
      "0.010191175155341625\n",
      "0.009351465851068497\n",
      "0.010235512629151344\n",
      "0.011560714803636074\n",
      "0.009743933565914631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [48:47<03:20, 100.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9042585784313726\n",
      "验证集精度0.909375\n",
      "测试集精度0.8921875\n",
      "0.009937746450304985\n",
      "0.011099722236394882\n",
      "0.010376853868365288\n",
      "0.009741604328155518\n",
      "0.01004322525113821\n",
      "0.009363673627376556\n",
      "0.010193748399615288\n",
      "0.009998786263167858\n",
      "0.009680325165390968\n",
      "0.009551642462611198\n",
      "0.00995945930480957\n",
      "0.01169669907540083\n",
      "0.008174476213753223\n",
      "0.01003179606050253\n",
      "0.010588597506284714\n",
      "0.009726363234221935\n",
      "0.010387099348008633\n",
      "0.010378038510680199\n",
      "0.010008582845330238\n",
      "0.010763523168861866\n",
      "0.009678594768047333\n",
      "0.009662702679634094\n",
      "0.00933983363211155\n",
      "0.010425557382404804\n",
      "0.009259817190468311\n",
      "0.010578682646155357\n",
      "0.009159854613244534\n",
      "0.009916788898408413\n",
      "0.009524037130177021\n",
      "0.009446506388485432\n",
      "0.009112168103456497\n",
      "0.009487967938184738\n",
      "0.009515434503555298\n",
      "0.00930026639252901\n",
      "0.0107454564422369\n",
      "0.0105563560500741\n",
      "0.011509778909385204\n",
      "0.010408339090645313\n",
      "0.009385217912495136\n",
      "0.009414177387952805\n",
      "0.008690345101058483\n",
      "0.009880205616354942\n",
      "0.00957350991666317\n",
      "0.009981122799217701\n",
      "0.009924394078552723\n",
      "0.01017691008746624\n",
      "0.010121873579919338\n",
      "0.011080989614129066\n",
      "0.010443853214383125\n",
      "0.011253047734498978\n",
      "0.01123937126249075\n",
      "0.010874930769205093\n",
      "0.01020913477987051\n",
      "0.010026059113442898\n",
      "0.01043902151286602\n",
      "0.010364416055381298\n",
      "0.00873852614313364\n",
      "0.01055032480508089\n",
      "0.009674061089754105\n",
      "0.010993728414177895\n",
      "0.010016817599534988\n",
      "0.010635516606271267\n",
      "0.009697804227471352\n",
      "0.011000185273587704\n",
      "0.008176731877028942\n",
      "0.009527446702122688\n",
      "0.009929871186614037\n",
      "0.008923526853322983\n",
      "0.010753372684121132\n",
      "0.009840637445449829\n",
      "0.009973898530006409\n",
      "0.010284492745995522\n",
      "0.010976179502904415\n",
      "0.010649248026311398\n",
      "0.00922713615000248\n",
      "0.010835251770913601\n",
      "0.009799374267458916\n",
      "0.00956880021840334\n",
      "0.011025601997971535\n",
      "0.010430978611111641\n",
      "0.010595070198178291\n",
      "0.010408136062324047\n",
      "0.010507588274776936\n",
      "0.010770159773528576\n",
      "0.01075953058898449\n",
      "0.010521622374653816\n",
      "0.010340551845729351\n",
      "0.009771113283932209\n",
      "0.010266738943755627\n",
      "0.009467169642448425\n",
      "0.009207727387547493\n",
      "0.010540352202951908\n",
      "0.01040954701602459\n",
      "0.009258775040507317\n",
      "0.009731379337608814\n",
      "0.010339170694351196\n",
      "0.011395067907869816\n",
      "0.00914668571203947\n",
      "0.00953491497784853\n",
      "0.009879525750875473\n",
      "0.008893413469195366\n",
      "0.010962503962218761\n",
      "0.010157421231269836\n",
      "0.009233166463673115\n",
      "0.009694661013782024\n",
      "0.009339545853435993\n",
      "0.010920850560069084\n",
      "0.00980296265333891\n",
      "0.009099435061216354\n",
      "0.01064818724989891\n",
      "0.008905700407922268\n",
      "0.010044028982520103\n",
      "0.008820493705570698\n",
      "0.010258897207677364\n",
      "0.010119296610355377\n",
      "0.010504807345569134\n",
      "0.010522542521357536\n",
      "0.010450218804180622\n",
      "0.008414862677454948\n",
      "0.010472606867551804\n",
      "0.010305488482117653\n",
      "0.009555875323712826\n",
      "0.009750548750162125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [50:23<01:39, 99.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8954503676470589\n",
      "验证集精度0.896875\n",
      "测试集精度0.8859375\n",
      "0.010498983785510063\n",
      "0.010315119288861752\n",
      "0.010824463330209255\n",
      "0.009470583871006966\n",
      "0.009358598850667477\n",
      "0.009852029383182526\n",
      "0.010359954088926315\n",
      "0.00971454568207264\n",
      "0.010291940532624722\n",
      "0.009820451028645039\n",
      "0.010241513140499592\n",
      "0.009654000401496887\n",
      "0.010702290572226048\n",
      "0.010211308486759663\n",
      "0.012160797603428364\n",
      "0.009249820373952389\n",
      "0.009083348326385021\n",
      "0.011469746939837933\n",
      "0.011239836923778057\n",
      "0.009963993914425373\n",
      "0.009907959029078484\n",
      "0.010120879858732224\n",
      "0.009870062582194805\n",
      "0.010294544510543346\n",
      "0.00924096442759037\n",
      "0.010833347216248512\n",
      "0.01065740641206503\n",
      "0.010916408151388168\n",
      "0.009768923744559288\n",
      "0.009879602119326591\n",
      "0.009889064356684685\n",
      "0.00984188076108694\n",
      "0.009267764165997505\n",
      "0.01126345619559288\n",
      "0.01084232423454523\n",
      "0.009967168793082237\n",
      "0.01093309186398983\n",
      "0.010961377993226051\n",
      "0.010458497330546379\n",
      "0.01029359083622694\n",
      "0.009578576311469078\n",
      "0.010366600006818771\n",
      "0.008427010849118233\n",
      "0.009647473692893982\n",
      "0.009154332801699638\n",
      "0.00967724621295929\n",
      "0.00968912523239851\n",
      "0.011124136857688427\n",
      "0.010002760216593742\n",
      "0.009009642526507378\n",
      "0.010320914909243584\n",
      "0.009370452724397182\n",
      "0.010317821055650711\n",
      "0.009644433856010437\n",
      "0.009391497820615768\n",
      "0.010415284894406796\n",
      "0.01044424157589674\n",
      "0.010324333794414997\n",
      "0.010981922969222069\n",
      "0.010006432421505451\n",
      "0.011124258860945702\n",
      "0.010348718613386154\n",
      "0.009907467290759087\n",
      "0.010399716906249523\n",
      "0.010068085044622421\n",
      "0.00949360802769661\n",
      "0.009591090492904186\n",
      "0.009876005351543427\n",
      "0.009839428588747978\n",
      "0.010442779399454594\n",
      "0.008702056482434273\n",
      "0.011141503229737282\n",
      "0.009998777881264687\n",
      "0.010087033733725548\n",
      "0.011358807794749737\n",
      "0.009863743558526039\n",
      "0.00979079119861126\n",
      "0.009623887948691845\n",
      "0.010389307513833046\n",
      "0.010379333980381489\n",
      "0.009854073636233807\n",
      "0.010025310330092907\n",
      "0.010673717595636845\n",
      "0.010654929094016552\n",
      "0.009969288483262062\n",
      "0.010131861083209515\n",
      "0.009421329014003277\n",
      "0.010467207990586758\n",
      "0.01046764012426138\n",
      "0.011974613182246685\n",
      "0.010253356769680977\n",
      "0.010713719762861729\n",
      "0.00994905550032854\n",
      "0.010564268566668034\n",
      "0.010009804740548134\n",
      "0.009926209226250648\n",
      "0.010565252043306828\n",
      "0.00959928147494793\n",
      "0.011015797033905983\n",
      "0.010124621912837029\n",
      "0.009396280162036419\n",
      "0.01020596083253622\n",
      "0.011016563512384892\n",
      "0.009692403487861156\n",
      "0.009925959631800652\n",
      "0.00962577760219574\n",
      "0.010457099415361881\n",
      "0.008741144090890884\n",
      "0.011744172312319279\n",
      "0.011178554967045784\n",
      "0.010297460481524467\n",
      "0.009614131413400173\n",
      "0.010298426263034344\n",
      "0.011364364996552467\n",
      "0.009378829970955849\n",
      "0.009878566488623619\n",
      "0.010553737170994282\n",
      "0.010006753727793694\n",
      "0.00984928384423256\n",
      "0.010413063690066338\n",
      "0.009925469756126404\n",
      "0.009350411593914032\n",
      "0.010315570048987865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [51:54<00:00, 103.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9056372549019608\n",
      "验证集精度0.9171875\n",
      "测试集精度0.890625\n",
      "训练集最终精度0.9042585784313726\n",
      "验证集最终精度0.909375\n",
      "测试集最终精度0.8921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, DI_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "#train_KD_student(bert_cnn, bert_cnn_student, DI_datasets_padding, optimizer, loss_func, loss_func2, 5, 30) #用padding后的DI来KD，对比OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:28<00:00, 618.89it/s]  \n"
     ]
    }
   ],
   "source": [
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15751\n"
     ]
    }
   ],
   "source": [
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        temp[i].insert(0,101)\n",
    "        temp[i].append(102)\n",
    "        while len(tokens[i]) <100:\n",
    "            temp[i].append(0)  #padding\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取ood数据的平均长度为：31.243857532855056\n"
     ]
    }
   ],
   "source": [
    "counts =0\n",
    "for data in ood_datas:\n",
    "    count = 0\n",
    "    for j in range(len(data)):\n",
    "        if data[j] == 0:\n",
    "            break\n",
    "        count += 1\n",
    "    counts += count\n",
    "ave = counts / len(ood_datas)\n",
    "print('选取ood数据的平均长度为：'+ str(ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_datasets = TensorDataset(torch.tensor(ood_datas).long())\n",
    "ood_datasets = DataLoader(ood_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_number = 8000\n",
    "ood_datas_2 = torch.tensor([])\n",
    "\n",
    "for i,data in enumerate(ood_datasets):\n",
    "    if len(ood_datas_2) > 8000:\n",
    "        break\n",
    "    ood_datas_2 = torch.cat([ood_datas_2, data[0]], dim=0)\n",
    "ood_datasets_4000 = TensorDataset(ood_datas_2.long())\n",
    "ood_datasets_4000 = DataLoader(ood_datasets_4000, batch_size=64, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020870793610811234\n",
      "0.019727371633052826\n",
      "0.019572243094444275\n",
      "0.01796109415590763\n",
      "0.01819884590804577\n",
      "0.01885722391307354\n",
      "0.01860547624528408\n",
      "0.018126003444194794\n",
      "0.016538331285119057\n",
      "0.016655689105391502\n",
      "0.01748432032763958\n",
      "0.019376317039132118\n",
      "0.016201060265302658\n",
      "0.016920065507292747\n",
      "0.018268505111336708\n",
      "0.018174557015299797\n",
      "0.01870163530111313\n",
      "0.01845458708703518\n",
      "0.016735684126615524\n",
      "0.018564498052001\n",
      "0.017472991719841957\n",
      "0.01593119092285633\n",
      "0.0161310862749815\n",
      "0.01630980148911476\n",
      "0.016428373754024506\n",
      "0.015658443793654442\n",
      "0.016401689499616623\n",
      "0.016827242448925972\n",
      "0.017941126599907875\n",
      "0.016903672367334366\n",
      "0.016318000853061676\n",
      "0.016841096803545952\n",
      "0.015573447570204735\n",
      "0.016224674880504608\n",
      "0.016659745946526527\n",
      "0.014287235215306282\n",
      "0.0158219076693058\n",
      "0.015858829021453857\n",
      "0.015954120084643364\n",
      "0.01604698784649372\n",
      "0.015902696177363396\n",
      "0.015379302203655243\n",
      "0.016500068828463554\n",
      "0.014111751690506935\n",
      "0.016007184982299805\n",
      "0.0141217652708292\n",
      "0.016455983743071556\n",
      "0.014762086793780327\n",
      "0.015543210320174694\n",
      "0.01440245471894741\n",
      "0.013202918693423271\n",
      "0.016066214069724083\n",
      "0.014418337494134903\n",
      "0.015488679520785809\n",
      "0.015540894120931625\n",
      "0.016044560819864273\n",
      "0.015762872993946075\n",
      "0.014867926016449928\n",
      "0.016992000862956047\n",
      "0.014551240019500256\n",
      "0.015497488901019096\n",
      "0.01416940800845623\n",
      "0.015507792122662067\n",
      "0.01605609804391861\n",
      "0.015601841732859612\n",
      "0.01642698235809803\n",
      "0.014163975603878498\n",
      "0.015153063461184502\n",
      "0.014025548473000526\n",
      "0.013680991716682911\n",
      "0.014887357130646706\n",
      "0.014162585139274597\n",
      "0.013654747977852821\n",
      "0.01376339327543974\n",
      "0.013384449295699596\n",
      "0.013011186383664608\n",
      "0.013410460203886032\n",
      "0.015445958822965622\n",
      "0.011576280929148197\n",
      "0.015241589397192001\n",
      "0.015729550272226334\n",
      "0.01359541155397892\n",
      "0.01291919220238924\n",
      "0.012765208259224892\n",
      "0.013571960851550102\n",
      "0.013383058831095695\n",
      "0.012788055464625359\n",
      "0.015116364695131779\n",
      "0.013777444139122963\n",
      "0.0138858612626791\n",
      "0.014275739900767803\n",
      "0.015093214809894562\n",
      "0.014099940657615662\n",
      "0.013404816389083862\n",
      "0.013074775226414204\n",
      "0.012826708145439625\n",
      "0.012462614104151726\n",
      "0.014355908147990704\n",
      "0.013585753738880157\n",
      "0.013689422979950905\n",
      "0.015018830075860023\n",
      "0.015112158842384815\n",
      "0.013528164476156235\n",
      "0.014008287340402603\n",
      "0.013504893518984318\n",
      "0.012857282534241676\n",
      "0.014108301140367985\n",
      "0.013215964660048485\n",
      "0.014347102493047714\n",
      "0.013958629220724106\n",
      "0.013117698021233082\n",
      "0.013682779856026173\n",
      "0.01572604849934578\n",
      "0.013563247397542\n",
      "0.01250510010868311\n",
      "0.013449437916278839\n",
      "0.013712624087929726\n",
      "0.012818913906812668\n",
      "0.013333414681255817\n",
      "0.014529156498610973\n",
      "0.01358003169298172\n",
      "0.014070154167711735\n",
      "0.013789720833301544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:02<59:12, 122.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.5372242647058824\n",
      "验证集精度0.5390625\n",
      "测试集精度0.54375\n",
      "0.013231231831014156\n",
      "0.012661447748541832\n",
      "0.013704727403819561\n",
      "0.013099697418510914\n",
      "0.014752527698874474\n",
      "0.013032807968556881\n",
      "0.013105352409183979\n",
      "0.013262241147458553\n",
      "0.012431683950126171\n",
      "0.01339228730648756\n",
      "0.011758280918002129\n",
      "0.013356203213334084\n",
      "0.01259188074618578\n",
      "0.012937204912304878\n",
      "0.0125576825812459\n",
      "0.012068251147866249\n",
      "0.015082362107932568\n",
      "0.012122753076255322\n",
      "0.0142515879124403\n",
      "0.012562685646116734\n",
      "0.010533642023801804\n",
      "0.011956960894167423\n",
      "0.012644636444747448\n",
      "0.012876986525952816\n",
      "0.012756291776895523\n",
      "0.013712691143155098\n",
      "0.013371310196816921\n",
      "0.010705405846238136\n",
      "0.013735635206103325\n",
      "0.013305014930665493\n",
      "0.012842842377722263\n",
      "0.012326435185968876\n",
      "0.012972737662494183\n",
      "0.01237115915864706\n",
      "0.012553343549370766\n",
      "0.012868072837591171\n",
      "0.011462908238172531\n",
      "0.011822937056422234\n",
      "0.011927620507776737\n",
      "0.012839268893003464\n",
      "0.012701739557087421\n",
      "0.01186308078467846\n",
      "0.012119224295020103\n",
      "0.013435745611786842\n",
      "0.013927984051406384\n",
      "0.01291411742568016\n",
      "0.014894428662955761\n",
      "0.012829604558646679\n",
      "0.011704315431416035\n",
      "0.01329813338816166\n",
      "0.013660797849297523\n",
      "0.013568091206252575\n",
      "0.013001504354178905\n",
      "0.011290444992482662\n",
      "0.01121421717107296\n",
      "0.011865532957017422\n",
      "0.013056852854788303\n",
      "0.013217654079198837\n",
      "0.014390386641025543\n",
      "0.012070628814399242\n",
      "0.01245205383747816\n",
      "0.013019053265452385\n",
      "0.013405266217887402\n",
      "0.011744475923478603\n",
      "0.013488693162798882\n",
      "0.013926761224865913\n",
      "0.012353149242699146\n",
      "0.012693309225142002\n",
      "0.01216257456690073\n",
      "0.01082890760153532\n",
      "0.013983594253659248\n",
      "0.012747492641210556\n",
      "0.01271872315555811\n",
      "0.012961532920598984\n",
      "0.012295803055167198\n",
      "0.01272602565586567\n",
      "0.01337332185357809\n",
      "0.012830225750803947\n",
      "0.012244950979948044\n",
      "0.01226374413818121\n",
      "0.01472317986190319\n",
      "0.012557501904666424\n",
      "0.012104961089789867\n",
      "0.015653477981686592\n",
      "0.012188972905278206\n",
      "0.012385275214910507\n",
      "0.012688524089753628\n",
      "0.01274538692086935\n",
      "0.012680082581937313\n",
      "0.01293839793652296\n",
      "0.011892330832779408\n",
      "0.013680364936590195\n",
      "0.0122210793197155\n",
      "0.0137168662622571\n",
      "0.01258891262114048\n",
      "0.012008079327642918\n",
      "0.012734330259263515\n",
      "0.01186573039740324\n",
      "0.011757561936974525\n",
      "0.011457521468400955\n",
      "0.0123095428571105\n",
      "0.01363546121865511\n",
      "0.011321838945150375\n",
      "0.011951987631618977\n",
      "0.011559214442968369\n",
      "0.012616882100701332\n",
      "0.011754107661545277\n",
      "0.01273126620799303\n",
      "0.012596110813319683\n",
      "0.011655222624540329\n",
      "0.01152823306620121\n",
      "0.013640528544783592\n",
      "0.012685177847743034\n",
      "0.011506040580570698\n",
      "0.0134110227227211\n",
      "0.01316564716398716\n",
      "0.012730258516967297\n",
      "0.010552232153713703\n",
      "0.011912906542420387\n",
      "0.012074210681021214\n",
      "0.011403529904782772\n",
      "0.012683997862040997\n",
      "0.014654534868896008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [04:01<56:16, 120.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6517310049019608\n",
      "验证集精度0.6484375\n",
      "测试集精度0.6578125\n",
      "0.011098736897110939\n",
      "0.012787293642759323\n",
      "0.01364772580564022\n",
      "0.011960174888372421\n",
      "0.01134293433278799\n",
      "0.012282597832381725\n",
      "0.012426099739968777\n",
      "0.01207147166132927\n",
      "0.012076403014361858\n",
      "0.011387692764401436\n",
      "0.011625329032540321\n",
      "0.012111843563616276\n",
      "0.011279428377747536\n",
      "0.012957886792719364\n",
      "0.012568953447043896\n",
      "0.010866457596421242\n",
      "0.011229468509554863\n",
      "0.012027769349515438\n",
      "0.010889226570725441\n",
      "0.012139415368437767\n",
      "0.011139918118715286\n",
      "0.012037844397127628\n",
      "0.013807528652250767\n",
      "0.010502762161195278\n",
      "0.011792351491749287\n",
      "0.011399203911423683\n",
      "0.010770880617201328\n",
      "0.011063313111662865\n",
      "0.011898192577064037\n",
      "0.01189750898629427\n",
      "0.011929777450859547\n",
      "0.012461360543966293\n",
      "0.010917050763964653\n",
      "0.011509894393384457\n",
      "0.013489254750311375\n",
      "0.012002742849290371\n",
      "0.01208232156932354\n",
      "0.011666659265756607\n",
      "0.011663686484098434\n",
      "0.014236358925700188\n",
      "0.012092909775674343\n",
      "0.012708408758044243\n",
      "0.011696573346853256\n",
      "0.011690749786794186\n",
      "0.01134214736521244\n",
      "0.01064655277878046\n",
      "0.01129761803895235\n",
      "0.011631738394498825\n",
      "0.012076808139681816\n",
      "0.01235945150256157\n",
      "0.011165282689034939\n",
      "0.012251022271811962\n",
      "0.012673279270529747\n",
      "0.012705578468739986\n",
      "0.012112629599869251\n",
      "0.011844637803733349\n",
      "0.012171711772680283\n",
      "0.010569924488663673\n",
      "0.01066839974373579\n",
      "0.012279502116143703\n",
      "0.01224671583622694\n",
      "0.012807645834982395\n",
      "0.012929760850965977\n",
      "0.012855920009315014\n",
      "0.012739815749228\n",
      "0.01236727461218834\n",
      "0.011051509529352188\n",
      "0.011397275142371655\n",
      "0.011951874941587448\n",
      "0.011663003824651241\n",
      "0.011805687099695206\n",
      "0.011234899051487446\n",
      "0.01195408683270216\n",
      "0.013267185539007187\n",
      "0.010795136913657188\n",
      "0.011881123296916485\n",
      "0.011752859689295292\n",
      "0.010601225309073925\n",
      "0.013271796517074108\n",
      "0.011152151972055435\n",
      "0.011807364411652088\n",
      "0.011738177388906479\n",
      "0.0130111463367939\n",
      "0.010596368461847305\n",
      "0.01299833133816719\n",
      "0.013227654621005058\n",
      "0.011253832839429379\n",
      "0.011921638622879982\n",
      "0.012885409407317638\n",
      "0.012273037806153297\n",
      "0.012182909063994884\n",
      "0.011168333701789379\n",
      "0.013170725665986538\n",
      "0.01097830943763256\n",
      "0.010745630599558353\n",
      "0.012747328728437424\n",
      "0.011151565238833427\n",
      "0.012186751700937748\n",
      "0.01133618876338005\n",
      "0.010453972034156322\n",
      "0.011357120238244534\n",
      "0.013351217843592167\n",
      "0.012974660843610764\n",
      "0.010903876274824142\n",
      "0.013534026220440865\n",
      "0.010640288703143597\n",
      "0.011635301634669304\n",
      "0.012092764489352703\n",
      "0.010511588305234909\n",
      "0.012193452566862106\n",
      "0.013737794011831284\n",
      "0.012059143744409084\n",
      "0.011561891995370388\n",
      "0.012384026311337948\n",
      "0.011826222762465477\n",
      "0.011994694359600544\n",
      "0.011731642298400402\n",
      "0.011288912035524845\n",
      "0.012309885583817959\n",
      "0.012945232912898064\n",
      "0.012216981500387192\n",
      "0.011893660761415958\n",
      "0.011154268868267536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [05:46<50:57, 113.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7084099264705882\n",
      "验证集精度0.703125\n",
      "测试集精度0.7265625\n",
      "0.011238976381719112\n",
      "0.01148049347102642\n",
      "0.01073470525443554\n",
      "0.011514370329678059\n",
      "0.010883737355470657\n",
      "0.010067549534142017\n",
      "0.01298566348850727\n",
      "0.011281158775091171\n",
      "0.011230723932385445\n",
      "0.01143607310950756\n",
      "0.011466742493212223\n",
      "0.010461620055139065\n",
      "0.012642752379179\n",
      "0.011171017773449421\n",
      "0.011876830831170082\n",
      "0.012115132063627243\n",
      "0.01008705422282219\n",
      "0.010871113277971745\n",
      "0.011113128624856472\n",
      "0.01188703440129757\n",
      "0.011026037856936455\n",
      "0.010561132803559303\n",
      "0.010956024751067162\n",
      "0.010947625152766705\n",
      "0.01133002806454897\n",
      "0.012533767148852348\n",
      "0.010729100555181503\n",
      "0.011754666455090046\n",
      "0.011144435964524746\n",
      "0.010661976411938667\n",
      "0.012156580574810505\n",
      "0.012282016687095165\n",
      "0.01066962257027626\n",
      "0.010734411887824535\n",
      "0.010471003130078316\n",
      "0.010819163173437119\n",
      "0.011082044802606106\n",
      "0.01171577163040638\n",
      "0.01237077172845602\n",
      "0.011590764857828617\n",
      "0.011261221952736378\n",
      "0.009917490184307098\n",
      "0.01164217572659254\n",
      "0.011658999137580395\n",
      "0.010536924935877323\n",
      "0.012374920770525932\n",
      "0.010943735018372536\n",
      "0.011628824286162853\n",
      "0.011364441365003586\n",
      "0.011411384679377079\n",
      "0.011998165398836136\n",
      "0.01133324857801199\n",
      "0.011008297093212605\n",
      "0.010650132782757282\n",
      "0.0118164187297225\n",
      "0.012371967546641827\n",
      "0.01128467544913292\n",
      "0.010647689923644066\n",
      "0.010230262763798237\n",
      "0.010963580571115017\n",
      "0.011465844698250294\n",
      "0.011497853323817253\n",
      "0.012047979049384594\n",
      "0.011180158704519272\n",
      "0.012891710735857487\n",
      "0.011097246780991554\n",
      "0.011787427589297295\n",
      "0.011191178113222122\n",
      "0.011270459741353989\n",
      "0.01096203364431858\n",
      "0.01132089365273714\n",
      "0.011651608161628246\n",
      "0.011026619002223015\n",
      "0.01188855990767479\n",
      "0.01081389281898737\n",
      "0.011077631264925003\n",
      "0.011936571449041367\n",
      "0.011204998008906841\n",
      "0.011005545035004616\n",
      "0.011189859360456467\n",
      "0.0118006132543087\n",
      "0.01101082842797041\n",
      "0.012191811576485634\n",
      "0.012241128832101822\n",
      "0.011496540158987045\n",
      "0.010360125452280045\n",
      "0.011741925962269306\n",
      "0.011649813503026962\n",
      "0.01178067084401846\n",
      "0.012270078994333744\n",
      "0.010950682684779167\n",
      "0.010055474005639553\n",
      "0.011423052288591862\n",
      "0.0107424883171916\n",
      "0.01127077080309391\n",
      "0.011104346252977848\n",
      "0.011593159288167953\n",
      "0.012659273110330105\n",
      "0.011387835256755352\n",
      "0.011795316822826862\n",
      "0.011026223190128803\n",
      "0.011049698106944561\n",
      "0.011919569224119186\n",
      "0.012623359449207783\n",
      "0.010826333425939083\n",
      "0.011698548682034016\n",
      "0.010831338353455067\n",
      "0.012923710979521275\n",
      "0.008975397795438766\n",
      "0.012206398881971836\n",
      "0.011918684467673302\n",
      "0.011339658871293068\n",
      "0.011881779879331589\n",
      "0.012344997376203537\n",
      "0.01237841323018074\n",
      "0.01093729492276907\n",
      "0.01180289126932621\n",
      "0.011434672400355339\n",
      "0.010912390425801277\n",
      "0.011595542542636395\n",
      "0.011559365317225456\n",
      "0.010125324130058289\n",
      "0.012463541701436043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [07:29<47:17, 109.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7305453431372549\n",
      "验证集精度0.71875\n",
      "测试集精度0.7484375\n",
      "0.010598368011415005\n",
      "0.011601181700825691\n",
      "0.01127376314252615\n",
      "0.009833921678364277\n",
      "0.011085528880357742\n",
      "0.011161040514707565\n",
      "0.010660474188625813\n",
      "0.014096280559897423\n",
      "0.01094684936106205\n",
      "0.01002978254109621\n",
      "0.009998761117458344\n",
      "0.010966531001031399\n",
      "0.01100426260381937\n",
      "0.011909951455891132\n",
      "0.010394906625151634\n",
      "0.010459702461957932\n",
      "0.010858891531825066\n",
      "0.011213908903300762\n",
      "0.012202437967061996\n",
      "0.011584627442061901\n",
      "0.011854169890284538\n",
      "0.011801166459918022\n",
      "0.010836531408131123\n",
      "0.01165674440562725\n",
      "0.010617620311677456\n",
      "0.010078098624944687\n",
      "0.01091421116143465\n",
      "0.010486098006367683\n",
      "0.011624506674706936\n",
      "0.011683856137096882\n",
      "0.01084519736468792\n",
      "0.011504380963742733\n",
      "0.011272923089563847\n",
      "0.010248755104839802\n",
      "0.01065718661993742\n",
      "0.010527555830776691\n",
      "0.012122384272515774\n",
      "0.009984675794839859\n",
      "0.010943339206278324\n",
      "0.011567125096917152\n",
      "0.01198688056319952\n",
      "0.009169306606054306\n",
      "0.0107176648452878\n",
      "0.011589419096708298\n",
      "0.011400462128221989\n",
      "0.01007106900215149\n",
      "0.010534773580729961\n",
      "0.010172766633331776\n",
      "0.010668892413377762\n",
      "0.011787026189267635\n",
      "0.01156088151037693\n",
      "0.01195058785378933\n",
      "0.010574977844953537\n",
      "0.011876966804265976\n",
      "0.011066005565226078\n",
      "0.011833989061415195\n",
      "0.010939317755401134\n",
      "0.011379549279808998\n",
      "0.010449986904859543\n",
      "0.01109981257468462\n",
      "0.011293257586658001\n",
      "0.010341708548367023\n",
      "0.012048046104609966\n",
      "0.010362504050135612\n",
      "0.011820865795016289\n",
      "0.009542034938931465\n",
      "0.012127740308642387\n",
      "0.011081589385867119\n",
      "0.011662817560136318\n",
      "0.011273867450654507\n",
      "0.01121156569570303\n",
      "0.010384681634604931\n",
      "0.010205365717411041\n",
      "0.011488677002489567\n",
      "0.010234678164124489\n",
      "0.009580638259649277\n",
      "0.011081230826675892\n",
      "0.01052678283303976\n",
      "0.00995839387178421\n",
      "0.01132936216890812\n",
      "0.009580373764038086\n",
      "0.011151570826768875\n",
      "0.010104620829224586\n",
      "0.011042897589504719\n",
      "0.01041903905570507\n",
      "0.01116050872951746\n",
      "0.012446809560060501\n",
      "0.012418840080499649\n",
      "0.011929254978895187\n",
      "0.011471597477793694\n",
      "0.012064393609762192\n",
      "0.011642629280686378\n",
      "0.010714199393987656\n",
      "0.010849124751985073\n",
      "0.012002350762486458\n",
      "0.011870420537889004\n",
      "0.012202294543385506\n",
      "0.010960552841424942\n",
      "0.010593227110803127\n",
      "0.011717922054231167\n",
      "0.011725502088665962\n",
      "0.01151861809194088\n",
      "0.010877270251512527\n",
      "0.012239967472851276\n",
      "0.009468089789152145\n",
      "0.009492110460996628\n",
      "0.011050833389163017\n",
      "0.01027996651828289\n",
      "0.010117496363818645\n",
      "0.009629718028008938\n",
      "0.011301341466605663\n",
      "0.011483053676784039\n",
      "0.010623974725604057\n",
      "0.011818028055131435\n",
      "0.010765079408884048\n",
      "0.011390740983188152\n",
      "0.00988193042576313\n",
      "0.012946938164532185\n",
      "0.0114729730412364\n",
      "0.011479397304356098\n",
      "0.011123741045594215\n",
      "0.01156699750572443\n",
      "0.009774897247552872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [09:09<44:11, 106.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7300091911764706\n",
      "验证集精度0.715625\n",
      "测试集精度0.75625\n",
      "0.011147296987473965\n",
      "0.011953948065638542\n",
      "0.010831297375261784\n",
      "0.01106442604213953\n",
      "0.009283204562962055\n",
      "0.010966620407998562\n",
      "0.01184519100934267\n",
      "0.012272062711417675\n",
      "0.009512703865766525\n",
      "0.010848307982087135\n",
      "0.011714567430317402\n",
      "0.01025549229234457\n",
      "0.010659415274858475\n",
      "0.011052058078348637\n",
      "0.011286299675703049\n",
      "0.010992980562150478\n",
      "0.010378779843449593\n",
      "0.0102909617125988\n",
      "0.01098058931529522\n",
      "0.01084030233323574\n",
      "0.009148821234703064\n",
      "0.010921696200966835\n",
      "0.011214586906135082\n",
      "0.010745028033852577\n",
      "0.011659295298159122\n",
      "0.011422047391533852\n",
      "0.010479376651346684\n",
      "0.011683497577905655\n",
      "0.01111097726970911\n",
      "0.01206202432513237\n",
      "0.011234058067202568\n",
      "0.010304715484380722\n",
      "0.010003498755395412\n",
      "0.010339023545384407\n",
      "0.009378229267895222\n",
      "0.0118698226287961\n",
      "0.010823899880051613\n",
      "0.011403311975300312\n",
      "0.010872183367609978\n",
      "0.010679250583052635\n",
      "0.011521320790052414\n",
      "0.008735567331314087\n",
      "0.009844155982136726\n",
      "0.009757667779922485\n",
      "0.011903699487447739\n",
      "0.010795127600431442\n",
      "0.010601227171719074\n",
      "0.009958761744201183\n",
      "0.01151787769049406\n",
      "0.010865379124879837\n",
      "0.011468972079455853\n",
      "0.010115917772054672\n",
      "0.011434284970164299\n",
      "0.010580531321465969\n",
      "0.010563848540186882\n",
      "0.01214977540075779\n",
      "0.01045250054448843\n",
      "0.010648838244378567\n",
      "0.011305178515613079\n",
      "0.011054192669689655\n",
      "0.011704848147928715\n",
      "0.009821860119700432\n",
      "0.010425148531794548\n",
      "0.009718748740851879\n",
      "0.011633013375103474\n",
      "0.008853452280163765\n",
      "0.011121375486254692\n",
      "0.009938868694007397\n",
      "0.010203711688518524\n",
      "0.010826666839420795\n",
      "0.010958859696984291\n",
      "0.011364932172000408\n",
      "0.011199221946299076\n",
      "0.009915409609675407\n",
      "0.010695802979171276\n",
      "0.010128391906619072\n",
      "0.010284284129738808\n",
      "0.01095498539507389\n",
      "0.011281208135187626\n",
      "0.011608803644776344\n",
      "0.010635981336236\n",
      "0.010710551403462887\n",
      "0.00990193709731102\n",
      "0.011161969043314457\n",
      "0.010849506594240665\n",
      "0.011449339799582958\n",
      "0.01199543010443449\n",
      "0.010082232765853405\n",
      "0.010807340033352375\n",
      "0.010945937596261501\n",
      "0.012323576025664806\n",
      "0.011022170074284077\n",
      "0.009812219068408012\n",
      "0.011159637942910194\n",
      "0.010994261130690575\n",
      "0.01023035030812025\n",
      "0.010622721165418625\n",
      "0.011634296737611294\n",
      "0.01095607690513134\n",
      "0.010587555356323719\n",
      "0.010390158742666245\n",
      "0.01118987426161766\n",
      "0.011522491462528706\n",
      "0.011373130604624748\n",
      "0.011735246516764164\n",
      "0.011111768893897533\n",
      "0.010468742810189724\n",
      "0.009840205311775208\n",
      "0.01112390961498022\n",
      "0.010509667918086052\n",
      "0.011423955671489239\n",
      "0.010946768335998058\n",
      "0.010652159340679646\n",
      "0.011396730318665504\n",
      "0.010795078240334988\n",
      "0.01089088711887598\n",
      "0.010655405931174755\n",
      "0.011070973239839077\n",
      "0.011519026011228561\n",
      "0.01057865098118782\n",
      "0.011572900228202343\n",
      "0.010852891020476818\n",
      "0.010589402168989182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [10:41<40:30, 101.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7364430147058824\n",
      "验证集精度0.74375\n",
      "测试集精度0.7671875\n",
      "0.010717018507421017\n",
      "0.010037645697593689\n",
      "0.010507765226066113\n",
      "0.010107215493917465\n",
      "0.00894471537321806\n",
      "0.009501859545707703\n",
      "0.010095322504639626\n",
      "0.011660880409181118\n",
      "0.009517962113022804\n",
      "0.010216692462563515\n",
      "0.009855764918029308\n",
      "0.009995800442993641\n",
      "0.012746828608214855\n",
      "0.00852716714143753\n",
      "0.012010392732918262\n",
      "0.010716588236391544\n",
      "0.011208455078303814\n",
      "0.011598614975810051\n",
      "0.010319923050701618\n",
      "0.009797264821827412\n",
      "0.01144497748464346\n",
      "0.00896681472659111\n",
      "0.011296926066279411\n",
      "0.011380399577319622\n",
      "0.009406966157257557\n",
      "0.010966923087835312\n",
      "0.009639001451432705\n",
      "0.011259973980486393\n",
      "0.009836497716605663\n",
      "0.010658357292413712\n",
      "0.010720343329012394\n",
      "0.011918393895030022\n",
      "0.00961466133594513\n",
      "0.011346003971993923\n",
      "0.0092299310490489\n",
      "0.011730436235666275\n",
      "0.010368194431066513\n",
      "0.008431925438344479\n",
      "0.009722728282213211\n",
      "0.010843108408153057\n",
      "0.010678650811314583\n",
      "0.010561207309365273\n",
      "0.011092430911958218\n",
      "0.010324983857572079\n",
      "0.011613928712904453\n",
      "0.00913705863058567\n",
      "0.010692974552512169\n",
      "0.010456431657075882\n",
      "0.010179217904806137\n",
      "0.009874201379716396\n",
      "0.00964525155723095\n",
      "0.011317926459014416\n",
      "0.01050285343080759\n",
      "0.00961922574788332\n",
      "0.010452424176037312\n",
      "0.011499898508191109\n",
      "0.010249314829707146\n",
      "0.010056755505502224\n",
      "0.010444117709994316\n",
      "0.010228868573904037\n",
      "0.011685462668538094\n",
      "0.010088447481393814\n",
      "0.009709354490041733\n",
      "0.009803647175431252\n",
      "0.010199601761996746\n",
      "0.010313494130969048\n",
      "0.011027958244085312\n",
      "0.011683356016874313\n",
      "0.010425700806081295\n",
      "0.01077292300760746\n",
      "0.011725496500730515\n",
      "0.01127069815993309\n",
      "0.010139902122318745\n",
      "0.010610980913043022\n",
      "0.010988804511725903\n",
      "0.010851196013391018\n",
      "0.009327325038611889\n",
      "0.010881367139518261\n",
      "0.011318173259496689\n",
      "0.01094136480242014\n",
      "0.011770782992243767\n",
      "0.01078798994421959\n",
      "0.010652704164385796\n",
      "0.010415786877274513\n",
      "0.010800285264849663\n",
      "0.009724093601107597\n",
      "0.009646020829677582\n",
      "0.010206117294728756\n",
      "0.00954343006014824\n",
      "0.010309266857802868\n",
      "0.010068876668810844\n",
      "0.011242170818150043\n",
      "0.010014669969677925\n",
      "0.010328452102839947\n",
      "0.009763096459209919\n",
      "0.01134606171399355\n",
      "0.010884666815400124\n",
      "0.010607073083519936\n",
      "0.010347730480134487\n",
      "0.01139946561306715\n",
      "0.011146428994834423\n",
      "0.012058373540639877\n",
      "0.010095316916704178\n",
      "0.010428567416965961\n",
      "0.010480474680662155\n",
      "0.012267830781638622\n",
      "0.009785718284547329\n",
      "0.011082700453698635\n",
      "0.010071001015603542\n",
      "0.009514357894659042\n",
      "0.011610617861151695\n",
      "0.011063246987760067\n",
      "0.010658803395926952\n",
      "0.009903932921588421\n",
      "0.011786502785980701\n",
      "0.00949839036911726\n",
      "0.00996789988130331\n",
      "0.010677256621420383\n",
      "0.010638462379574776\n",
      "0.012622547335922718\n",
      "0.010180417448282242\n",
      "0.009649479761719704\n",
      "0.009929842315614223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [12:14<37:45, 98.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7395067401960784\n",
      "验证集精度0.7390625\n",
      "测试集精度0.7625\n",
      "0.01196411531418562\n",
      "0.010035896673798561\n",
      "0.009622462093830109\n",
      "0.01031543966382742\n",
      "0.010926973074674606\n",
      "0.01074024848639965\n",
      "0.010947717353701591\n",
      "0.010736272670328617\n",
      "0.01040644571185112\n",
      "0.009465483948588371\n",
      "0.012247945182025433\n",
      "0.010199390351772308\n",
      "0.010758744552731514\n",
      "0.009830973111093044\n",
      "0.010902995243668556\n",
      "0.009960098192095757\n",
      "0.011933485046029091\n",
      "0.009437406435608864\n",
      "0.00977820809930563\n",
      "0.009941435419023037\n",
      "0.010321996174752712\n",
      "0.009136366657912731\n",
      "0.010146266780793667\n",
      "0.009887291118502617\n",
      "0.00944115687161684\n",
      "0.009962011128664017\n",
      "0.008966784924268723\n",
      "0.010577622801065445\n",
      "0.01012082677334547\n",
      "0.010664899833500385\n",
      "0.010333007201552391\n",
      "0.009924964979290962\n",
      "0.009338892064988613\n",
      "0.01006857305765152\n",
      "0.010568561032414436\n",
      "0.009831098839640617\n",
      "0.01057005301117897\n",
      "0.009928595274686813\n",
      "0.010340488515794277\n",
      "0.00904166977852583\n",
      "0.01182484906166792\n",
      "0.009052494540810585\n",
      "0.01012257020920515\n",
      "0.009724321775138378\n",
      "0.01089413557201624\n",
      "0.009504484944045544\n",
      "0.010535987094044685\n",
      "0.010144702158868313\n",
      "0.010098516941070557\n",
      "0.00929967686533928\n",
      "0.01097223348915577\n",
      "0.01109007466584444\n",
      "0.010065170004963875\n",
      "0.010656326077878475\n",
      "0.01029684767127037\n",
      "0.01064388733357191\n",
      "0.009983350522816181\n",
      "0.009911201894283295\n",
      "0.008811518549919128\n",
      "0.010312682017683983\n",
      "0.009873275645077229\n",
      "0.008969159796833992\n",
      "0.010511916130781174\n",
      "0.011050202883780003\n",
      "0.010633459314703941\n",
      "0.010031936690211296\n",
      "0.009235113859176636\n",
      "0.011545967310667038\n",
      "0.009895022958517075\n",
      "0.010186809115111828\n",
      "0.011846844106912613\n",
      "0.010787298902869225\n",
      "0.010570583865046501\n",
      "0.009745820425450802\n",
      "0.011847147718071938\n",
      "0.009854915551841259\n",
      "0.010408657602965832\n",
      "0.009760893881320953\n",
      "0.010571116581559181\n",
      "0.009928097017109394\n",
      "0.009431952610611916\n",
      "0.010849452577531338\n",
      "0.009931886568665504\n",
      "0.01013520173728466\n",
      "0.008839119225740433\n",
      "0.00870002992451191\n",
      "0.009178536012768745\n",
      "0.009988646022975445\n",
      "0.008974270895123482\n",
      "0.012136480771005154\n",
      "0.009575402364134789\n",
      "0.009348754771053791\n",
      "0.010341939516365528\n",
      "0.009347192011773586\n",
      "0.010613339021801949\n",
      "0.010502377524971962\n",
      "0.011032622307538986\n",
      "0.009954703971743584\n",
      "0.01098423171788454\n",
      "0.01005102414637804\n",
      "0.010505876503884792\n",
      "0.010889453813433647\n",
      "0.010897577740252018\n",
      "0.008688457310199738\n",
      "0.00991621520370245\n",
      "0.010750445537269115\n",
      "0.009944766759872437\n",
      "0.011230084113776684\n",
      "0.009874839335680008\n",
      "0.009819812141358852\n",
      "0.009190554730594158\n",
      "0.008836694993078709\n",
      "0.00949483085423708\n",
      "0.009790202602744102\n",
      "0.00891646184027195\n",
      "0.011505629867315292\n",
      "0.009624063968658447\n",
      "0.010698196478188038\n",
      "0.009685548953711987\n",
      "0.009923437610268593\n",
      "0.01044737733900547\n",
      "0.009679247625172138\n",
      "0.008836779743432999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [13:50<35:51, 97.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7535232843137255\n",
      "验证集精度0.759375\n",
      "测试集精度0.771875\n",
      "0.010786629281938076\n",
      "0.010289713740348816\n",
      "0.010761699639260769\n",
      "0.010638153180480003\n",
      "0.008674259297549725\n",
      "0.011318011209368706\n",
      "0.009643844328820705\n",
      "0.010473912581801414\n",
      "0.010519806295633316\n",
      "0.009213222190737724\n",
      "0.009548489935696125\n",
      "0.011203660629689693\n",
      "0.01011419016867876\n",
      "0.009457672946155071\n",
      "0.011414434760808945\n",
      "0.012076887302100658\n",
      "0.00985769648104906\n",
      "0.010753572918474674\n",
      "0.011745811440050602\n",
      "0.01073488686233759\n",
      "0.010343213565647602\n",
      "0.00970742478966713\n",
      "0.011196700856089592\n",
      "0.009041781537234783\n",
      "0.010763166472315788\n",
      "0.01025584526360035\n",
      "0.009429250843822956\n",
      "0.010878792963922024\n",
      "0.009361954405903816\n",
      "0.010665742680430412\n",
      "0.009075652807950974\n",
      "0.011083575896918774\n",
      "0.011592891067266464\n",
      "0.011159190908074379\n",
      "0.01009456068277359\n",
      "0.009601714089512825\n",
      "0.010255892761051655\n",
      "0.011564946733415127\n",
      "0.01065159123390913\n",
      "0.009509395807981491\n",
      "0.011586192063987255\n",
      "0.010164925828576088\n",
      "0.008963771164417267\n",
      "0.01016474049538374\n",
      "0.009320009499788284\n",
      "0.010032194666564465\n",
      "0.010712547227740288\n",
      "0.010295972228050232\n",
      "0.009468486532568932\n",
      "0.010648122988641262\n",
      "0.011453023180365562\n",
      "0.010262775234878063\n",
      "0.011170749552547932\n",
      "0.01037395466119051\n",
      "0.010381249710917473\n",
      "0.009847963228821754\n",
      "0.011169985868036747\n",
      "0.0094135832041502\n",
      "0.011060521937906742\n",
      "0.011030257679522038\n",
      "0.0132673941552639\n",
      "0.010140578262507915\n",
      "0.01002819836139679\n",
      "0.01063076313585043\n",
      "0.010275738313794136\n",
      "0.011089164763689041\n",
      "0.009121122770011425\n",
      "0.0111234150826931\n",
      "0.009672010317444801\n",
      "0.009009761735796928\n",
      "0.010217124596238136\n",
      "0.008869516663253307\n",
      "0.009777812287211418\n",
      "0.009429408237338066\n",
      "0.008524050936102867\n",
      "0.010600777342915535\n",
      "0.009634963236749172\n",
      "0.010328247211873531\n",
      "0.01186230406165123\n",
      "0.010199440643191338\n",
      "0.010676315985620022\n",
      "0.011612924747169018\n",
      "0.009837435558438301\n",
      "0.009766992181539536\n",
      "0.010308687575161457\n",
      "0.008123745210468769\n",
      "0.009157013148069382\n",
      "0.008751188404858112\n",
      "0.010295641608536243\n",
      "0.010837961919605732\n",
      "0.008612331934273243\n",
      "0.010567010380327702\n",
      "0.010791012085974216\n",
      "0.009571842849254608\n",
      "0.01006288267672062\n",
      "0.010939693078398705\n",
      "0.00971217267215252\n",
      "0.010101720690727234\n",
      "0.01028442196547985\n",
      "0.009418103843927383\n",
      "0.011526244692504406\n",
      "0.010430577211081982\n",
      "0.00999318715184927\n",
      "0.010464875027537346\n",
      "0.010433533228933811\n",
      "0.009063424542546272\n",
      "0.010877503082156181\n",
      "0.010568431578576565\n",
      "0.009966382756829262\n",
      "0.00915326178073883\n",
      "0.009113085456192493\n",
      "0.010955223813652992\n",
      "0.010192114859819412\n",
      "0.009809105657041073\n",
      "0.010037461295723915\n",
      "0.010379582643508911\n",
      "0.010141223669052124\n",
      "0.010989164933562279\n",
      "0.010141021572053432\n",
      "0.009011334739625454\n",
      "0.010324643924832344\n",
      "0.009243096224963665\n",
      "0.00981813296675682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [15:23<33:39, 96.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7521446078431373\n",
      "验证集精度0.759375\n",
      "测试集精度0.7734375\n",
      "0.009598900564014912\n",
      "0.009849708527326584\n",
      "0.011227940209209919\n",
      "0.010889637283980846\n",
      "0.010452544316649437\n",
      "0.009629514068365097\n",
      "0.009035144932568073\n",
      "0.009910170920193195\n",
      "0.010647940449416637\n",
      "0.010614489205181599\n",
      "0.009078850969672203\n",
      "0.008979897946119308\n",
      "0.010249066166579723\n",
      "0.0108655309304595\n",
      "0.010369863361120224\n",
      "0.010718661360442638\n",
      "0.008465123362839222\n",
      "0.009976317174732685\n",
      "0.010623757727444172\n",
      "0.01008976623415947\n",
      "0.010399196296930313\n",
      "0.008955417200922966\n",
      "0.010342907160520554\n",
      "0.011561764404177666\n",
      "0.009474987164139748\n",
      "0.009972989559173584\n",
      "0.00992138497531414\n",
      "0.010123521089553833\n",
      "0.01039395947009325\n",
      "0.010371520183980465\n",
      "0.009514298290014267\n",
      "0.009352256543934345\n",
      "0.010635746642947197\n",
      "0.010134458541870117\n",
      "0.009583229199051857\n",
      "0.011353271082043648\n",
      "0.011242127977311611\n",
      "0.010440390557050705\n",
      "0.010827291756868362\n",
      "0.011725288815796375\n",
      "0.008695852011442184\n",
      "0.010660945437848568\n",
      "0.009448520839214325\n",
      "0.009349470026791096\n",
      "0.010914982296526432\n",
      "0.01070929504930973\n",
      "0.01036769524216652\n",
      "0.01056799478828907\n",
      "0.010205769911408424\n",
      "0.010661708191037178\n",
      "0.010264676995575428\n",
      "0.00957468617707491\n",
      "0.010390798561275005\n",
      "0.009261758998036385\n",
      "0.009885862469673157\n",
      "0.009268692694604397\n",
      "0.009064855985343456\n",
      "0.01028821524232626\n",
      "0.010182886384427547\n",
      "0.009428219869732857\n",
      "0.009953765198588371\n",
      "0.010052314028143883\n",
      "0.00982494093477726\n",
      "0.010679366998374462\n",
      "0.009489430114626884\n",
      "0.009749938733875751\n",
      "0.010660620406270027\n",
      "0.01004752330482006\n",
      "0.010565060190856457\n",
      "0.009135129861533642\n",
      "0.009526053443551064\n",
      "0.009236898273229599\n",
      "0.010870099999010563\n",
      "0.0105498768389225\n",
      "0.009853987023234367\n",
      "0.011279656551778316\n",
      "0.009796268306672573\n",
      "0.00990721583366394\n",
      "0.00890397559851408\n",
      "0.010428568348288536\n",
      "0.010447877459228039\n",
      "0.012348508462309837\n",
      "0.009371389634907246\n",
      "0.011023979634046555\n",
      "0.009546643123030663\n",
      "0.01004713773727417\n",
      "0.011126027442514896\n",
      "0.010182212106883526\n",
      "0.009115743450820446\n",
      "0.009570011869072914\n",
      "0.010988039895892143\n",
      "0.010247928090393543\n",
      "0.009322956204414368\n",
      "0.010259856469929218\n",
      "0.010509321466088295\n",
      "0.009554404765367508\n",
      "0.0106286546215415\n",
      "0.01117421593517065\n",
      "0.009157759137451649\n",
      "0.010328126139938831\n",
      "0.010603872127830982\n",
      "0.011622468009591103\n",
      "0.010796839371323586\n",
      "0.010618872009217739\n",
      "0.009387713856995106\n",
      "0.008967248722910881\n",
      "0.01064063049852848\n",
      "0.011309993453323841\n",
      "0.009705101139843464\n",
      "0.009976610541343689\n",
      "0.010833454318344593\n",
      "0.009977048262953758\n",
      "0.00935920886695385\n",
      "0.010741973295807838\n",
      "0.010301086120307446\n",
      "0.011034448631107807\n",
      "0.010109624825417995\n",
      "0.01032881997525692\n",
      "0.010193094611167908\n",
      "0.010317970998585224\n",
      "0.011172226630151272\n",
      "0.00959205161780119\n",
      "0.009503769688308239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [16:55<31:39, 94.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7410386029411765\n",
      "验证集精度0.7375\n",
      "测试集精度0.7625\n",
      "0.010202824138104916\n",
      "0.010145461186766624\n",
      "0.01059567742049694\n",
      "0.010736928321421146\n",
      "0.009662546217441559\n",
      "0.009849576279520988\n",
      "0.01023750938475132\n",
      "0.01064343936741352\n",
      "0.01090359129011631\n",
      "0.01118099968880415\n",
      "0.010518515482544899\n",
      "0.010101201012730598\n",
      "0.01065065898001194\n",
      "0.008772321045398712\n",
      "0.009872209280729294\n",
      "0.010934153571724892\n",
      "0.010510025545954704\n",
      "0.011238758452236652\n",
      "0.009741492569446564\n",
      "0.009759641252458096\n",
      "0.01046224869787693\n",
      "0.009608292952179909\n",
      "0.00944122951477766\n",
      "0.009731910191476345\n",
      "0.011170300655066967\n",
      "0.010120071470737457\n",
      "0.010394314303994179\n",
      "0.008225678466260433\n",
      "0.009874042123556137\n",
      "0.012221794575452805\n",
      "0.010110404342412949\n",
      "0.010320628061890602\n",
      "0.010161567479372025\n",
      "0.01057351939380169\n",
      "0.008882833644747734\n",
      "0.010317590087652206\n",
      "0.010241923853754997\n",
      "0.009114581160247326\n",
      "0.009479875676333904\n",
      "0.009862813167273998\n",
      "0.01019267737865448\n",
      "0.009096870198845863\n",
      "0.011112089268863201\n",
      "0.009438581764698029\n",
      "0.010671711526811123\n",
      "0.010775898583233356\n",
      "0.00981850828975439\n",
      "0.010438639670610428\n",
      "0.010321191512048244\n",
      "0.010773925110697746\n",
      "0.01016217190772295\n",
      "0.010202450677752495\n",
      "0.009745447896420956\n",
      "0.011098803021013737\n",
      "0.008792970329523087\n",
      "0.009236949495971203\n",
      "0.01170713733881712\n",
      "0.009474094025790691\n",
      "0.010392948053777218\n",
      "0.009925362654030323\n",
      "0.010145342908799648\n",
      "0.011386728845536709\n",
      "0.010538207367062569\n",
      "0.008624333888292313\n",
      "0.010614712722599506\n",
      "0.01062334980815649\n",
      "0.010443988256156445\n",
      "0.010022838599979877\n",
      "0.010904697701334953\n",
      "0.00894463062286377\n",
      "0.012220804579555988\n",
      "0.009836718440055847\n",
      "0.009982272982597351\n",
      "0.010254230350255966\n",
      "0.008830896578729153\n",
      "0.009563791565597057\n",
      "0.009331058710813522\n",
      "0.010517618618905544\n",
      "0.009482648223638535\n",
      "0.009505991823971272\n",
      "0.010495067574083805\n",
      "0.010954465717077255\n",
      "0.00893126055598259\n",
      "0.010507239028811455\n",
      "0.011118637397885323\n",
      "0.009635226801037788\n",
      "0.00946220476180315\n",
      "0.010403519496321678\n",
      "0.009462369605898857\n",
      "0.009289613924920559\n",
      "0.010210225358605385\n",
      "0.009970957413315773\n",
      "0.009022146463394165\n",
      "0.009903929196298122\n",
      "0.009859255515038967\n",
      "0.010104058310389519\n",
      "0.009918897412717342\n",
      "0.009970065206289291\n",
      "0.01043552253395319\n",
      "0.012185930274426937\n",
      "0.01099547278136015\n",
      "0.00987662561237812\n",
      "0.009961649775505066\n",
      "0.010580820962786674\n",
      "0.010450794361531734\n",
      "0.00853960495442152\n",
      "0.010631532408297062\n",
      "0.01036888174712658\n",
      "0.010457976721227169\n",
      "0.01003812626004219\n",
      "0.010961037129163742\n",
      "0.010080745443701744\n",
      "0.010557871311903\n",
      "0.008798887953162193\n",
      "0.0108391884714365\n",
      "0.01101065892726183\n",
      "0.010554310865700245\n",
      "0.010965808294713497\n",
      "0.011060679331421852\n",
      "0.010059288702905178\n",
      "0.010465293191373348\n",
      "0.00950134452432394\n",
      "0.009502813220024109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [18:29<29:58, 94.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7588848039215687\n",
      "验证集精度0.7640625\n",
      "测试集精度0.7765625\n",
      "0.010044015944004059\n",
      "0.010759759694337845\n",
      "0.008706067688763142\n",
      "0.009811392985284328\n",
      "0.009526694193482399\n",
      "0.010702061466872692\n",
      "0.009825083427131176\n",
      "0.010144500061869621\n",
      "0.0092690484598279\n",
      "0.009968696162104607\n",
      "0.010573694482445717\n",
      "0.010115626268088818\n",
      "0.010536092333495617\n",
      "0.009843003004789352\n",
      "0.010996798053383827\n",
      "0.010556051507592201\n",
      "0.00979616865515709\n",
      "0.009662339463829994\n",
      "0.008773325011134148\n",
      "0.009995875880122185\n",
      "0.009679298847913742\n",
      "0.009229014627635479\n",
      "0.01006003376096487\n",
      "0.01014072448015213\n",
      "0.011046742089092731\n",
      "0.008746109902858734\n",
      "0.00990945752710104\n",
      "0.01001589372754097\n",
      "0.010229572653770447\n",
      "0.01132546178996563\n",
      "0.008704662322998047\n",
      "0.009724628180265427\n",
      "0.009680951945483685\n",
      "0.010910767130553722\n",
      "0.00911288894712925\n",
      "0.010675775818526745\n",
      "0.010459617711603642\n",
      "0.009495582431554794\n",
      "0.010743523016571999\n",
      "0.010573741048574448\n",
      "0.010676718316972256\n",
      "0.01030687429010868\n",
      "0.012044432573020458\n",
      "0.008379417471587658\n",
      "0.011322388425469398\n",
      "0.009306984022259712\n",
      "0.009605176746845245\n",
      "0.009555704891681671\n",
      "0.009296265430748463\n",
      "0.010529807768762112\n",
      "0.009553907439112663\n",
      "0.010242419317364693\n",
      "0.010528654791414738\n",
      "0.010142160579562187\n",
      "0.011155661195516586\n",
      "0.009511698968708515\n",
      "0.01089619193226099\n",
      "0.010040657594799995\n",
      "0.008514158427715302\n",
      "0.00971471518278122\n",
      "0.010627456940710545\n",
      "0.010524196550250053\n",
      "0.010509598068892956\n",
      "0.01041339710354805\n",
      "0.010348625481128693\n",
      "0.0091176126152277\n",
      "0.007527131587266922\n",
      "0.010679269209504128\n",
      "0.008714346215128899\n",
      "0.00968143530189991\n",
      "0.009430794976651669\n",
      "0.010210397653281689\n",
      "0.011217283084988594\n",
      "0.009413555264472961\n",
      "0.008801314979791641\n",
      "0.00977317988872528\n",
      "0.009138024412095547\n",
      "0.01118465606123209\n",
      "0.009035125374794006\n",
      "0.009170386008918285\n",
      "0.008726249448955059\n",
      "0.01046084240078926\n",
      "0.01130021270364523\n",
      "0.010972068645060062\n",
      "0.011060458607971668\n",
      "0.008322897367179394\n",
      "0.011078628711402416\n",
      "0.010280239395797253\n",
      "0.009198579005897045\n",
      "0.00933824386447668\n",
      "0.009663938544690609\n",
      "0.009611481800675392\n",
      "0.010475886054337025\n",
      "0.010203237645328045\n",
      "0.010167202912271023\n",
      "0.010640687309205532\n",
      "0.009597967378795147\n",
      "0.009546506218612194\n",
      "0.011744565330445766\n",
      "0.009567189030349255\n",
      "0.010396715253591537\n",
      "0.008198709227144718\n",
      "0.010135045275092125\n",
      "0.01001200545579195\n",
      "0.00995120033621788\n",
      "0.009335901588201523\n",
      "0.011591924354434013\n",
      "0.008994887582957745\n",
      "0.011168193072080612\n",
      "0.00898529589176178\n",
      "0.009356971830129623\n",
      "0.010201379656791687\n",
      "0.009326814673841\n",
      "0.010319158434867859\n",
      "0.009521855972707272\n",
      "0.010291751474142075\n",
      "0.008561543188989162\n",
      "0.009043668396770954\n",
      "0.009775418788194656\n",
      "0.01007981039583683\n",
      "0.00886077992618084\n",
      "0.010552247054874897\n",
      "0.011300022713840008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [20:07<28:43, 95.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7711397058823529\n",
      "验证集精度0.778125\n",
      "测试集精度0.7796875\n",
      "0.00996667705476284\n",
      "0.009821446612477303\n",
      "0.009403111413121223\n",
      "0.009486709721386433\n",
      "0.009060842916369438\n",
      "0.011304778978228569\n",
      "0.0115443654358387\n",
      "0.011489538475871086\n",
      "0.010946542955935001\n",
      "0.010045860894024372\n",
      "0.009188776835799217\n",
      "0.009161359630525112\n",
      "0.011076989583671093\n",
      "0.010304245166480541\n",
      "0.011701869778335094\n",
      "0.009081356227397919\n",
      "0.009016016498208046\n",
      "0.009098461829125881\n",
      "0.008411902002990246\n",
      "0.008929368108510971\n",
      "0.010349582880735397\n",
      "0.009279489517211914\n",
      "0.009417745284736156\n",
      "0.009583388455212116\n",
      "0.010253539308905602\n",
      "0.010408209636807442\n",
      "0.009949218481779099\n",
      "0.01050561759620905\n",
      "0.009592482820153236\n",
      "0.010570991784334183\n",
      "0.010777133516967297\n",
      "0.010251538828015327\n",
      "0.009966518729925156\n",
      "0.010848293080925941\n",
      "0.008879429660737514\n",
      "0.008850771933794022\n",
      "0.0109309833496809\n",
      "0.010768511332571507\n",
      "0.011197865940630436\n",
      "0.009678898379206657\n",
      "0.009375033900141716\n",
      "0.00927463173866272\n",
      "0.009770361706614494\n",
      "0.00906108133494854\n",
      "0.010635397396981716\n",
      "0.008951947093009949\n",
      "0.009319419972598553\n",
      "0.009541397914290428\n",
      "0.010485325939953327\n",
      "0.01032403577119112\n",
      "0.009651380591094494\n",
      "0.009956590831279755\n",
      "0.009581118822097778\n",
      "0.009569713845849037\n",
      "0.009645262733101845\n",
      "0.010346725583076477\n",
      "0.01049311738461256\n",
      "0.009991476312279701\n",
      "0.009000408463180065\n",
      "0.008501674979925156\n",
      "0.010716041550040245\n",
      "0.009869820438325405\n",
      "0.00954966526478529\n",
      "0.010298107750713825\n",
      "0.009820121340453625\n",
      "0.009563419967889786\n",
      "0.010489579290151596\n",
      "0.010807597078382969\n",
      "0.009322252124547958\n",
      "0.010361610911786556\n",
      "0.011690327897667885\n",
      "0.009768766351044178\n",
      "0.01005662139505148\n",
      "0.009125450626015663\n",
      "0.009463821537792683\n",
      "0.009478605352342129\n",
      "0.008891904726624489\n",
      "0.010454145260155201\n",
      "0.009784886613488197\n",
      "0.010567640885710716\n",
      "0.01076703891158104\n",
      "0.00901882816106081\n",
      "0.009378103539347649\n",
      "0.011197379790246487\n",
      "0.009813348762691021\n",
      "0.010784839279949665\n",
      "0.007860863581299782\n",
      "0.010005485266447067\n",
      "0.010936380364000797\n",
      "0.010340427048504353\n",
      "0.010310697369277477\n",
      "0.009615592658519745\n",
      "0.009534423239529133\n",
      "0.009282312355935574\n",
      "0.009854835458099842\n",
      "0.009558239951729774\n",
      "0.010262657888233662\n",
      "0.010230784304440022\n",
      "0.008843263611197472\n",
      "0.010502896271646023\n",
      "0.010778081603348255\n",
      "0.009998003952205181\n",
      "0.01013853121548891\n",
      "0.009746436029672623\n",
      "0.009518178179860115\n",
      "0.00970237422734499\n",
      "0.010505732148885727\n",
      "0.010016580112278461\n",
      "0.01052185334265232\n",
      "0.0101315351203084\n",
      "0.010494488291442394\n",
      "0.01056655403226614\n",
      "0.009152436628937721\n",
      "0.010087424889206886\n",
      "0.010249110870063305\n",
      "0.01007019355893135\n",
      "0.010501261800527573\n",
      "0.01053408719599247\n",
      "0.00979660078883171\n",
      "0.011135991662740707\n",
      "0.01007604505866766\n",
      "0.009749313816428185\n",
      "0.008876703679561615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [21:44<27:09, 95.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7815563725490197\n",
      "验证集精度0.790625\n",
      "测试集精度0.79375\n",
      "0.01054038293659687\n",
      "0.009646985679864883\n",
      "0.009067868813872337\n",
      "0.009692015126347542\n",
      "0.010516522452235222\n",
      "0.009753013961017132\n",
      "0.010833132080733776\n",
      "0.009888287633657455\n",
      "0.00956729706376791\n",
      "0.010283446870744228\n",
      "0.009359571151435375\n",
      "0.0105919623747468\n",
      "0.010216053575277328\n",
      "0.009588677436113358\n",
      "0.008784147910773754\n",
      "0.00804253201931715\n",
      "0.010797204449772835\n",
      "0.00970869418233633\n",
      "0.008880234323441982\n",
      "0.010096619836986065\n",
      "0.010656080208718777\n",
      "0.008717767894268036\n",
      "0.010813537985086441\n",
      "0.010159440338611603\n",
      "0.010175535455346107\n",
      "0.010640766471624374\n",
      "0.010121982544660568\n",
      "0.008258959278464317\n",
      "0.009612596593797207\n",
      "0.010725107043981552\n",
      "0.009732922539114952\n",
      "0.010340062901377678\n",
      "0.009524073451757431\n",
      "0.010159879922866821\n",
      "0.00958072580397129\n",
      "0.010868620127439499\n",
      "0.008425453677773476\n",
      "0.009086217731237411\n",
      "0.009015396237373352\n",
      "0.00994562916457653\n",
      "0.009566433727741241\n",
      "0.008461407385766506\n",
      "0.007800981868058443\n",
      "0.00938295479863882\n",
      "0.010356149636209011\n",
      "0.010315134190022945\n",
      "0.008926477283239365\n",
      "0.009487858973443508\n",
      "0.009283887222409248\n",
      "0.010805445723235607\n",
      "0.008967455476522446\n",
      "0.010276850312948227\n",
      "0.010825901292264462\n",
      "0.01061415858566761\n",
      "0.010280221700668335\n",
      "0.009416719898581505\n",
      "0.01062760315835476\n",
      "0.009063862264156342\n",
      "0.011018713004887104\n",
      "0.009087621234357357\n",
      "0.010561591945588589\n",
      "0.00959011074155569\n",
      "0.010461716912686825\n",
      "0.01117189321666956\n",
      "0.009409381076693535\n",
      "0.010837160982191563\n",
      "0.009361284784972668\n",
      "0.010721048340201378\n",
      "0.010777105577290058\n",
      "0.011483528651297092\n",
      "0.009551551192998886\n",
      "0.009714675135910511\n",
      "0.011285782791674137\n",
      "0.010577878914773464\n",
      "0.01022887509316206\n",
      "0.010539194568991661\n",
      "0.009478859603404999\n",
      "0.009526994079351425\n",
      "0.009956834837794304\n",
      "0.009694261476397514\n",
      "0.010642463341355324\n",
      "0.0098775839433074\n",
      "0.00984211079776287\n",
      "0.009837794117629528\n",
      "0.010344265028834343\n",
      "0.010152697563171387\n",
      "0.008548351936042309\n",
      "0.010188463144004345\n",
      "0.010440042242407799\n",
      "0.01003294251859188\n",
      "0.010842879302799702\n",
      "0.01104824710637331\n",
      "0.009968062862753868\n",
      "0.01012808084487915\n",
      "0.011169781908392906\n",
      "0.009137633256614208\n",
      "0.009783166460692883\n",
      "0.010480733588337898\n",
      "0.009077979251742363\n",
      "0.009406546130776405\n",
      "0.010548307560384274\n",
      "0.011351498775184155\n",
      "0.010550914332270622\n",
      "0.00874635111540556\n",
      "0.010452011600136757\n",
      "0.00959865190088749\n",
      "0.009761101566255093\n",
      "0.009728394448757172\n",
      "0.011379067786037922\n",
      "0.010232429020106792\n",
      "0.009555614553391933\n",
      "0.010137262754142284\n",
      "0.010358479805290699\n",
      "0.010399013757705688\n",
      "0.010916177183389664\n",
      "0.008823961019515991\n",
      "0.008779818192124367\n",
      "0.009465508162975311\n",
      "0.009191642515361309\n",
      "0.010134696960449219\n",
      "0.00939194019883871\n",
      "0.009475146420300007\n",
      "0.010416864417493343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [23:27<26:09, 98.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7735906862745098\n",
      "验证集精度0.75625\n",
      "测试集精度0.7921875\n",
      "0.011330890469253063\n",
      "0.009490265510976315\n",
      "0.009645526297390461\n",
      "0.009288436733186245\n",
      "0.009779681451618671\n",
      "0.009205636568367481\n",
      "0.009221217595040798\n",
      "0.01233928557485342\n",
      "0.009512684307992458\n",
      "0.00888749212026596\n",
      "0.010047651827335358\n",
      "0.01032901182770729\n",
      "0.008810557425022125\n",
      "0.009761108085513115\n",
      "0.011178581044077873\n",
      "0.01153336837887764\n",
      "0.009364101104438305\n",
      "0.009173180907964706\n",
      "0.009623602032661438\n",
      "0.009448578581213951\n",
      "0.007997865788638592\n",
      "0.011508182622492313\n",
      "0.010868648067116737\n",
      "0.009641183540225029\n",
      "0.010094930417835712\n",
      "0.009029265493154526\n",
      "0.009104462340474129\n",
      "0.009801745414733887\n",
      "0.010706744156777859\n",
      "0.009856126271188259\n",
      "0.009049377404153347\n",
      "0.009750112891197205\n",
      "0.009601086378097534\n",
      "0.009342974051833153\n",
      "0.010399064980447292\n",
      "0.008742858655750751\n",
      "0.009281396865844727\n",
      "0.009559417143464088\n",
      "0.010033026337623596\n",
      "0.007804701570421457\n",
      "0.010181046091020107\n",
      "0.009126517921686172\n",
      "0.01007874682545662\n",
      "0.010101010091602802\n",
      "0.01036488451063633\n",
      "0.01077603455632925\n",
      "0.009614452719688416\n",
      "0.01114009041339159\n",
      "0.009681165218353271\n",
      "0.007894914597272873\n",
      "0.008351708762347698\n",
      "0.010696745477616787\n",
      "0.0099919019266963\n",
      "0.008802369236946106\n",
      "0.011584007181227207\n",
      "0.008661548607051373\n",
      "0.009992437437176704\n",
      "0.01020104344934225\n",
      "0.010232221335172653\n",
      "0.007811516523361206\n",
      "0.009380949661135674\n",
      "0.008092140778899193\n",
      "0.010757123120129108\n",
      "0.010140819475054741\n",
      "0.009330532513558865\n",
      "0.009372951462864876\n",
      "0.009702480398118496\n",
      "0.011194171383976936\n",
      "0.0111998300999403\n",
      "0.009781396947801113\n",
      "0.00981111079454422\n",
      "0.009931005537509918\n",
      "0.008619258180260658\n",
      "0.009007840417325497\n",
      "0.009737011976540089\n",
      "0.009174957871437073\n",
      "0.009603500366210938\n",
      "0.01023109070956707\n",
      "0.009370237588882446\n",
      "0.010157904587686062\n",
      "0.009901139885187149\n",
      "0.009228194132447243\n",
      "0.00983246136456728\n",
      "0.009821930900216103\n",
      "0.009393385611474514\n",
      "0.008426457643508911\n",
      "0.00972322653979063\n",
      "0.009194900281727314\n",
      "0.008628848008811474\n",
      "0.010688011534512043\n",
      "0.009777805767953396\n",
      "0.010270311497151852\n",
      "0.00977617222815752\n",
      "0.009722632355988026\n",
      "0.008494995534420013\n",
      "0.011177707463502884\n",
      "0.01049129106104374\n",
      "0.009841117076575756\n",
      "0.010150534100830555\n",
      "0.010170961730182171\n",
      "0.008860358037054539\n",
      "0.009642990306019783\n",
      "0.010768997482955456\n",
      "0.008618790656328201\n",
      "0.01070273108780384\n",
      "0.008725469000637531\n",
      "0.008798126131296158\n",
      "0.010400245897471905\n",
      "0.010206280276179314\n",
      "0.010119362734258175\n",
      "0.010158618912100792\n",
      "0.009776744060218334\n",
      "0.01010159868746996\n",
      "0.010451060719788074\n",
      "0.008236787281930447\n",
      "0.0102011663839221\n",
      "0.00988753605633974\n",
      "0.009995992295444012\n",
      "0.00932537205517292\n",
      "0.009783651679754257\n",
      "0.011251355521380901\n",
      "0.00935982447117567\n",
      "0.010231951251626015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [25:09<24:51, 99.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7911305147058824\n",
      "验证集精度0.78125\n",
      "测试集精度0.8109375\n",
      "0.009210128337144852\n",
      "0.009287341497838497\n",
      "0.01108101662248373\n",
      "0.009714005514979362\n",
      "0.010360266081988811\n",
      "0.01064972672611475\n",
      "0.009966522455215454\n",
      "0.011204845272004604\n",
      "0.009040728211402893\n",
      "0.009228798560798168\n",
      "0.009810060262680054\n",
      "0.009396355599164963\n",
      "0.010389779694378376\n",
      "0.00933217816054821\n",
      "0.009501002728939056\n",
      "0.009241881780326366\n",
      "0.008628368377685547\n",
      "0.009597293101251125\n",
      "0.01092336792498827\n",
      "0.010225096717476845\n",
      "0.009778467938303947\n",
      "0.011158601380884647\n",
      "0.01118063647300005\n",
      "0.009507556445896626\n",
      "0.00885998085141182\n",
      "0.009436754509806633\n",
      "0.010210325941443443\n",
      "0.009167114272713661\n",
      "0.00863664597272873\n",
      "0.011383724398911\n",
      "0.009160280227661133\n",
      "0.009633874520659447\n",
      "0.010027334094047546\n",
      "0.00936989113688469\n",
      "0.009237047284841537\n",
      "0.010161950252950191\n",
      "0.00923728384077549\n",
      "0.010108060203492641\n",
      "0.008977217599749565\n",
      "0.009572918526828289\n",
      "0.010389539413154125\n",
      "0.010358509607613087\n",
      "0.00917099416255951\n",
      "0.009227681905031204\n",
      "0.01086951233446598\n",
      "0.008834686130285263\n",
      "0.010350087657570839\n",
      "0.009904211387038231\n",
      "0.010558891110122204\n",
      "0.008927449584007263\n",
      "0.009269981645047665\n",
      "0.009960765019059181\n",
      "0.009262211620807648\n",
      "0.010738935321569443\n",
      "0.01014627330005169\n",
      "0.00991594698280096\n",
      "0.007792269811034203\n",
      "0.009911066852509975\n",
      "0.009946200996637344\n",
      "0.008852329105138779\n",
      "0.008706269785761833\n",
      "0.009377202950417995\n",
      "0.009793397970497608\n",
      "0.009702244773507118\n",
      "0.010027493350207806\n",
      "0.010509584099054337\n",
      "0.011553461663424969\n",
      "0.010063933208584785\n",
      "0.011257766745984554\n",
      "0.00957538466900587\n",
      "0.008634064346551895\n",
      "0.009312651120126247\n",
      "0.009249490685760975\n",
      "0.010286256670951843\n",
      "0.010607520118355751\n",
      "0.010163430124521255\n",
      "0.009603998623788357\n",
      "0.009837636724114418\n",
      "0.008998775854706764\n",
      "0.009326407685875893\n",
      "0.010578903369605541\n",
      "0.010505575686693192\n",
      "0.010356821119785309\n",
      "0.009333441033959389\n",
      "0.008510644547641277\n",
      "0.009935996495187283\n",
      "0.009631626307964325\n",
      "0.010525156743824482\n",
      "0.009066763333976269\n",
      "0.009496091865003109\n",
      "0.009378800168633461\n",
      "0.009871218353509903\n",
      "0.009118829853832722\n",
      "0.009182860143482685\n",
      "0.009346571750938892\n",
      "0.008233313448727131\n",
      "0.009955103509128094\n",
      "0.01081011164933443\n",
      "0.010018689557909966\n",
      "0.0108203599229455\n",
      "0.008661489933729172\n",
      "0.009635979309678078\n",
      "0.008788501843810081\n",
      "0.01095977146178484\n",
      "0.008695942349731922\n",
      "0.00909922830760479\n",
      "0.010292747989296913\n",
      "0.009537125006318092\n",
      "0.008294542320072651\n",
      "0.008789136074483395\n",
      "0.010705551132559776\n",
      "0.009577551856637001\n",
      "0.011189245618879795\n",
      "0.01022474467754364\n",
      "0.008910251781344414\n",
      "0.010300329886376858\n",
      "0.008184739388525486\n",
      "0.010621062479913235\n",
      "0.00926029309630394\n",
      "0.010482597164809704\n",
      "0.011487285606563091\n",
      "0.00913144275546074\n",
      "0.011140728369355202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [26:50<23:16, 99.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8055300245098039\n",
      "验证集精度0.809375\n",
      "测试集精度0.8109375\n",
      "0.010992352850735188\n",
      "0.011570432223379612\n",
      "0.00966852717101574\n",
      "0.009814588353037834\n",
      "0.010281150229275227\n",
      "0.0105442451313138\n",
      "0.009267198853194714\n",
      "0.009365307167172432\n",
      "0.01035283226519823\n",
      "0.008990203961730003\n",
      "0.007863051258027554\n",
      "0.010024001821875572\n",
      "0.009481828659772873\n",
      "0.009876652620732784\n",
      "0.01030090730637312\n",
      "0.009455478750169277\n",
      "0.008999546058475971\n",
      "0.009649021551012993\n",
      "0.010317057371139526\n",
      "0.009891084395349026\n",
      "0.010671737603843212\n",
      "0.009322932921350002\n",
      "0.008381441235542297\n",
      "0.009953441098332405\n",
      "0.009289070963859558\n",
      "0.01077972911298275\n",
      "0.009835412725806236\n",
      "0.009885615669190884\n",
      "0.011022309772670269\n",
      "0.010191483423113823\n",
      "0.007823450490832329\n",
      "0.009100941941142082\n",
      "0.009898252785205841\n",
      "0.010970980860292912\n",
      "0.009455767460167408\n",
      "0.008902661502361298\n",
      "0.01034607458859682\n",
      "0.00970759242773056\n",
      "0.009697379544377327\n",
      "0.009671020321547985\n",
      "0.010445392690598965\n",
      "0.009680463001132011\n",
      "0.010432749055325985\n",
      "0.009524192661046982\n",
      "0.010573787614703178\n",
      "0.008927560411393642\n",
      "0.008978239260613918\n",
      "0.010525685735046864\n",
      "0.009659434668719769\n",
      "0.010035241954028606\n",
      "0.009545925073325634\n",
      "0.010046834126114845\n",
      "0.00942267756909132\n",
      "0.009221590124070644\n",
      "0.009901896119117737\n",
      "0.009236931800842285\n",
      "0.009517032653093338\n",
      "0.0096769779920578\n",
      "0.010729626752436161\n",
      "0.009625863283872604\n",
      "0.008682413026690483\n",
      "0.009318324737250805\n",
      "0.010184984654188156\n",
      "0.009496239945292473\n",
      "0.01150414440780878\n",
      "0.009099854156374931\n",
      "0.010803611017763615\n",
      "0.010051069781184196\n",
      "0.009720793925225735\n",
      "0.010717623867094517\n",
      "0.00898684374988079\n",
      "0.009682469069957733\n",
      "0.00993894413113594\n",
      "0.009700234979391098\n",
      "0.010995731689035892\n",
      "0.00997842289507389\n",
      "0.010766174644231796\n",
      "0.010891329497098923\n",
      "0.00978929828852415\n",
      "0.009944875724613667\n",
      "0.00903845950961113\n",
      "0.010670555755496025\n",
      "0.008530210703611374\n",
      "0.009435692802071571\n",
      "0.009370478801429272\n",
      "0.009157096967101097\n",
      "0.010331309400498867\n",
      "0.00974787212908268\n",
      "0.01067532878369093\n",
      "0.00868552178144455\n",
      "0.010062295012176037\n",
      "0.009659571573138237\n",
      "0.010457752272486687\n",
      "0.009815732017159462\n",
      "0.0084236990660429\n",
      "0.010301395319402218\n",
      "0.009712889790534973\n",
      "0.009362075477838516\n",
      "0.007784600369632244\n",
      "0.009076550602912903\n",
      "0.009144751355051994\n",
      "0.009106582961976528\n",
      "0.009669668972492218\n",
      "0.00978455413132906\n",
      "0.008394195698201656\n",
      "0.01180251594632864\n",
      "0.009268228895962238\n",
      "0.009139723144471645\n",
      "0.009483312256634235\n",
      "0.009796405211091042\n",
      "0.009567692875862122\n",
      "0.009806296788156033\n",
      "0.008832613937556744\n",
      "0.009723054245114326\n",
      "0.009733645245432854\n",
      "0.009959324263036251\n",
      "0.01047313679009676\n",
      "0.009875639341771603\n",
      "0.00938535388559103\n",
      "0.008828970603644848\n",
      "0.009944047778844833\n",
      "0.008785557001829147\n",
      "0.00933043658733368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [28:28<21:30, 99.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7998621323529411\n",
      "验证集精度0.7953125\n",
      "测试集精度0.8171875\n",
      "0.010216757655143738\n",
      "0.009976188652217388\n",
      "0.009770721197128296\n",
      "0.009111715480685234\n",
      "0.010019960813224316\n",
      "0.009927542880177498\n",
      "0.008921432308852673\n",
      "0.011259867809712887\n",
      "0.010712424293160439\n",
      "0.010249867103993893\n",
      "0.00916901882737875\n",
      "0.009675068780779839\n",
      "0.009156091138720512\n",
      "0.009389877319335938\n",
      "0.009479032829403877\n",
      "0.009757086634635925\n",
      "0.008962063118815422\n",
      "0.009686975739896297\n",
      "0.008674997836351395\n",
      "0.00913950428366661\n",
      "0.009835919365286827\n",
      "0.009791316464543343\n",
      "0.009458323009312153\n",
      "0.008618826046586037\n",
      "0.009985973127186298\n",
      "0.010082703083753586\n",
      "0.009918383322656155\n",
      "0.010593225248157978\n",
      "0.009810122661292553\n",
      "0.008977925404906273\n",
      "0.008917883038520813\n",
      "0.008977264165878296\n",
      "0.010118281468749046\n",
      "0.010541095398366451\n",
      "0.009558458812534809\n",
      "0.010329540818929672\n",
      "0.010940877720713615\n",
      "0.0092298723757267\n",
      "0.00927842129021883\n",
      "0.009938368573784828\n",
      "0.01011052168905735\n",
      "0.009874780662357807\n",
      "0.010073746554553509\n",
      "0.008107682690024376\n",
      "0.010349612683057785\n",
      "0.009986598044633865\n",
      "0.009676610119640827\n",
      "0.010111835785210133\n",
      "0.010251355357468128\n",
      "0.010052913799881935\n",
      "0.011283776722848415\n",
      "0.010318688116967678\n",
      "0.010408940725028515\n",
      "0.009974172338843346\n",
      "0.010939394123852253\n",
      "0.009823834523558617\n",
      "0.009978113695979118\n",
      "0.01151979062706232\n",
      "0.008643393404781818\n",
      "0.009783434681594372\n",
      "0.011227474547922611\n",
      "0.00898522138595581\n",
      "0.008975553326308727\n",
      "0.00996941328048706\n",
      "0.00890299677848816\n",
      "0.01076006330549717\n",
      "0.010913229547441006\n",
      "0.009405090473592281\n",
      "0.01011000107973814\n",
      "0.008791324682533741\n",
      "0.009713222272694111\n",
      "0.008304521441459656\n",
      "0.009883693419396877\n",
      "0.00903602410107851\n",
      "0.010269003920257092\n",
      "0.0103555116802454\n",
      "0.010201791301369667\n",
      "0.010539594106376171\n",
      "0.009790434502065182\n",
      "0.01006107497960329\n",
      "0.010306126438081264\n",
      "0.008941328153014183\n",
      "0.009949971921741962\n",
      "0.011240797117352486\n",
      "0.010426483117043972\n",
      "0.009538358077406883\n",
      "0.009458615444600582\n",
      "0.010296374559402466\n",
      "0.010729236528277397\n",
      "0.009864673018455505\n",
      "0.009829100221395493\n",
      "0.010151924565434456\n",
      "0.010249930433928967\n",
      "0.009237004444003105\n",
      "0.008906012400984764\n",
      "0.009970254264771938\n",
      "0.011569088324904442\n",
      "0.00984884612262249\n",
      "0.009988178499042988\n",
      "0.008597979322075844\n",
      "0.010011245496571064\n",
      "0.009568240493535995\n",
      "0.010094834491610527\n",
      "0.010445653460919857\n",
      "0.009200045838952065\n",
      "0.009202075190842152\n",
      "0.011316289193928242\n",
      "0.010361529886722565\n",
      "0.010269541293382645\n",
      "0.009299500845372677\n",
      "0.009553342126309872\n",
      "0.009434221312403679\n",
      "0.01122978050261736\n",
      "0.010293552652001381\n",
      "0.008756972849369049\n",
      "0.009574869647622108\n",
      "0.009308991022408009\n",
      "0.009693167172372341\n",
      "0.009459106251597404\n",
      "0.01054918859153986\n",
      "0.008916681632399559\n",
      "0.009278381243348122\n",
      "0.01038120687007904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [30:02<19:34, 97.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8094362745098039\n",
      "验证集精度0.8140625\n",
      "测试集精度0.8296875\n",
      "0.010044300928711891\n",
      "0.008713174611330032\n",
      "0.009955818764865398\n",
      "0.010154533199965954\n",
      "0.010687057860195637\n",
      "0.010057361796498299\n",
      "0.00989187229424715\n",
      "0.009404865093529224\n",
      "0.010112173855304718\n",
      "0.009759850800037384\n",
      "0.01079507265239954\n",
      "0.009370828978717327\n",
      "0.008437609300017357\n",
      "0.0096581457182765\n",
      "0.009409919381141663\n",
      "0.008562001399695873\n",
      "0.008678581565618515\n",
      "0.009680412709712982\n",
      "0.010244120843708515\n",
      "0.009410033002495766\n",
      "0.009722888469696045\n",
      "0.011408800259232521\n",
      "0.010110639035701752\n",
      "0.008473062887787819\n",
      "0.010849718935787678\n",
      "0.009611648507416248\n",
      "0.010027779266238213\n",
      "0.010210609994828701\n",
      "0.009354385547339916\n",
      "0.00952906347811222\n",
      "0.008760024793446064\n",
      "0.008816009387373924\n",
      "0.009739021770656109\n",
      "0.008806390687823296\n",
      "0.008546561934053898\n",
      "0.010753894224762917\n",
      "0.009156434796750546\n",
      "0.00942312553524971\n",
      "0.00944032333791256\n",
      "0.009602467529475689\n",
      "0.009347456507384777\n",
      "0.009769442491233349\n",
      "0.008831243962049484\n",
      "0.008679589256644249\n",
      "0.009524164721369743\n",
      "0.008884157985448837\n",
      "0.01056886836886406\n",
      "0.010538381524384022\n",
      "0.01006213016808033\n",
      "0.01078339759260416\n",
      "0.009965496137738228\n",
      "0.011953954584896564\n",
      "0.009166806004941463\n",
      "0.009254561737179756\n",
      "0.009448129683732986\n",
      "0.0098663829267025\n",
      "0.010405574925243855\n",
      "0.010131893679499626\n",
      "0.009351801127195358\n",
      "0.007975651882588863\n",
      "0.009910265915095806\n",
      "0.008968240581452847\n",
      "0.009795579127967358\n",
      "0.009412010200321674\n",
      "0.009630275890231133\n",
      "0.011038771830499172\n",
      "0.01039140485227108\n",
      "0.010659022256731987\n",
      "0.011232685297727585\n",
      "0.009549609385430813\n",
      "0.011442283168435097\n",
      "0.01127135381102562\n",
      "0.009955525398254395\n",
      "0.009386377409100533\n",
      "0.008982699364423752\n",
      "0.00901324488222599\n",
      "0.009060247801244259\n",
      "0.009677714668214321\n",
      "0.009626500308513641\n",
      "0.008861038833856583\n",
      "0.008608200587332249\n",
      "0.009239265695214272\n",
      "0.008527170866727829\n",
      "0.009952619671821594\n",
      "0.01012058462947607\n",
      "0.01001332513988018\n",
      "0.0092129772529006\n",
      "0.010480773635208607\n",
      "0.009016948752105236\n",
      "0.0092279938980937\n",
      "0.010783213190734386\n",
      "0.009548449888825417\n",
      "0.00972878560423851\n",
      "0.00971095822751522\n",
      "0.011028865352272987\n",
      "0.010139835998415947\n",
      "0.00935503002256155\n",
      "0.009290759451687336\n",
      "0.00933709368109703\n",
      "0.008913007564842701\n",
      "0.011384274810552597\n",
      "0.009549230337142944\n",
      "0.010184971615672112\n",
      "0.009424297139048576\n",
      "0.008612288162112236\n",
      "0.010703591629862785\n",
      "0.009670935571193695\n",
      "0.01003070455044508\n",
      "0.009742656722664833\n",
      "0.00909151416271925\n",
      "0.010244887322187424\n",
      "0.010785569436848164\n",
      "0.008250143378973007\n",
      "0.009799838066101074\n",
      "0.010771955363452435\n",
      "0.010503559373319149\n",
      "0.009125624783337116\n",
      "0.011486632749438286\n",
      "0.01022009551525116\n",
      "0.009793690405786037\n",
      "0.010115532204508781\n",
      "0.011617479845881462\n",
      "0.008331424556672573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [31:38<17:49, 97.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7974877450980392\n",
      "验证集精度0.8\n",
      "测试集精度0.8171875\n",
      "0.01057514175772667\n",
      "0.010248932056128979\n",
      "0.009557938203215599\n",
      "0.009939718060195446\n",
      "0.009875123389065266\n",
      "0.010617454536259174\n",
      "0.008121797814965248\n",
      "0.011439776048064232\n",
      "0.009575184434652328\n",
      "0.009487088769674301\n",
      "0.010121680796146393\n",
      "0.00950314849615097\n",
      "0.009843965992331505\n",
      "0.010258413851261139\n",
      "0.008466148748993874\n",
      "0.009738913737237453\n",
      "0.009281255304813385\n",
      "0.008412463590502739\n",
      "0.01068654004484415\n",
      "0.009713138453662395\n",
      "0.009270284324884415\n",
      "0.009659331291913986\n",
      "0.009556794539093971\n",
      "0.01034626830369234\n",
      "0.009313298389315605\n",
      "0.010544833727180958\n",
      "0.008765100501477718\n",
      "0.008512062951922417\n",
      "0.009850721806287766\n",
      "0.008973854593932629\n",
      "0.010128344409167767\n",
      "0.012079920619726181\n",
      "0.009545032866299152\n",
      "0.008556286804378033\n",
      "0.010569347999989986\n",
      "0.009593314491212368\n",
      "0.010745019651949406\n",
      "0.008309255354106426\n",
      "0.009128030389547348\n",
      "0.010228388011455536\n",
      "0.008158320561051369\n",
      "0.011825325898826122\n",
      "0.009585978463292122\n",
      "0.009933462366461754\n",
      "0.010689493268728256\n",
      "0.009092341177165508\n",
      "0.008944015018641949\n",
      "0.010825813747942448\n",
      "0.010246566496789455\n",
      "0.009000018239021301\n",
      "0.008059890940785408\n",
      "0.007210795301944017\n",
      "0.009353110566735268\n",
      "0.01032191514968872\n",
      "0.009488603100180626\n",
      "0.00889064371585846\n",
      "0.010167157277464867\n",
      "0.01069694571197033\n",
      "0.01031569018959999\n",
      "0.010504791513085365\n",
      "0.009315039962530136\n",
      "0.010426945053040981\n",
      "0.010519537143409252\n",
      "0.009357094764709473\n",
      "0.009617834351956844\n",
      "0.009500782936811447\n",
      "0.009419411420822144\n",
      "0.009958709590137005\n",
      "0.009950574487447739\n",
      "0.010319813154637814\n",
      "0.009866513311862946\n",
      "0.00997287966310978\n",
      "0.01021617278456688\n",
      "0.010059612803161144\n",
      "0.008957204408943653\n",
      "0.010328411124646664\n",
      "0.00875791534781456\n",
      "0.008959468454122543\n",
      "0.008471610955893993\n",
      "0.008480439893901348\n",
      "0.011486117728054523\n",
      "0.009278129786252975\n",
      "0.009545407257974148\n",
      "0.009696796536445618\n",
      "0.009681778028607368\n",
      "0.009057581424713135\n",
      "0.01099381409585476\n",
      "0.009860232472419739\n",
      "0.010477965697646141\n",
      "0.009461842477321625\n",
      "0.008813516236841679\n",
      "0.010590875521302223\n",
      "0.009456543251872063\n",
      "0.008357025682926178\n",
      "0.010403875261545181\n",
      "0.009947922080755234\n",
      "0.010096314363181591\n",
      "0.010409857146441936\n",
      "0.009137207642197609\n",
      "0.008489648811519146\n",
      "0.010661027394235134\n",
      "0.008209269493818283\n",
      "0.011378859169781208\n",
      "0.011279324069619179\n",
      "0.010228889994323254\n",
      "0.008791392669081688\n",
      "0.009352033026516438\n",
      "0.009486140683293343\n",
      "0.010353654623031616\n",
      "0.009675934910774231\n",
      "0.009571154601871967\n",
      "0.009593123570084572\n",
      "0.008611286990344524\n",
      "0.011139560490846634\n",
      "0.009722379967570305\n",
      "0.009004942141473293\n",
      "0.00927969440817833\n",
      "0.011344168335199356\n",
      "0.010573845356702805\n",
      "0.009996182285249233\n",
      "0.009584753774106503\n",
      "0.009889200329780579\n",
      "0.008839070796966553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [33:19<16:22, 98.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8023131127450981\n",
      "验证集精度0.8125\n",
      "测试集精度0.8203125\n",
      "0.010365788824856281\n",
      "0.010455970652401447\n",
      "0.010442466475069523\n",
      "0.010828944854438305\n",
      "0.009448508732020855\n",
      "0.010180222801864147\n",
      "0.00979221798479557\n",
      "0.01128390897065401\n",
      "0.009348622523248196\n",
      "0.010241917334496975\n",
      "0.010279717855155468\n",
      "0.010164868086576462\n",
      "0.009357648901641369\n",
      "0.011268077418208122\n",
      "0.009717505425214767\n",
      "0.010033880360424519\n",
      "0.008334008976817131\n",
      "0.010661030188202858\n",
      "0.010425064712762833\n",
      "0.008746616542339325\n",
      "0.010189160704612732\n",
      "0.009823957458138466\n",
      "0.01082698442041874\n",
      "0.008673025295138359\n",
      "0.010370563715696335\n",
      "0.010397705249488354\n",
      "0.009382916614413261\n",
      "0.010625244118273258\n",
      "0.01001603715121746\n",
      "0.010011228732764721\n",
      "0.009909289889037609\n",
      "0.009439120069146156\n",
      "0.00862376019358635\n",
      "0.008730968460440636\n",
      "0.00898812711238861\n",
      "0.009279655292630196\n",
      "0.009320284239947796\n",
      "0.009444761089980602\n",
      "0.009973764419555664\n",
      "0.009753397665917873\n",
      "0.008857222273945808\n",
      "0.009755371138453484\n",
      "0.008406031876802444\n",
      "0.008395812474191189\n",
      "0.00926065631210804\n",
      "0.00986752100288868\n",
      "0.009739233180880547\n",
      "0.011043298058211803\n",
      "0.009642910212278366\n",
      "0.009710531681776047\n",
      "0.010263008065521717\n",
      "0.009153096005320549\n",
      "0.010746047832071781\n",
      "0.009160347282886505\n",
      "0.008561345748603344\n",
      "0.010455245152115822\n",
      "0.0100441575050354\n",
      "0.00874324981123209\n",
      "0.008986621163785458\n",
      "0.009356518276035786\n",
      "0.009320061653852463\n",
      "0.009507757611572742\n",
      "0.009753409773111343\n",
      "0.00988129060715437\n",
      "0.00963003933429718\n",
      "0.009479459375143051\n",
      "0.010149000212550163\n",
      "0.008652996271848679\n",
      "0.010909964330494404\n",
      "0.010067831724882126\n",
      "0.010673853568732738\n",
      "0.009509159252047539\n",
      "0.00988788902759552\n",
      "0.009306750260293484\n",
      "0.009736565873026848\n",
      "0.008871893398463726\n",
      "0.008835644461214542\n",
      "0.009922120720148087\n",
      "0.008474718779325485\n",
      "0.01094015035778284\n",
      "0.009646311402320862\n",
      "0.008927169255912304\n",
      "0.009499277919530869\n",
      "0.00936597865074873\n",
      "0.009869654662907124\n",
      "0.010001919232308865\n",
      "0.009071243926882744\n",
      "0.010812590830028057\n",
      "0.007860085926949978\n",
      "0.00958353839814663\n",
      "0.010282915085554123\n",
      "0.011195260100066662\n",
      "0.010305475443601608\n",
      "0.011346162296831608\n",
      "0.009424738585948944\n",
      "0.011204862967133522\n",
      "0.00986457522958517\n",
      "0.010520280338823795\n",
      "0.009194904938340187\n",
      "0.010921738110482693\n",
      "0.010260194540023804\n",
      "0.009889724664390087\n",
      "0.00940426904708147\n",
      "0.009872888214886189\n",
      "0.008263739757239819\n",
      "0.00947287306189537\n",
      "0.009169300086796284\n",
      "0.009608794935047626\n",
      "0.010194092988967896\n",
      "0.008741144090890884\n",
      "0.009210033342242241\n",
      "0.010548120364546776\n",
      "0.009931748732924461\n",
      "0.009466186165809631\n",
      "0.00984213873744011\n",
      "0.010032466612756252\n",
      "0.010028302669525146\n",
      "0.010224636644124985\n",
      "0.010184980928897858\n",
      "0.01050419732928276\n",
      "0.011190000921487808\n",
      "0.009852731600403786\n",
      "0.00994812324643135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [34:59<14:49, 98.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8043811274509803\n",
      "验证集精度0.8078125\n",
      "测试集精度0.821875\n",
      "0.009617122821509838\n",
      "0.010500534437596798\n",
      "0.011012616567313671\n",
      "0.011665304191410542\n",
      "0.010107140988111496\n",
      "0.011832322925329208\n",
      "0.010079305619001389\n",
      "0.011009344831109047\n",
      "0.009809387847781181\n",
      "0.009968872182071209\n",
      "0.008212573826313019\n",
      "0.010126245208084583\n",
      "0.008286834694445133\n",
      "0.007787999697029591\n",
      "0.009462933987379074\n",
      "0.007894217036664486\n",
      "0.007858185097575188\n",
      "0.010187102481722832\n",
      "0.009418206289410591\n",
      "0.008907211944460869\n",
      "0.009345564059913158\n",
      "0.010603350587189198\n",
      "0.007568913046270609\n",
      "0.008905509486794472\n",
      "0.009471903555095196\n",
      "0.008804029785096645\n",
      "0.01105982530862093\n",
      "0.009024091064929962\n",
      "0.009504804387688637\n",
      "0.009100774303078651\n",
      "0.010312743484973907\n",
      "0.00928984023630619\n",
      "0.008511310443282127\n",
      "0.009063235484063625\n",
      "0.009082790464162827\n",
      "0.01039440743625164\n",
      "0.010475163348019123\n",
      "0.009852941147983074\n",
      "0.01017860509455204\n",
      "0.009430591948330402\n",
      "0.00820173230022192\n",
      "0.010027362033724785\n",
      "0.010056850500404835\n",
      "0.01174077671021223\n",
      "0.00945823173969984\n",
      "0.008942264132201672\n",
      "0.010463354177772999\n",
      "0.009191691875457764\n",
      "0.011525044217705727\n",
      "0.009750057943165302\n",
      "0.009468862786889076\n",
      "0.010249431245028973\n",
      "0.007821937091648579\n",
      "0.00960738118737936\n",
      "0.009826983325183392\n",
      "0.010549788363277912\n",
      "0.011084260419011116\n",
      "0.009289981797337532\n",
      "0.010584661737084389\n",
      "0.00888846255838871\n",
      "0.009577144868671894\n",
      "0.010322694666683674\n",
      "0.0092001436278224\n",
      "0.00877563189715147\n",
      "0.010188239626586437\n",
      "0.009569103829562664\n",
      "0.010306432843208313\n",
      "0.009407514706254005\n",
      "0.00942663848400116\n",
      "0.008158339187502861\n",
      "0.009478475898504257\n",
      "0.010106890462338924\n",
      "0.00934156309813261\n",
      "0.010436903685331345\n",
      "0.009386024437844753\n",
      "0.009392651729285717\n",
      "0.009188223630189896\n",
      "0.008970915339887142\n",
      "0.009444678202271461\n",
      "0.011520063504576683\n",
      "0.00981433130800724\n",
      "0.010610547848045826\n",
      "0.01056361012160778\n",
      "0.010284232906997204\n",
      "0.011196976527571678\n",
      "0.011446695774793625\n",
      "0.008921143598854542\n",
      "0.010174790397286415\n",
      "0.009084758348762989\n",
      "0.009208235889673233\n",
      "0.009422484785318375\n",
      "0.009211699478328228\n",
      "0.009638785384595394\n",
      "0.008558857254683971\n",
      "0.01038565393537283\n",
      "0.008904065936803818\n",
      "0.00870534498244524\n",
      "0.008574356324970722\n",
      "0.010239309631288052\n",
      "0.009943978860974312\n",
      "0.0091098016127944\n",
      "0.007266995497047901\n",
      "0.00793665461242199\n",
      "0.009666564874351025\n",
      "0.01038496196269989\n",
      "0.009250073693692684\n",
      "0.009423479437828064\n",
      "0.010185198858380318\n",
      "0.010522746481001377\n",
      "0.00955156609416008\n",
      "0.00804720539599657\n",
      "0.008048171177506447\n",
      "0.008607584983110428\n",
      "0.00918670929968357\n",
      "0.007931036874651909\n",
      "0.010709202848374844\n",
      "0.00951333623379469\n",
      "0.00962079968303442\n",
      "0.010623966343700886\n",
      "0.011348589323461056\n",
      "0.008798853494226933\n",
      "0.00994179118424654\n",
      "0.009194719605147839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [36:29<12:48, 96.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8023897058823529\n",
      "验证集精度0.815625\n",
      "测试集精度0.8171875\n",
      "0.0097819147631526\n",
      "0.010416589677333832\n",
      "0.009575839154422283\n",
      "0.010920831002295017\n",
      "0.009817013517022133\n",
      "0.009115912020206451\n",
      "0.01041692215949297\n",
      "0.009148025885224342\n",
      "0.00934014655649662\n",
      "0.009371604770421982\n",
      "0.00927282776683569\n",
      "0.009016869589686394\n",
      "0.009971004910767078\n",
      "0.009107112884521484\n",
      "0.008861051872372627\n",
      "0.009405041113495827\n",
      "0.009675730019807816\n",
      "0.009980502538383007\n",
      "0.010228749364614487\n",
      "0.009114178828895092\n",
      "0.009173640981316566\n",
      "0.009081412106752396\n",
      "0.0086444653570652\n",
      "0.010564467869699001\n",
      "0.008331350050866604\n",
      "0.0089033842086792\n",
      "0.009047052823007107\n",
      "0.010081413201987743\n",
      "0.010930221527814865\n",
      "0.009140136651694775\n",
      "0.008943137712776661\n",
      "0.011448838748037815\n",
      "0.010738988406956196\n",
      "0.01018295343965292\n",
      "0.009791210293769836\n",
      "0.009383236058056355\n",
      "0.009440124034881592\n",
      "0.009100649505853653\n",
      "0.00923819001764059\n",
      "0.00922082643955946\n",
      "0.009266315028071404\n",
      "0.009733986109495163\n",
      "0.009342742152512074\n",
      "0.008770476095378399\n",
      "0.010133123956620693\n",
      "0.010874033905565739\n",
      "0.01074965763837099\n",
      "0.008094144985079765\n",
      "0.01012880727648735\n",
      "0.008620456792414188\n",
      "0.009981423616409302\n",
      "0.010120517574250698\n",
      "0.010198365896940231\n",
      "0.008423511870205402\n",
      "0.00987815298140049\n",
      "0.010505561716854572\n",
      "0.00958835706114769\n",
      "0.0109765799716115\n",
      "0.011225199326872826\n",
      "0.009020674973726273\n",
      "0.009428824298083782\n",
      "0.009325088933110237\n",
      "0.009714952670037746\n",
      "0.011145497672259808\n",
      "0.009864461608231068\n",
      "0.008949125185608864\n",
      "0.008703703992068768\n",
      "0.009880823083221912\n",
      "0.009300504811108112\n",
      "0.008673986420035362\n",
      "0.008970705792307854\n",
      "0.011441177688539028\n",
      "0.009552117437124252\n",
      "0.011239254847168922\n",
      "0.010394006967544556\n",
      "0.0104069784283638\n",
      "0.010145085863769054\n",
      "0.009401637129485607\n",
      "0.009819891303777695\n",
      "0.009236151352524757\n",
      "0.00954064354300499\n",
      "0.01022987999022007\n",
      "0.009381502866744995\n",
      "0.009159933775663376\n",
      "0.008899820037186146\n",
      "0.008397514931857586\n",
      "0.009531183168292046\n",
      "0.009878220036625862\n",
      "0.011412686668336391\n",
      "0.009605392813682556\n",
      "0.010095309466123581\n",
      "0.010106276720762253\n",
      "0.009168158285319805\n",
      "0.01018030196428299\n",
      "0.010411260649561882\n",
      "0.008050475269556046\n",
      "0.011419803835451603\n",
      "0.008529442362487316\n",
      "0.008015258237719536\n",
      "0.0093223936855793\n",
      "0.009697657078504562\n",
      "0.009045875631272793\n",
      "0.009327292442321777\n",
      "0.009887313470244408\n",
      "0.009374389424920082\n",
      "0.010485852137207985\n",
      "0.009644215926527977\n",
      "0.010066483169794083\n",
      "0.008964692242443562\n",
      "0.009105296805500984\n",
      "0.009787613525986671\n",
      "0.009933335706591606\n",
      "0.007695899810642004\n",
      "0.007887927815318108\n",
      "0.008245605044066906\n",
      "0.010807925835251808\n",
      "0.009273523464798927\n",
      "0.009885706007480621\n",
      "0.009739203378558159\n",
      "0.009647379629313946\n",
      "0.009605693630874157\n",
      "0.00990993157029152\n",
      "0.00876697339117527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [38:03<11:08, 95.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8068321078431373\n",
      "验证集精度0.8140625\n",
      "测试集精度0.828125\n",
      "0.009554256685078144\n",
      "0.00900041963905096\n",
      "0.009514679200947285\n",
      "0.010143354535102844\n",
      "0.008426019921898842\n",
      "0.00909443013370037\n",
      "0.010138365440070629\n",
      "0.009530111216008663\n",
      "0.009330222383141518\n",
      "0.01030320581048727\n",
      "0.011616253294050694\n",
      "0.00993665773421526\n",
      "0.008110929280519485\n",
      "0.011104063130915165\n",
      "0.008935539051890373\n",
      "0.009642483666539192\n",
      "0.010184627026319504\n",
      "0.009869840927422047\n",
      "0.00942140631377697\n",
      "0.008450154215097427\n",
      "0.008811060339212418\n",
      "0.010696102865040302\n",
      "0.009052981622517109\n",
      "0.00953033845871687\n",
      "0.010472199879586697\n",
      "0.010396325960755348\n",
      "0.009178733453154564\n",
      "0.00973547250032425\n",
      "0.007784970570355654\n",
      "0.008679594844579697\n",
      "0.009327515959739685\n",
      "0.009129456244409084\n",
      "0.009143328294157982\n",
      "0.007770137395709753\n",
      "0.009977228008210659\n",
      "0.01024598814547062\n",
      "0.009409363381564617\n",
      "0.011749655939638615\n",
      "0.00993610080331564\n",
      "0.007668339181691408\n",
      "0.008511628024280071\n",
      "0.00906608160585165\n",
      "0.009552001953125\n",
      "0.01032993197441101\n",
      "0.010643736459314823\n",
      "0.008600486442446709\n",
      "0.009595615789294243\n",
      "0.009997587651014328\n",
      "0.010433129034936428\n",
      "0.009649594314396381\n",
      "0.008868947625160217\n",
      "0.00817383173853159\n",
      "0.009984608739614487\n",
      "0.008023569360375404\n",
      "0.009754598140716553\n",
      "0.00965644046664238\n",
      "0.010659982450306416\n",
      "0.007830745540559292\n",
      "0.00905410572886467\n",
      "0.009314934723079205\n",
      "0.009456496685743332\n",
      "0.011479699052870274\n",
      "0.008789448998868465\n",
      "0.009839470498263836\n",
      "0.009783830493688583\n",
      "0.010033744387328625\n",
      "0.008410434238612652\n",
      "0.00975562073290348\n",
      "0.008428706787526608\n",
      "0.010879391804337502\n",
      "0.010725112631917\n",
      "0.009667091071605682\n",
      "0.00887077022343874\n",
      "0.008958227932453156\n",
      "0.008862845599651337\n",
      "0.00969722680747509\n",
      "0.007971849292516708\n",
      "0.011216949671506882\n",
      "0.009712839499115944\n",
      "0.009056519716978073\n",
      "0.009679694660007954\n",
      "0.009156032465398312\n",
      "0.00969627033919096\n",
      "0.00912521779537201\n",
      "0.01034238189458847\n",
      "0.010094624012708664\n",
      "0.010123669169843197\n",
      "0.009713839739561081\n",
      "0.010935083962976933\n",
      "0.00906867254525423\n",
      "0.009596256539225578\n",
      "0.008838566951453686\n",
      "0.00960936676710844\n",
      "0.008733049966394901\n",
      "0.008466674946248531\n",
      "0.010048172436654568\n",
      "0.010264109820127487\n",
      "0.009085600264370441\n",
      "0.009176183491945267\n",
      "0.010129913687705994\n",
      "0.009804834611713886\n",
      "0.009836395271122456\n",
      "0.0071215578354895115\n",
      "0.007859578356146812\n",
      "0.009968649595975876\n",
      "0.009977469220757484\n",
      "0.011221284046769142\n",
      "0.008830785751342773\n",
      "0.009723881259560585\n",
      "0.0085710808634758\n",
      "0.009383788332343102\n",
      "0.01009871531277895\n",
      "0.01056269183754921\n",
      "0.010000689886510372\n",
      "0.01097697950899601\n",
      "0.010698659345507622\n",
      "0.009800983592867851\n",
      "0.00921054556965828\n",
      "0.009650307707488537\n",
      "0.009497329592704773\n",
      "0.00995838176459074\n",
      "0.010831269435584545\n",
      "0.009134199470281601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [39:47<09:49, 98.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8328737745098039\n",
      "验证集精度0.853125\n",
      "测试集精度0.8375\n",
      "0.008865098468959332\n",
      "0.010297352448105812\n",
      "0.008917607367038727\n",
      "0.009288517758250237\n",
      "0.009219883009791374\n",
      "0.011031294241547585\n",
      "0.010901707224547863\n",
      "0.01105393748730421\n",
      "0.008079396560788155\n",
      "0.010532224550843239\n",
      "0.008544938638806343\n",
      "0.010248054750263691\n",
      "0.01126894447952509\n",
      "0.01018017902970314\n",
      "0.009418226778507233\n",
      "0.008877001702785492\n",
      "0.00901429820805788\n",
      "0.009968897327780724\n",
      "0.008665520697832108\n",
      "0.008306856267154217\n",
      "0.008875496685504913\n",
      "0.009411818347871304\n",
      "0.008794994093477726\n",
      "0.007815108634531498\n",
      "0.008554608561098576\n",
      "0.010789956897497177\n",
      "0.01049365196377039\n",
      "0.008880043402314186\n",
      "0.010085354559123516\n",
      "0.009623325429856777\n",
      "0.010538174770772457\n",
      "0.008548072539269924\n",
      "0.009758571162819862\n",
      "0.00995207391679287\n",
      "0.00914942380040884\n",
      "0.010284907184541225\n",
      "0.009610476903617382\n",
      "0.009872755967080593\n",
      "0.008893782272934914\n",
      "0.010214269161224365\n",
      "0.010297149419784546\n",
      "0.009910449385643005\n",
      "0.008910585194826126\n",
      "0.009348627179861069\n",
      "0.009999817237257957\n",
      "0.011774814687669277\n",
      "0.009997533634305\n",
      "0.008326745592057705\n",
      "0.008066769689321518\n",
      "0.009386973455548286\n",
      "0.009064320474863052\n",
      "0.009789633564651012\n",
      "0.00910071562975645\n",
      "0.009977715089917183\n",
      "0.009550973773002625\n",
      "0.00935877114534378\n",
      "0.010643853805959225\n",
      "0.009894056245684624\n",
      "0.008906126022338867\n",
      "0.009386880323290825\n",
      "0.009855440817773342\n",
      "0.010465356521308422\n",
      "0.009453277103602886\n",
      "0.009593091905117035\n",
      "0.010798354633152485\n",
      "0.00913605373352766\n",
      "0.00887608714401722\n",
      "0.011309453286230564\n",
      "0.009920614771544933\n",
      "0.01097887847572565\n",
      "0.008963281288743019\n",
      "0.011244195513427258\n",
      "0.00975519698113203\n",
      "0.009023118764162064\n",
      "0.009665493853390217\n",
      "0.011439674533903599\n",
      "0.009224793873727322\n",
      "0.009230906143784523\n",
      "0.00976190622895956\n",
      "0.010193752124905586\n",
      "0.010205447673797607\n",
      "0.008349159732460976\n",
      "0.009595412760972977\n",
      "0.009913690388202667\n",
      "0.00953599251806736\n",
      "0.010115656070411205\n",
      "0.009627489373087883\n",
      "0.00930795632302761\n",
      "0.009914398193359375\n",
      "0.010060233995318413\n",
      "0.009168222546577454\n",
      "0.008988221175968647\n",
      "0.010040192864835262\n",
      "0.009451805613934994\n",
      "0.008542048744857311\n",
      "0.009558642283082008\n",
      "0.009563944302499294\n",
      "0.011924113146960735\n",
      "0.0105671351775527\n",
      "0.008898869156837463\n",
      "0.010068065486848354\n",
      "0.009223764762282372\n",
      "0.010530048981308937\n",
      "0.010233277454972267\n",
      "0.008780915290117264\n",
      "0.009097266010940075\n",
      "0.009583007544279099\n",
      "0.010641773231327534\n",
      "0.00981922633945942\n",
      "0.010353635996580124\n",
      "0.010028870776295662\n",
      "0.009160568006336689\n",
      "0.010605684481561184\n",
      "0.009912083856761456\n",
      "0.009581676684319973\n",
      "0.009585801512002945\n",
      "0.00978420116007328\n",
      "0.008950024843215942\n",
      "0.010249480605125427\n",
      "0.009414969012141228\n",
      "0.008489478379487991\n",
      "0.008787776343524456\n",
      "0.009530606679618359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [41:27<08:13, 98.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8159466911764706\n",
      "验证集精度0.8171875\n",
      "测试集精度0.825\n",
      "0.008052539080381393\n",
      "0.009638188406825066\n",
      "0.00908012967556715\n",
      "0.009323551319539547\n",
      "0.00882197730243206\n",
      "0.00828265305608511\n",
      "0.00801941566169262\n",
      "0.010031408630311489\n",
      "0.008940067142248154\n",
      "0.009703029878437519\n",
      "0.009272134862840176\n",
      "0.008618246763944626\n",
      "0.010233504697680473\n",
      "0.009562122635543346\n",
      "0.009555662982165813\n",
      "0.008430450223386288\n",
      "0.009397304616868496\n",
      "0.010059644468128681\n",
      "0.010193166323006153\n",
      "0.00850776955485344\n",
      "0.008238918147981167\n",
      "0.010444791056215763\n",
      "0.009687060490250587\n",
      "0.011549591086804867\n",
      "0.010182449594140053\n",
      "0.01198561955243349\n",
      "0.009480899199843407\n",
      "0.010468894615769386\n",
      "0.008251050487160683\n",
      "0.010763469152152538\n",
      "0.00914197601377964\n",
      "0.009940434247255325\n",
      "0.009193042293190956\n",
      "0.009906015358865261\n",
      "0.009446429088711739\n",
      "0.009830260649323463\n",
      "0.00952183362096548\n",
      "0.008954213932156563\n",
      "0.009260612539947033\n",
      "0.009886940009891987\n",
      "0.008645668625831604\n",
      "0.009201619774103165\n",
      "0.010265651158988476\n",
      "0.009021406061947346\n",
      "0.008431105874478817\n",
      "0.010611082427203655\n",
      "0.00907858181744814\n",
      "0.007707957178354263\n",
      "0.010499680414795876\n",
      "0.009576315060257912\n",
      "0.010347743518650532\n",
      "0.009802496992051601\n",
      "0.010307056829333305\n",
      "0.009862502105534077\n",
      "0.010260624811053276\n",
      "0.010032047517597675\n",
      "0.011206655763089657\n",
      "0.009155653417110443\n",
      "0.008744163438677788\n",
      "0.009803137741982937\n",
      "0.00843153428286314\n",
      "0.010369915515184402\n",
      "0.00972664263099432\n",
      "0.009523560293018818\n",
      "0.00928724929690361\n",
      "0.010531515814363956\n",
      "0.00976580660790205\n",
      "0.009677544236183167\n",
      "0.010004173964262009\n",
      "0.00857611745595932\n",
      "0.010198536328971386\n",
      "0.00876722764223814\n",
      "0.008790634572505951\n",
      "0.010774961672723293\n",
      "0.009733986109495163\n",
      "0.009989539161324501\n",
      "0.010737664066255093\n",
      "0.009630641900002956\n",
      "0.010553509928286076\n",
      "0.009357539936900139\n",
      "0.008716738782823086\n",
      "0.009387430734932423\n",
      "0.010560906492173672\n",
      "0.009571229107677937\n",
      "0.009136229753494263\n",
      "0.009764570742845535\n",
      "0.009774035774171352\n",
      "0.010896733961999416\n",
      "0.009134255349636078\n",
      "0.009521848522126675\n",
      "0.009166319854557514\n",
      "0.009641153737902641\n",
      "0.009862342849373817\n",
      "0.010321203619241714\n",
      "0.00855231937021017\n",
      "0.011060209013521671\n",
      "0.010246006771922112\n",
      "0.00928089302033186\n",
      "0.009532079100608826\n",
      "0.00873536616563797\n",
      "0.010679221712052822\n",
      "0.008470278233289719\n",
      "0.009160135872662067\n",
      "0.00939153041690588\n",
      "0.010648037306964397\n",
      "0.008549262769520283\n",
      "0.008602146059274673\n",
      "0.008465070277452469\n",
      "0.00891834031790495\n",
      "0.009072456508874893\n",
      "0.009749631397426128\n",
      "0.008617807179689407\n",
      "0.009064068086445332\n",
      "0.010256960988044739\n",
      "0.008804586715996265\n",
      "0.010522325523197651\n",
      "0.00969923846423626\n",
      "0.009808163158595562\n",
      "0.00911146029829979\n",
      "0.009157302789390087\n",
      "0.010855036787688732\n",
      "0.008637268096208572\n",
      "0.009737375192344189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [43:02<06:29, 97.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8208486519607843\n",
      "验证集精度0.8359375\n",
      "测试集精度0.8234375\n",
      "0.009540713392198086\n",
      "0.009968076832592487\n",
      "0.009662415832281113\n",
      "0.00913469959050417\n",
      "0.009612343274056911\n",
      "0.009144005365669727\n",
      "0.009180496446788311\n",
      "0.009262006729841232\n",
      "0.010404398664832115\n",
      "0.00952397845685482\n",
      "0.009639737196266651\n",
      "0.010110546834766865\n",
      "0.009561113081872463\n",
      "0.01162030640989542\n",
      "0.009528062306344509\n",
      "0.009405463933944702\n",
      "0.008096335455775261\n",
      "0.009919309988617897\n",
      "0.009977555833756924\n",
      "0.008138786070048809\n",
      "0.009728191420435905\n",
      "0.009710940532386303\n",
      "0.010453877970576286\n",
      "0.009648878127336502\n",
      "0.010171565227210522\n",
      "0.010995272547006607\n",
      "0.009458704851567745\n",
      "0.008731557056307793\n",
      "0.009071622043848038\n",
      "0.009443048387765884\n",
      "0.010532978922128677\n",
      "0.009727302007377148\n",
      "0.010863897390663624\n",
      "0.009809225797653198\n",
      "0.01021112222224474\n",
      "0.009802869521081448\n",
      "0.010303857736289501\n",
      "0.009705061092972755\n",
      "0.008972585201263428\n",
      "0.009175046347081661\n",
      "0.010325714014470577\n",
      "0.008789554238319397\n",
      "0.009233083575963974\n",
      "0.009411320090293884\n",
      "0.00925387442111969\n",
      "0.009097698144614697\n",
      "0.008864471688866615\n",
      "0.010980802588164806\n",
      "0.009536411613225937\n",
      "0.009673448279500008\n",
      "0.010200677439570427\n",
      "0.008605509996414185\n",
      "0.009156152606010437\n",
      "0.00859730876982212\n",
      "0.009999951347708702\n",
      "0.00981482770293951\n",
      "0.010102629661560059\n",
      "0.010571262799203396\n",
      "0.010825901292264462\n",
      "0.009613659232854843\n",
      "0.009762819856405258\n",
      "0.009428205899894238\n",
      "0.009554814547300339\n",
      "0.007660428527742624\n",
      "0.010358025319874287\n",
      "0.00872197188436985\n",
      "0.009325585328042507\n",
      "0.009949618950486183\n",
      "0.009310172870755196\n",
      "0.010044260881841183\n",
      "0.00922677107155323\n",
      "0.010154820047318935\n",
      "0.009431537240743637\n",
      "0.009800051338970661\n",
      "0.009359478950500488\n",
      "0.010314752347767353\n",
      "0.010476258583366871\n",
      "0.008811011910438538\n",
      "0.008397362194955349\n",
      "0.009111853316426277\n",
      "0.009019619785249233\n",
      "0.009968098253011703\n",
      "0.010021490976214409\n",
      "0.009769861586391926\n",
      "0.009914770722389221\n",
      "0.008521858602762222\n",
      "0.009648818522691727\n",
      "0.009847994893789291\n",
      "0.009573377668857574\n",
      "0.00846657995134592\n",
      "0.010574249550700188\n",
      "0.008877221494913101\n",
      "0.00892842747271061\n",
      "0.010022689588367939\n",
      "0.010151279158890247\n",
      "0.010692762210965157\n",
      "0.007959823124110699\n",
      "0.009253021329641342\n",
      "0.009549882262945175\n",
      "0.008881328627467155\n",
      "0.008196198381483555\n",
      "0.008623844012618065\n",
      "0.00870103295892477\n",
      "0.010118002071976662\n",
      "0.009797953069210052\n",
      "0.009319063276052475\n",
      "0.009869656525552273\n",
      "0.009589902125298977\n",
      "0.008956928737461567\n",
      "0.009954061359167099\n",
      "0.009312193840742111\n",
      "0.009915187023580074\n",
      "0.009739820845425129\n",
      "0.009956377558410168\n",
      "0.010466891340911388\n",
      "0.009021195583045483\n",
      "0.009257336147129536\n",
      "0.008352547883987427\n",
      "0.00984107330441475\n",
      "0.009310543537139893\n",
      "0.008737970143556595\n",
      "0.009722274728119373\n",
      "0.009999081492424011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [44:34<04:47, 95.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8219975490196079\n",
      "验证集精度0.8375\n",
      "测试集精度0.8359375\n",
      "0.010922110639512539\n",
      "0.009769421070814133\n",
      "0.008818484842777252\n",
      "0.008261327631771564\n",
      "0.009822741150856018\n",
      "0.008952263742685318\n",
      "0.008560752496123314\n",
      "0.00849885307252407\n",
      "0.010391002520918846\n",
      "0.009083161130547523\n",
      "0.00974094308912754\n",
      "0.00856082420796156\n",
      "0.009706007316708565\n",
      "0.008265798911452293\n",
      "0.009680631570518017\n",
      "0.009745799005031586\n",
      "0.009572576731443405\n",
      "0.01109782513231039\n",
      "0.008812745101749897\n",
      "0.010204371064901352\n",
      "0.010360222309827805\n",
      "0.009956720285117626\n",
      "0.010708807967603207\n",
      "0.008876033127307892\n",
      "0.009444298222661018\n",
      "0.0097054373472929\n",
      "0.009688526391983032\n",
      "0.008948413655161858\n",
      "0.009511981159448624\n",
      "0.009436646476387978\n",
      "0.009034635499119759\n",
      "0.009736227802932262\n",
      "0.009801839478313923\n",
      "0.009825453162193298\n",
      "0.009826315566897392\n",
      "0.011111581698060036\n",
      "0.00932822935283184\n",
      "0.0109587786719203\n",
      "0.009085789322853088\n",
      "0.009414774365723133\n",
      "0.008449053391814232\n",
      "0.00925763975828886\n",
      "0.009853526949882507\n",
      "0.008549334481358528\n",
      "0.009815704077482224\n",
      "0.01001044362783432\n",
      "0.009436184540390968\n",
      "0.009516934864223003\n",
      "0.009201167151331902\n",
      "0.009741132147610188\n",
      "0.009483618661761284\n",
      "0.010303925722837448\n",
      "0.00980457104742527\n",
      "0.00982704944908619\n",
      "0.009154331870377064\n",
      "0.010649172589182854\n",
      "0.009821172803640366\n",
      "0.010005413554608822\n",
      "0.009779502637684345\n",
      "0.009977903217077255\n",
      "0.010764745995402336\n",
      "0.01021617092192173\n",
      "0.01060383953154087\n",
      "0.01008059736341238\n",
      "0.010489660315215588\n",
      "0.01066309679299593\n",
      "0.009114610031247139\n",
      "0.010444085113704205\n",
      "0.009561840444803238\n",
      "0.009078125469386578\n",
      "0.009593102149665356\n",
      "0.010677342303097248\n",
      "0.009890733286738396\n",
      "0.008786633610725403\n",
      "0.012220309115946293\n",
      "0.009370611980557442\n",
      "0.009579482488334179\n",
      "0.009978143498301506\n",
      "0.008222030475735664\n",
      "0.008279957808554173\n",
      "0.009458205662667751\n",
      "0.009037730284035206\n",
      "0.008975242264568806\n",
      "0.01166345365345478\n",
      "0.01102525182068348\n",
      "0.009304843842983246\n",
      "0.009534272365272045\n",
      "0.010689173825085163\n",
      "0.00946942251175642\n",
      "0.008518964052200317\n",
      "0.009122485294938087\n",
      "0.0105803357437253\n",
      "0.010238554328680038\n",
      "0.010340302251279354\n",
      "0.009004784747958183\n",
      "0.0087616927921772\n",
      "0.010214120149612427\n",
      "0.009056237526237965\n",
      "0.009447749704122543\n",
      "0.010808596387505531\n",
      "0.009437063708901405\n",
      "0.00988295953720808\n",
      "0.009583770297467709\n",
      "0.01001017726957798\n",
      "0.010806365869939327\n",
      "0.00791783258318901\n",
      "0.009241411462426186\n",
      "0.009424260817468166\n",
      "0.011248895898461342\n",
      "0.00942079909145832\n",
      "0.008680189028382301\n",
      "0.00996367633342743\n",
      "0.010041463188827038\n",
      "0.009473275393247604\n",
      "0.010853778570890427\n",
      "0.009119773283600807\n",
      "0.00963911134749651\n",
      "0.01014193519949913\n",
      "0.009322098456323147\n",
      "0.009768915362656116\n",
      "0.009810667484998703\n",
      "0.009928378276526928\n",
      "0.009623176418244839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [46:03<03:07, 93.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8252144607843137\n",
      "验证集精度0.840625\n",
      "测试集精度0.8328125\n",
      "0.008685808628797531\n",
      "0.010161207988858223\n",
      "0.008746443316340446\n",
      "0.009508778341114521\n",
      "0.010257238522171974\n",
      "0.010371719487011433\n",
      "0.008926598355174065\n",
      "0.008854742161929607\n",
      "0.00881875492632389\n",
      "0.009368028491735458\n",
      "0.009060421958565712\n",
      "0.010530940257012844\n",
      "0.008765297941863537\n",
      "0.008473078720271587\n",
      "0.00867580994963646\n",
      "0.011064368300139904\n",
      "0.008730716072022915\n",
      "0.00877922959625721\n",
      "0.009773384779691696\n",
      "0.008924252353608608\n",
      "0.009765992872416973\n",
      "0.009495103731751442\n",
      "0.009870795533061028\n",
      "0.010364541783928871\n",
      "0.010001796297729015\n",
      "0.010257013142108917\n",
      "0.008824372664093971\n",
      "0.010123205371201038\n",
      "0.010059359483420849\n",
      "0.009053550660610199\n",
      "0.008750144392251968\n",
      "0.008588775992393494\n",
      "0.008431319147348404\n",
      "0.009985018521547318\n",
      "0.009342371486127377\n",
      "0.010005773976445198\n",
      "0.010254683904349804\n",
      "0.00787383783608675\n",
      "0.00799548253417015\n",
      "0.010106930509209633\n",
      "0.0113831777125597\n",
      "0.00985281728208065\n",
      "0.009612825699150562\n",
      "0.010059678927063942\n",
      "0.009210425429046154\n",
      "0.008316411636769772\n",
      "0.0093700485303998\n",
      "0.009370229206979275\n",
      "0.009389683604240417\n",
      "0.008988011628389359\n",
      "0.008871035650372505\n",
      "0.00983625277876854\n",
      "0.008822440169751644\n",
      "0.01083125825971365\n",
      "0.009349729865789413\n",
      "0.008617381565272808\n",
      "0.009482154622673988\n",
      "0.010079788975417614\n",
      "0.009953254833817482\n",
      "0.008095400407910347\n",
      "0.009166013449430466\n",
      "0.009767463430762291\n",
      "0.010070467367768288\n",
      "0.007997558452188969\n",
      "0.009264156222343445\n",
      "0.009819676168262959\n",
      "0.008555685169994831\n",
      "0.009792642667889595\n",
      "0.010247752070426941\n",
      "0.008792477659881115\n",
      "0.009749796241521835\n",
      "0.011206353083252907\n",
      "0.010771570727229118\n",
      "0.009344386868178844\n",
      "0.01076135691255331\n",
      "0.010061696171760559\n",
      "0.009927566163241863\n",
      "0.009120185859501362\n",
      "0.009794855490326881\n",
      "0.010938168503344059\n",
      "0.010111858136951923\n",
      "0.00960726011544466\n",
      "0.008708336390554905\n",
      "0.010213461704552174\n",
      "0.008511773310601711\n",
      "0.010279702953994274\n",
      "0.009286140091717243\n",
      "0.009336037561297417\n",
      "0.010023031383752823\n",
      "0.009620259515941143\n",
      "0.00843912921845913\n",
      "0.010754633694887161\n",
      "0.009070669300854206\n",
      "0.009569562040269375\n",
      "0.010564462281763554\n",
      "0.008847433142364025\n",
      "0.00828030239790678\n",
      "0.010559414513409138\n",
      "0.009237443096935749\n",
      "0.008812417276203632\n",
      "0.009667426347732544\n",
      "0.010141869075596333\n",
      "0.00952980387955904\n",
      "0.008518597111105919\n",
      "0.008249706588685513\n",
      "0.010393496602773666\n",
      "0.009312513284385204\n",
      "0.008603997528553009\n",
      "0.00885702297091484\n",
      "0.010510814376175404\n",
      "0.009437784552574158\n",
      "0.010171321220695972\n",
      "0.010350631549954414\n",
      "0.009643767960369587\n",
      "0.009197421371936798\n",
      "0.009521538391709328\n",
      "0.009097883477807045\n",
      "0.009597393684089184\n",
      "0.011446150951087475\n",
      "0.008709058165550232\n",
      "0.009889199398458004\n",
      "0.009763664565980434\n",
      "0.010941051878035069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [47:31<01:32, 92.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8194699754901961\n",
      "验证集精度0.846875\n",
      "测试集精度0.8265625\n",
      "0.00837203674018383\n",
      "0.008872724138200283\n",
      "0.010100048966705799\n",
      "0.009470331482589245\n",
      "0.009097977541387081\n",
      "0.00881961453706026\n",
      "0.009340045042335987\n",
      "0.009015071205794811\n",
      "0.008490584790706635\n",
      "0.010421019978821278\n",
      "0.010465147905051708\n",
      "0.010163730010390282\n",
      "0.008880814537405968\n",
      "0.010033169761300087\n",
      "0.011232253164052963\n",
      "0.01117333211004734\n",
      "0.010881203226745129\n",
      "0.010551748797297478\n",
      "0.010236640460789204\n",
      "0.009532402269542217\n",
      "0.00887623056769371\n",
      "0.009886911138892174\n",
      "0.00903826579451561\n",
      "0.008710320107638836\n",
      "0.009438246488571167\n",
      "0.008916073478758335\n",
      "0.009982592426240444\n",
      "0.008574116043746471\n",
      "0.008929985575377941\n",
      "0.009996955282986164\n",
      "0.009509853087365627\n",
      "0.009340082295238972\n",
      "0.008911619894206524\n",
      "0.010907936841249466\n",
      "0.008928372524678707\n",
      "0.008968873880803585\n",
      "0.008693214505910873\n",
      "0.009609404020011425\n",
      "0.00922043900936842\n",
      "0.008783046156167984\n",
      "0.009224583394825459\n",
      "0.008298523724079132\n",
      "0.009123465046286583\n",
      "0.008179864846169949\n",
      "0.009547913447022438\n",
      "0.00911770574748516\n",
      "0.009242481552064419\n",
      "0.010044509544968605\n",
      "0.011057388037443161\n",
      "0.0100991390645504\n",
      "0.009086896665394306\n",
      "0.008893790654838085\n",
      "0.008835500106215477\n",
      "0.011114691384136677\n",
      "0.009476947598159313\n",
      "0.009853940457105637\n",
      "0.009469551965594292\n",
      "0.0090315667912364\n",
      "0.008742318488657475\n",
      "0.010387811809778214\n",
      "0.009575733914971352\n",
      "0.009613126516342163\n",
      "0.009459355846047401\n",
      "0.00937818456441164\n",
      "0.009817552752792835\n",
      "0.00945052970200777\n",
      "0.009728917852044106\n",
      "0.009754602797329426\n",
      "0.010175744071602821\n",
      "0.009484118781983852\n",
      "0.008458170108497143\n",
      "0.010472368448972702\n",
      "0.007554049137979746\n",
      "0.0098703783005476\n",
      "0.00994434766471386\n",
      "0.009984727017581463\n",
      "0.010372963733971119\n",
      "0.00982553232461214\n",
      "0.010172097943723202\n",
      "0.0095924511551857\n",
      "0.009712419472634792\n",
      "0.009536182507872581\n",
      "0.010499524883925915\n",
      "0.009247524663805962\n",
      "0.011162287555634975\n",
      "0.009770246222615242\n",
      "0.010454390197992325\n",
      "0.009489673189818859\n",
      "0.009841956198215485\n",
      "0.01031581312417984\n",
      "0.009727328084409237\n",
      "0.008796696551144123\n",
      "0.010725053958594799\n",
      "0.008833741769194603\n",
      "0.01082943007349968\n",
      "0.009153908118605614\n",
      "0.0073752691969275475\n",
      "0.008893268182873726\n",
      "0.00864319782704115\n",
      "0.010312831960618496\n",
      "0.011795095168054104\n",
      "0.008287729695439339\n",
      "0.009726261720061302\n",
      "0.008116970770061016\n",
      "0.010262532159686089\n",
      "0.011417055502533913\n",
      "0.009623547084629536\n",
      "0.009535906836390495\n",
      "0.009868703782558441\n",
      "0.009867970831692219\n",
      "0.010336428880691528\n",
      "0.009244218468666077\n",
      "0.009452532976865768\n",
      "0.009850072674453259\n",
      "0.0088737141340971\n",
      "0.00933467410504818\n",
      "0.009348723106086254\n",
      "0.008854766376316547\n",
      "0.00912931002676487\n",
      "0.009075808338820934\n",
      "0.010458379052579403\n",
      "0.010259109549224377\n",
      "0.01049490924924612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [49:05<00:00, 98.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8144914215686274\n",
      "验证集精度0.81875\n",
      "测试集精度0.8234375\n",
      "训练集最终精度0.8328737745098039\n",
      "验证集最终精度0.853125\n",
      "测试集最终精度0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集最终精度0.8017769607843137\n",
      "验证集最终精度0.80625\n",
      "测试集最终精度0.809375\n"
     ]
    }
   ],
   "source": [
    "'''用ood数据直接进行KL散度蒸馏studentmodel'''\n",
    "print('*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, ood_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hinton few-shotKD'''\n",
    "def train_HintonKD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs, train_original_datas, dev_original_datas, test_original_datas ):\n",
    "    device = 'cuda:1'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    max_acc_fin = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            \n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    " \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.5*loss_func2(probs_student, labels)\n",
    "            loss.backward()#这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:37<05:35, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9129901960784313\n",
      "验证集精度0.9265625\n",
      "测试集精度0.8796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:04<04:11, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9540441176470589\n",
      "验证集精度0.9578125\n",
      "测试集精度0.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:32<03:28, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9708946078431373\n",
      "验证集精度0.965625\n",
      "测试集精度0.94375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:49<02:27, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9775582107843137\n",
      "验证集精度0.9796875\n",
      "测试集精度0.95625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:03<01:45, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9781709558823529\n",
      "验证集精度0.9859375\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:25<01:24, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9788602941176471\n",
      "验证集精度0.9875\n",
      "测试集精度0.9734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:44<01:01, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9811580882352942\n",
      "验证集精度0.9859375\n",
      "测试集精度0.978125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:59<00:37, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9817708333333334\n",
      "验证集精度0.975\n",
      "测试集精度0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:13<00:17, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9820772058823529\n",
      "验证集精度0.98125\n",
      "测试集精度0.978125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:26<00:00, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9829963235294118\n",
      "验证集精度0.984375\n",
      "测试集精度0.9734375\n",
      "训练集最终精度0.9811580882352942\n",
      "验证集最终精度0.9859375\n",
      "测试集最终精度0.978125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存数据集精度0.996875\n",
      "训练集最终精度0.9823835784313726\n",
      "验证集最终精度0.9875\n",
      "测试集最终精度0.975\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''随机保存一定数量（和DI数量相同做对比）的原始数据，各个类别保存数量相等'''\n",
    "print('***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************')\n",
    "reserve_num=2000 #一共保存用于KD多少个数据\n",
    "data_num = [0 for i in range(len(train_original_labels))] #记录当前时刻每一类保存了多少个数据\n",
    "tokens_reserved = torch.tensor([])  #用于保存数据\n",
    "labels_reserved = torch.tensor([])\n",
    "\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data_num[data[1][j].item()] < int(reserve_num/len(train_original_labels)): \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "\n",
    "'''将保存的数据装入Dataloader中'''\n",
    "reserved_datasets = TensorDataset(tokens_reserved.long(), labels_reserved.long())\n",
    "reserved_datasets = DataLoader(reserved_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "'''hinton方法KD得到的模型精度'''\n",
    "train_HintonKD_student(teacher_model, bert_student, reserved_datasets, optimizer, loss_func, loss_func2, 5, 10, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_reserved, loss_reserved = Model_Train().eval_for_incremental(bert_student, reserved_datasets, loss_func2)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('保存数据集精度'+str(accuracy_reserved))\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('csuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab6d371e845a933fefd78872ae9ed5c08b7429001c2088fe7b56efc961c495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
