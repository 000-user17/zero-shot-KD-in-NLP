{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental, Data_Init\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc = nn.Linear(768, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    " \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "'''定义Bert生成模型。通过在一个OOD数据集训练让其输入噪声后可以输出在该OOD上的词汇集'''\n",
    "class Bert_Gen(nn.Module):  #Bert生成模型\n",
    "    def __init__(self, Bert_config): #tokens_len表示生成数据的长度,即最后bert要生成这么长的文本\n",
    "        super(Bert_Gen,self).__init__()\n",
    "        self.device = Bert_config.device\n",
    "        \n",
    "        self.bert1=BertModel.from_pretrained(Bert_config.bertmini_path)  #从路径加载预训练模型\n",
    "        for param in self.bert1.parameters():\n",
    "            param.requires_grad = True # 使参数可更新\n",
    "        \n",
    "        self.fc3= nn.Linear(Bert_config.hidden_size, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 30522)\n",
    "    \n",
    "    def forward(self, z): #tokens表示dataloader中的一个batch的tokens，即去掉label部分的token tensor\n",
    "        \n",
    "\n",
    "        out = z.long()#将经过线性层将正态分布z变为long型整数输入到bert\n",
    "        \n",
    "        encoder_out, pool = self.bert1(out.view(1,-1), output_all_encoded_layers=False) #得到每个token的向量表示\n",
    "        \n",
    "        out = self.fc3(encoder_out.squeeze())  \n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)  #经过线性层处理生成新的向量，和bert词表大小相同\n",
    "        out = F.gumbel_softmax(out, 10, True)\n",
    "        \n",
    "        return out  #输出一个batch的softmax [batch_size, 类别的softmax得分]\n",
    "\n",
    "\n",
    "'''用于生成DI数据印象的模型'''\n",
    "class DI_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super(DI_Gen_model,self).__init__()\n",
    "        \n",
    "        self.bert_gen = torch.load('./model/bert_genMINI3')\n",
    "        for param in self.bert_gen.parameters():    \n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.bert_cnn = teacher_model\n",
    "        for param in self.bert_cnn.parameters():    \n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, z):\n",
    "        \n",
    "        \n",
    "        tokens = self.bert_gen(z)\n",
    "        tokens = torch.argmax(tokens, dim=1, keepdim=False).long().view(1,-1)\n",
    "        \n",
    "        tokens = tokens.squeeze().tolist()\n",
    "        tokens.append(102)#添加sep符号\n",
    "        tokens.insert(0, 101) #添加cls符号\n",
    "        tokens = torch.tensor(tokens).view(1,-1).to('cuda:0')  #感觉加了之后要好一些\n",
    "        \n",
    "        self.bert_cnn.eval()\n",
    "        out = self.bert_cnn(tokens) #输入(batch_size=1, token_len)的tokens, 输出(batch_size=1, num_classes)的out\n",
    "        \n",
    "        return out, tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Train_ipynb(object):\n",
    "    def __init__(self, isTPCIL=False): #\n",
    "        #self.epochs = MyModel_Config.epochs #训练几个epochs\n",
    "        self.device = 'cuda:0'\n",
    "        self.isTPCIL = isTPCIL\n",
    "        \n",
    "    '''测试集和验证集的精度计算,用于全体验证集或测试集的精度计算\n",
    "    model：要评估的模型\n",
    "    datapath：输入字符串如'./data/snips/valid.csv'，表明要测试的验证集或测试集路径\n",
    "    mode:输入字符串'csv'或'tsv' ，表明要测试的文件格式'''\n",
    "    def my_eval(self, model, datapath, loss_func, mode, label_to_idx_train):\n",
    "        device = self.device\n",
    "        tensor_datas, labels_idx = Data_Init(datapath, 64, mode, 'eval', label_to_idx_train).datas_to_tensors()#输出都是tensor形式\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval() #eval()将我们的模型置于评估模式，而不是训练模式。在这种情况下，评估模式关闭了训练中使用的dropout正则化。\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "        with torch.no_grad():\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                #虽然这里的probs没有经过softmax处理，但也可以用下面的这个argmax公式，因为softmax不会改变原本数值元素的大小排名\n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = accuracy / (idx*tensor_datas.batch_size + last_size)\n",
    "        accuracy = accuracy.item()\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "    \n",
    "    '''由于增量学习要求对相应的增量类和原始类数据进行精度的计算，所以如果直接输入验证集路径进去，会导致计算所有类精度，所以这里输入变为直接输入数据\n",
    "    model:要进行精度计算的模型\n",
    "tensor_datas:验证集/测试集的经过Dataloader封装的数据\n",
    "loss_function:用于计算验证集/测试集损失'''\n",
    "\n",
    "    def eval_for_incremental(self, model, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        model = model.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        model.eval() #关闭模型dropout\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "#用法：\n",
    "#eval_for_incremental(model, tensor_datas, loss_function),用法在incremental_learning文件的类中\n",
    "\n",
    "\n",
    "    '''参数：\n",
    "    model：训练模型\n",
    "    loss_func:损失函数\n",
    "    optimizer:优化器\n",
    "    epochs:迭代次数\n",
    "    tensor_datas:要输入的Dataloader封装的数据，默认为MyModel_Config里面的数据\n",
    "    datapath_eval: 如果等于'none'说明不对验证集或测试集进行每个batch训练后的精度和损失计算；如果等于验证集或测试集路径，则进行计算\n",
    "    eval_mode：验证集或测试集的格式，为'csv'或'tsv'.\n",
    "    label_to_idx_train:训练集的标签字典，只有当datapath_eval不为none时候才设置初值'''\n",
    "    def my_train(self, model, loss_func, optimizer, epochs, tensor_datas, datapath_eval='none', eval_mode='csv', label_to_idx_train={}): #增加了需要自己输入的epochs\n",
    "        device = self.device\n",
    "        #epochs = self.epochs\n",
    "        model.train()\n",
    "\n",
    "        model = model.to(device)\n",
    "        losses = [] #存放所有样本一个epoch的损失\n",
    "        accuracies = []\n",
    "        iter = [] #用于绘图的横坐标\n",
    "\n",
    "        #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            '''对每个batch的训练'''\n",
    "            for idx, datas in enumerate(tensor_datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "                tokens = datas[0].to(device)\n",
    "                labels = datas[1].to(device)\n",
    "                #labels_one_hot = datas[1].to(device)  #one-hot形式标签，用于损失计算，[batch_size, labels_nums]\n",
    "                #labels = torch.topk(labels_one_hot, 1)[1].view(-1,1)   #要计算精度，就需要非one-hot形式的标签，转化为(batch_size,1)形式的标签\n",
    "        \n",
    "                optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()#学习率递减\n",
    "            accuracy_train, loss_sum = self.eval_for_incremental(model, tensor_datas, loss_func)\n",
    "    \n",
    "            if datapath_eval != 'none': \n",
    "                if label_to_idx_train == {}:\n",
    "                    raise ValueError(\"要输出测试集精度模式下需要输入训练集对应的标签字典\")\n",
    "                accuracy_eval, loss_eval = self.my_eval(model, datapath_eval, loss_func, eval_mode, label_to_idx_train)\n",
    "                print('第'+str(epoch)+'的验证集失为：'+str(loss_eval))\n",
    "                print('第'+str(epoch)+'的验证集精度为：'+str(accuracy_eval))\n",
    "            \n",
    "            accuracies.append(accuracy_train) #accuracy上的数据在cuda上，需要放到cpu上才能作图，而loss.item()已经加到cpu上了\n",
    "            losses.append(loss_sum)\n",
    "            iter.append(epoch)\n",
    "            #print(\"the loss of  training data \"+ str(epoch) + \"  is-----------\" + str(loss_sum))\n",
    "            #print(\"the accuracy of training data   \"+ str(epoch) + \"  is-----------\" + str(accuracy_train))\n",
    "    \n",
    "        #plt.figure(1)\n",
    "        #plt.title(\"loss of epoch per————\"+str(loss_func)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"loss per epoch\")\n",
    "        #plt.ylabel(\"LOSS\")\n",
    "        #plt.plot(iter, losses)\n",
    "\n",
    "        #plt.figure(2)\n",
    "        #plt.title(\"accuracy of epoch per————\"+str(accuracy_train)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"accuracy per epoch\")\n",
    "        #plt.ylabel(\"ACCURACY\")\n",
    "        #plt.plot(iter, accuracies)\n",
    "\n",
    "        #plt.show()\n",
    "        return accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:11<00:00, 55.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9859068627450981, 0.9905790441176471, 0.9931832107843137, 0.9954810049019608, 0.9931832107843137, 0.9967830882352942, 0.9983915441176471, 0.9983149509803921, 0.9990042892156863, 0.9993872549019608]\n",
      "验证集最终精度0.9875\n",
      "测试集最终精度0.98125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(teacher_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(teacher_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(teacher_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:01<00:00, 12.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.934359681372549, 0.9654564950980392, 0.9760263480392157, 0.9816176470588235, 0.9832261029411765, 0.9862132352941176, 0.9872855392156863, 0.9892769607843137, 0.9896599264705882, 0.9919577205882353]\n",
      "验证集最终精度0.9859375\n",
      "测试集最终精度0.978125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(student_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(student_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(student_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model.fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:22<00:00, 622.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15774\n"
     ]
    }
   ],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')\n",
    "\n",
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)\n",
    "\n",
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练DI生成模型'''\n",
    "def train_DI_gen(dir_samples, ood_data, DI_gen, optimizer, loss_func, loss_func2, label, temper=10, error=1.4, max_iter=True):\n",
    "    device = 'cuda:0'\n",
    "    DI_gen = DI_gen.to(device)\n",
    "    loss_num=999\n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "    DI_gen.train()\n",
    "    for i in range(len(dir_samples)):\n",
    "        count = 0\n",
    "        ood_data = ood_data.view(-1,1).to(device)\n",
    "        #z = torch.randn(30,1).to(device)\n",
    "        tokens_gens=torch.tensor([]).to(device) #选择最小损失的tokens\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            label = label.to(device).long()\n",
    "            dir_sample = dir_samples[i].to(device).view(1,-1)\n",
    "            \n",
    "            probs, tokens_gen = DI_gen(ood_data)\n",
    "            \n",
    "            #loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample)\n",
    "            #loss = 0.6*loss_func2(probs, label)\n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample) + 0.6*loss_func2(probs, label) #如果不加后面的硬性指标会使得预测的标签混乱\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokens_gens = torch.cat([tokens_gens, tokens_gen], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中bert_cnn的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "    if max_iter == True and len(tokens_gens) > 0:\n",
    "        tokens_gen = tokens_gens[torch.argmin(losses).item()]  #选择loss最小的\n",
    "            \n",
    "    return tokens_gen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义理想情况，DI数据应该对应的真实标签'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_labels = torch.tensor([])\n",
    "for i in range(len(train_original_labels)):\n",
    "    for k in [1,5]:\n",
    "        for j in range(int(DI_num/len(train_original_labels)/2)):\n",
    "            DI_labels = torch.cat([DI_labels, torch.tensor([i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1126 [00:00<?, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 1126/1126 [07:49<00:00,  2.40it/s]\n",
      "100%|██████████| 1126/1126 [07:34<00:00,  2.48it/s]\n",
      "100%|██████████| 1126/1126 [05:36<00:00,  3.34it/s]\n",
      "100%|██████████| 1126/1126 [05:29<00:00,  3.42it/s]\n",
      "100%|██████████| 1126/1126 [21:41<00:00,  1.16s/it]\n",
      "100%|██████████| 1126/1126 [19:30<00:00,  1.04s/it]\n",
      "100%|██████████| 1126/1126 [07:02<00:00,  2.67it/s]\n",
      "100%|██████████| 1126/1126 [06:54<00:00,  2.72it/s]\n",
      "100%|██████████| 1126/1126 [13:24<00:00,  1.40it/s]\n",
      "100%|██████████| 1126/1126 [13:39<00:00,  1.37it/s]\n",
      "100%|██████████| 1126/1126 [10:14<00:00,  1.83it/s]\n",
      "100%|██████████| 1126/1126 [10:29<00:00,  1.79it/s]\n",
      "100%|██████████| 1126/1126 [04:09<00:00,  4.51it/s]\n",
      "100%|██████████| 1126/1126 [04:15<00:00,  4.41it/s]\n"
     ]
    }
   ],
   "source": [
    "'''定义DI的生成模型，以及损失函数和优化器'''\n",
    "DI_gen = DI_Gen_model(teacher_model)\n",
    "loss_func = nn.KLDivLoss(reduction = 'mean')\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "\n",
    "'''生成训练集的DI'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_datas = torch.tensor([])\n",
    "ood_idx = 0\n",
    "for i in range(len(train_original_labels)):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [0.5,0.8]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in tqdm(range(int(DI_num/len(train_original_labels)/2))):\n",
    "            x = m.sample().view(1,-1)\n",
    "            \n",
    "            DI_gen = DI_Gen_model(teacher_model)\n",
    "            optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "            \n",
    "            tokens = train_DI_gen(x, torch.tensor(ood_datas[ood_idx]), DI_gen, optimizer, loss_func, loss_func2, torch.tensor([i]))\n",
    "            ood_idx += 1\n",
    "            \n",
    "            tokens = tokens.squeeze().tolist()\n",
    "            while len(tokens)<100:\n",
    "                tokens.append(0)  #padding到100\n",
    "        \n",
    "            tokens = torch.tensor(tokens)\n",
    "            DI_datas = torch.cat([DI_datas, tokens.to('cpu').view(1,-1)], dim=0)\n",
    "            \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '##pies', '##nett', '##iable', 'ara', 'victory', 'claus', '忠', 'undergone', '藤', 'acacia', 'sixteenth', '90s', 'entrepreneur', 'milos', 'bonnie', 'silvio', 'sub', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 562, 1: 8584, 2: 150, 3: 1338, 4: 948, 5: 696, 6: 3486}\n"
     ]
    }
   ],
   "source": [
    "'''随机测试DI对应的英文'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "text = tokenizer.convert_ids_to_tokens(DI_datas[10].tolist())\n",
    "print(text)\n",
    "\n",
    "DI_datasets = TensorDataset(DI_datas.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "'''观察生成DI数据的预测标签特性'''\n",
    "teacher_model.eval()\n",
    "teacher_model = teacher_model.to('cuda:0')\n",
    "DI_pred_labels = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(DI_datasets):\n",
    "        out = teacher_model(data[0].to('cuda:0').long())\n",
    "        DI_pred = torch.argmax(F.softmax(out), dim=1) #DI数据输入到bert_cnn中对应的标签\n",
    "        DI_pred_labels = torch.cat([DI_pred_labels, DI_pred.to('cpu')])\n",
    "\n",
    "DI_pred_dict = {} #记录DI预测的不同种类标签个数\n",
    "for i in range(len(train_original_labels)):\n",
    "    DI_pred_dict[i] = 0\n",
    "for i in range(len(DI_pred_labels)):\n",
    "    DI_pred_dict[DI_pred_labels[i].item()] += 1 \n",
    "print(DI_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''将DI文件装入Dataloader中'''\n",
    "DI_datasets = TensorDataset(DI_datas.long(), DI_pred_labels.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:0')\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:0'))\n",
    "        x = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 0, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 0, 0, 6, 6, 6, 6, 3, 6, 3, 0, 6, 0,\n",
      "        6, 0, 0, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 0, 2, 0, 3, 6, 3, 1, 6, 3, 1, 6,\n",
      "        1, 6, 6, 0, 6, 6, 2, 0, 0, 0, 0, 3, 6, 6, 6, 0, 0, 1, 6, 0, 6, 0, 6, 6,\n",
      "        6, 1, 6, 6, 0, 6, 6, 0, 3, 6, 6, 4, 0, 6, 3, 0, 1, 6, 3, 1, 0, 0, 6, 1,\n",
      "        3, 1, 6, 6, 6, 6, 0, 6, 6, 3, 0, 6, 6, 6, 6, 1, 0, 6, 6, 6, 0, 6, 3, 1,\n",
      "        6, 6, 6, 6, 6, 6, 6, 1], device='cuda:0')\n",
      "tensor([[0.2010, 0.0630, 0.0619, 0.0419, 0.0117, 0.0192, 0.6013],\n",
      "        [0.4994, 0.2625, 0.0220, 0.0270, 0.0349, 0.0212, 0.1330],\n",
      "        [0.2304, 0.0640, 0.0654, 0.0372, 0.0510, 0.0363, 0.5158],\n",
      "        [0.0167, 0.0089, 0.0037, 0.0157, 0.0021, 0.0101, 0.9428],\n",
      "        [0.0742, 0.1276, 0.0529, 0.0958, 0.0184, 0.0173, 0.6137],\n",
      "        [0.1463, 0.0460, 0.0119, 0.0202, 0.0236, 0.0065, 0.7455],\n",
      "        [0.0714, 0.0225, 0.0441, 0.0425, 0.0125, 0.0163, 0.7908],\n",
      "        [0.1343, 0.0924, 0.0911, 0.1272, 0.0358, 0.0163, 0.5029],\n",
      "        [0.0337, 0.0223, 0.0619, 0.0531, 0.0062, 0.0544, 0.7683],\n",
      "        [0.6069, 0.1249, 0.0395, 0.0963, 0.0630, 0.0107, 0.0587],\n",
      "        [0.1615, 0.2806, 0.0505, 0.0293, 0.1743, 0.0137, 0.2901],\n",
      "        [0.1080, 0.1232, 0.0799, 0.1083, 0.0851, 0.0076, 0.4878],\n",
      "        [0.3603, 0.2839, 0.0619, 0.0894, 0.0969, 0.0185, 0.0891],\n",
      "        [0.5415, 0.1791, 0.0596, 0.0309, 0.0331, 0.0189, 0.1367],\n",
      "        [0.1736, 0.0275, 0.0394, 0.1584, 0.1070, 0.0209, 0.4732],\n",
      "        [0.2853, 0.1179, 0.0533, 0.0679, 0.0576, 0.0217, 0.3965],\n",
      "        [0.0681, 0.0239, 0.2766, 0.2484, 0.0160, 0.0208, 0.3463],\n",
      "        [0.1535, 0.2850, 0.0842, 0.0540, 0.0352, 0.0179, 0.3702],\n",
      "        [0.0492, 0.0334, 0.0248, 0.6293, 0.0214, 0.0480, 0.1939],\n",
      "        [0.1302, 0.2393, 0.0659, 0.0379, 0.0346, 0.0332, 0.4588],\n",
      "        [0.0227, 0.0265, 0.0334, 0.6678, 0.0652, 0.0340, 0.1503],\n",
      "        [0.4892, 0.1231, 0.0905, 0.0368, 0.1179, 0.0217, 0.1208],\n",
      "        [0.0327, 0.0408, 0.0550, 0.0610, 0.0278, 0.0063, 0.7764],\n",
      "        [0.5585, 0.1636, 0.0126, 0.0471, 0.0989, 0.0144, 0.1049],\n",
      "        [0.0722, 0.1364, 0.0868, 0.0357, 0.0402, 0.0096, 0.6190],\n",
      "        [0.2973, 0.2390, 0.1094, 0.1452, 0.0467, 0.0437, 0.1187],\n",
      "        [0.5118, 0.2008, 0.0148, 0.0534, 0.0383, 0.0154, 0.1655],\n",
      "        [0.1634, 0.0965, 0.0312, 0.0744, 0.0738, 0.1382, 0.4225],\n",
      "        [0.1256, 0.1330, 0.0323, 0.4031, 0.0150, 0.0261, 0.2649],\n",
      "        [0.0248, 0.0598, 0.0174, 0.0456, 0.0051, 0.0186, 0.8288],\n",
      "        [0.2482, 0.0910, 0.0174, 0.0399, 0.0093, 0.0128, 0.5814],\n",
      "        [0.0409, 0.1401, 0.0082, 0.4193, 0.2572, 0.0605, 0.0738],\n",
      "        [0.0334, 0.0386, 0.1819, 0.1326, 0.0258, 0.0374, 0.5502],\n",
      "        [0.0459, 0.0489, 0.0211, 0.0571, 0.0179, 0.0101, 0.7992],\n",
      "        [0.0237, 0.0247, 0.0645, 0.1885, 0.0154, 0.0262, 0.6570],\n",
      "        [0.0670, 0.0350, 0.0546, 0.0624, 0.0168, 0.0088, 0.7555],\n",
      "        [0.0908, 0.0386, 0.0224, 0.0313, 0.0134, 0.0157, 0.7879],\n",
      "        [0.4769, 0.1467, 0.0325, 0.1385, 0.1146, 0.0209, 0.0697],\n",
      "        [0.0445, 0.0899, 0.4528, 0.2126, 0.0222, 0.0089, 0.1692],\n",
      "        [0.3971, 0.0758, 0.0448, 0.0346, 0.0427, 0.0121, 0.3928],\n",
      "        [0.1193, 0.0195, 0.0345, 0.4132, 0.0432, 0.0512, 0.3191],\n",
      "        [0.1698, 0.0418, 0.0413, 0.1757, 0.0213, 0.0172, 0.5329],\n",
      "        [0.1865, 0.0920, 0.0166, 0.2325, 0.2203, 0.0504, 0.2017],\n",
      "        [0.2541, 0.2811, 0.0383, 0.0765, 0.0642, 0.0174, 0.2685],\n",
      "        [0.2259, 0.0137, 0.0393, 0.2192, 0.0484, 0.0518, 0.4017],\n",
      "        [0.1999, 0.0599, 0.1156, 0.5003, 0.0182, 0.0166, 0.0895],\n",
      "        [0.1823, 0.3270, 0.0653, 0.1446, 0.0501, 0.0101, 0.2207],\n",
      "        [0.3143, 0.0936, 0.0172, 0.0679, 0.0809, 0.0357, 0.3904],\n",
      "        [0.1270, 0.3923, 0.0258, 0.1302, 0.0376, 0.0202, 0.2669],\n",
      "        [0.0307, 0.0357, 0.1663, 0.1910, 0.0059, 0.0264, 0.5440],\n",
      "        [0.1189, 0.1804, 0.0384, 0.1016, 0.0451, 0.0262, 0.4896],\n",
      "        [0.6372, 0.1233, 0.0564, 0.0324, 0.0291, 0.0199, 0.1018],\n",
      "        [0.0651, 0.0391, 0.0431, 0.2033, 0.0090, 0.0143, 0.6262],\n",
      "        [0.0365, 0.0148, 0.0148, 0.1894, 0.1523, 0.0781, 0.5142],\n",
      "        [0.1956, 0.1384, 0.2592, 0.1680, 0.0906, 0.0536, 0.0947],\n",
      "        [0.6275, 0.1442, 0.0649, 0.0540, 0.0106, 0.0063, 0.0925],\n",
      "        [0.5200, 0.1186, 0.0574, 0.0362, 0.0167, 0.0505, 0.2006],\n",
      "        [0.3023, 0.2931, 0.0391, 0.0270, 0.0523, 0.0476, 0.2386],\n",
      "        [0.4292, 0.1104, 0.0284, 0.0747, 0.0241, 0.0112, 0.3220],\n",
      "        [0.1076, 0.1836, 0.1456, 0.3367, 0.0669, 0.0080, 0.1516],\n",
      "        [0.3689, 0.0846, 0.0280, 0.0777, 0.0147, 0.0184, 0.4078],\n",
      "        [0.2910, 0.1253, 0.0914, 0.0893, 0.0596, 0.0338, 0.3096],\n",
      "        [0.0678, 0.0465, 0.0732, 0.2278, 0.0207, 0.0373, 0.5266],\n",
      "        [0.5589, 0.1386, 0.0484, 0.0302, 0.0173, 0.0182, 0.1884],\n",
      "        [0.4528, 0.1522, 0.0156, 0.0869, 0.0248, 0.0256, 0.2421],\n",
      "        [0.2787, 0.4583, 0.0475, 0.0930, 0.0603, 0.0099, 0.0523],\n",
      "        [0.0827, 0.0766, 0.0327, 0.1631, 0.0185, 0.0096, 0.6168],\n",
      "        [0.5252, 0.1148, 0.0485, 0.1128, 0.0827, 0.0125, 0.1034],\n",
      "        [0.1038, 0.1098, 0.0261, 0.2869, 0.0287, 0.0256, 0.4191],\n",
      "        [0.2914, 0.2227, 0.0224, 0.1453, 0.0765, 0.0330, 0.2087],\n",
      "        [0.1030, 0.0969, 0.3098, 0.0417, 0.0090, 0.0111, 0.4286],\n",
      "        [0.2582, 0.0460, 0.0517, 0.1488, 0.0244, 0.0087, 0.4622],\n",
      "        [0.1713, 0.1451, 0.0997, 0.1073, 0.1426, 0.0118, 0.3222],\n",
      "        [0.0772, 0.3856, 0.0469, 0.1894, 0.0255, 0.0782, 0.1972],\n",
      "        [0.3002, 0.1391, 0.0574, 0.1321, 0.0174, 0.0114, 0.3424],\n",
      "        [0.0928, 0.0202, 0.0371, 0.1590, 0.0064, 0.0191, 0.6654],\n",
      "        [0.3764, 0.1079, 0.0496, 0.1258, 0.0394, 0.0141, 0.2868],\n",
      "        [0.0196, 0.0788, 0.0411, 0.0498, 0.0207, 0.0298, 0.7602],\n",
      "        [0.1880, 0.3091, 0.0532, 0.0502, 0.0378, 0.0249, 0.3369],\n",
      "        [0.6000, 0.1771, 0.0191, 0.0156, 0.0160, 0.0096, 0.1626],\n",
      "        [0.0478, 0.0284, 0.0456, 0.4169, 0.0372, 0.0271, 0.3970],\n",
      "        [0.0539, 0.0854, 0.0443, 0.0152, 0.0082, 0.0076, 0.7854],\n",
      "        [0.0355, 0.0318, 0.2308, 0.0250, 0.0076, 0.0344, 0.6349],\n",
      "        [0.1946, 0.0833, 0.0145, 0.1652, 0.4433, 0.0262, 0.0730],\n",
      "        [0.3274, 0.0644, 0.0436, 0.1721, 0.0716, 0.0414, 0.2795],\n",
      "        [0.1613, 0.0895, 0.0619, 0.0772, 0.0255, 0.0076, 0.5770],\n",
      "        [0.0696, 0.0444, 0.2258, 0.3712, 0.0282, 0.0925, 0.1684],\n",
      "        [0.5755, 0.1848, 0.0275, 0.0288, 0.0243, 0.0096, 0.1496],\n",
      "        [0.2025, 0.5014, 0.0621, 0.0486, 0.0501, 0.0077, 0.1276],\n",
      "        [0.1367, 0.0638, 0.0460, 0.0507, 0.0184, 0.0134, 0.6710],\n",
      "        [0.1955, 0.0532, 0.0887, 0.4716, 0.0269, 0.0111, 0.1529],\n",
      "        [0.1807, 0.5162, 0.0159, 0.0455, 0.0390, 0.0208, 0.1819],\n",
      "        [0.3877, 0.1809, 0.0916, 0.0393, 0.0740, 0.0170, 0.2096],\n",
      "        [0.3734, 0.1761, 0.0920, 0.1686, 0.0375, 0.0160, 0.1365],\n",
      "        [0.0841, 0.0694, 0.0437, 0.3152, 0.0799, 0.0382, 0.3695],\n",
      "        [0.2462, 0.2850, 0.0593, 0.0981, 0.0357, 0.0126, 0.2630],\n",
      "        [0.0821, 0.0504, 0.1712, 0.3346, 0.0640, 0.0218, 0.2758],\n",
      "        [0.1721, 0.5935, 0.0453, 0.0703, 0.0559, 0.0196, 0.0434],\n",
      "        [0.2169, 0.0728, 0.0272, 0.0684, 0.0287, 0.0209, 0.5651],\n",
      "        [0.2338, 0.1541, 0.0456, 0.0927, 0.0110, 0.0288, 0.4339],\n",
      "        [0.1506, 0.0810, 0.0571, 0.0364, 0.0384, 0.0218, 0.6147],\n",
      "        [0.1986, 0.1172, 0.0600, 0.0119, 0.0730, 0.0140, 0.5253],\n",
      "        [0.3964, 0.1024, 0.0315, 0.0337, 0.0596, 0.0371, 0.3392],\n",
      "        [0.0308, 0.0804, 0.0198, 0.2131, 0.0819, 0.0362, 0.5378],\n",
      "        [0.0788, 0.0261, 0.0278, 0.0500, 0.0100, 0.2399, 0.5674],\n",
      "        [0.0773, 0.0588, 0.0432, 0.3183, 0.0784, 0.1482, 0.2758],\n",
      "        [0.3150, 0.2247, 0.0473, 0.0437, 0.1252, 0.0143, 0.2297],\n",
      "        [0.2819, 0.0838, 0.0516, 0.0483, 0.0210, 0.0115, 0.5019],\n",
      "        [0.0724, 0.1649, 0.0813, 0.1550, 0.0769, 0.0149, 0.4345],\n",
      "        [0.0959, 0.0633, 0.0443, 0.0785, 0.0369, 0.0581, 0.6231],\n",
      "        [0.1716, 0.1030, 0.0845, 0.1031, 0.0201, 0.0259, 0.4917],\n",
      "        [0.0481, 0.7559, 0.0224, 0.0353, 0.0213, 0.0174, 0.0996],\n",
      "        [0.6342, 0.2336, 0.0195, 0.0244, 0.0185, 0.0119, 0.0580],\n",
      "        [0.0621, 0.0548, 0.0696, 0.0534, 0.0347, 0.0154, 0.7102],\n",
      "        [0.0891, 0.0583, 0.0292, 0.1207, 0.0334, 0.0172, 0.6522],\n",
      "        [0.2683, 0.0623, 0.0194, 0.0494, 0.0383, 0.0215, 0.5408],\n",
      "        [0.4594, 0.2254, 0.0435, 0.0522, 0.0345, 0.0349, 0.1501],\n",
      "        [0.0605, 0.0871, 0.3305, 0.0571, 0.0171, 0.0312, 0.4165],\n",
      "        [0.1364, 0.0811, 0.1456, 0.3223, 0.0155, 0.0161, 0.2830],\n",
      "        [0.3114, 0.4002, 0.1290, 0.0364, 0.0213, 0.0067, 0.0950],\n",
      "        [0.2946, 0.0745, 0.0634, 0.0711, 0.0190, 0.0255, 0.4520],\n",
      "        [0.2670, 0.1914, 0.0604, 0.0494, 0.0381, 0.0138, 0.3799],\n",
      "        [0.0709, 0.0290, 0.0506, 0.0715, 0.0407, 0.0199, 0.7174],\n",
      "        [0.0284, 0.0693, 0.0614, 0.1595, 0.0421, 0.0208, 0.6184],\n",
      "        [0.1107, 0.0687, 0.0343, 0.0699, 0.1728, 0.0147, 0.5289],\n",
      "        [0.3290, 0.0534, 0.0281, 0.0197, 0.0144, 0.0090, 0.5464],\n",
      "        [0.2921, 0.1199, 0.0353, 0.0540, 0.0478, 0.0220, 0.4290],\n",
      "        [0.2547, 0.3878, 0.0388, 0.0872, 0.0652, 0.0221, 0.1442]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(F.softmax(test_output, dim=1), dim=1))\n",
    "indexs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "print(F.softmax(test_output, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6013, device='cuda:0')\n",
      "tensor(0.4994, device='cuda:0')\n",
      "tensor(0.5158, device='cuda:0')\n",
      "tensor(0.9428, device='cuda:0')\n",
      "tensor(0.6137, device='cuda:0')\n",
      "tensor(0.7455, device='cuda:0')\n",
      "tensor(0.7908, device='cuda:0')\n",
      "tensor(0.5029, device='cuda:0')\n",
      "tensor(0.7683, device='cuda:0')\n",
      "tensor(0.6069, device='cuda:0')\n",
      "tensor(0.2901, device='cuda:0')\n",
      "tensor(0.4878, device='cuda:0')\n",
      "tensor(0.3603, device='cuda:0')\n",
      "tensor(0.5415, device='cuda:0')\n",
      "tensor(0.4732, device='cuda:0')\n",
      "tensor(0.3965, device='cuda:0')\n",
      "tensor(0.3463, device='cuda:0')\n",
      "tensor(0.3702, device='cuda:0')\n",
      "tensor(0.6293, device='cuda:0')\n",
      "tensor(0.4588, device='cuda:0')\n",
      "tensor(0.6678, device='cuda:0')\n",
      "tensor(0.4892, device='cuda:0')\n",
      "tensor(0.7764, device='cuda:0')\n",
      "tensor(0.5585, device='cuda:0')\n",
      "tensor(0.6190, device='cuda:0')\n",
      "tensor(0.2973, device='cuda:0')\n",
      "tensor(0.5118, device='cuda:0')\n",
      "tensor(0.4225, device='cuda:0')\n",
      "tensor(0.4031, device='cuda:0')\n",
      "tensor(0.8288, device='cuda:0')\n",
      "tensor(0.5814, device='cuda:0')\n",
      "tensor(0.4193, device='cuda:0')\n",
      "tensor(0.5502, device='cuda:0')\n",
      "tensor(0.7992, device='cuda:0')\n",
      "tensor(0.6570, device='cuda:0')\n",
      "tensor(0.7555, device='cuda:0')\n",
      "tensor(0.7879, device='cuda:0')\n",
      "tensor(0.4769, device='cuda:0')\n",
      "tensor(0.4528, device='cuda:0')\n",
      "tensor(0.3971, device='cuda:0')\n",
      "tensor(0.4132, device='cuda:0')\n",
      "tensor(0.5329, device='cuda:0')\n",
      "tensor(0.2325, device='cuda:0')\n",
      "tensor(0.2811, device='cuda:0')\n",
      "tensor(0.4017, device='cuda:0')\n",
      "tensor(0.5003, device='cuda:0')\n",
      "tensor(0.3270, device='cuda:0')\n",
      "tensor(0.3904, device='cuda:0')\n",
      "tensor(0.3923, device='cuda:0')\n",
      "tensor(0.5440, device='cuda:0')\n",
      "tensor(0.4896, device='cuda:0')\n",
      "tensor(0.6372, device='cuda:0')\n",
      "tensor(0.6262, device='cuda:0')\n",
      "tensor(0.5142, device='cuda:0')\n",
      "tensor(0.2592, device='cuda:0')\n",
      "tensor(0.6275, device='cuda:0')\n",
      "tensor(0.5200, device='cuda:0')\n",
      "tensor(0.3023, device='cuda:0')\n",
      "tensor(0.4292, device='cuda:0')\n",
      "tensor(0.3367, device='cuda:0')\n",
      "tensor(0.4078, device='cuda:0')\n",
      "tensor(0.3096, device='cuda:0')\n",
      "tensor(0.5266, device='cuda:0')\n",
      "tensor(0.5589, device='cuda:0')\n",
      "tensor(0.4528, device='cuda:0')\n",
      "tensor(0.4583, device='cuda:0')\n",
      "tensor(0.6168, device='cuda:0')\n",
      "tensor(0.5252, device='cuda:0')\n",
      "tensor(0.4191, device='cuda:0')\n",
      "tensor(0.2914, device='cuda:0')\n",
      "tensor(0.4286, device='cuda:0')\n",
      "tensor(0.4622, device='cuda:0')\n",
      "tensor(0.3222, device='cuda:0')\n",
      "tensor(0.3856, device='cuda:0')\n",
      "tensor(0.3424, device='cuda:0')\n",
      "tensor(0.6654, device='cuda:0')\n",
      "tensor(0.3764, device='cuda:0')\n",
      "tensor(0.7602, device='cuda:0')\n",
      "tensor(0.3369, device='cuda:0')\n",
      "tensor(0.6000, device='cuda:0')\n",
      "tensor(0.4169, device='cuda:0')\n",
      "tensor(0.7854, device='cuda:0')\n",
      "tensor(0.6349, device='cuda:0')\n",
      "tensor(0.4433, device='cuda:0')\n",
      "tensor(0.3274, device='cuda:0')\n",
      "tensor(0.5770, device='cuda:0')\n",
      "tensor(0.3712, device='cuda:0')\n",
      "tensor(0.5755, device='cuda:0')\n",
      "tensor(0.5014, device='cuda:0')\n",
      "tensor(0.6710, device='cuda:0')\n",
      "tensor(0.4716, device='cuda:0')\n",
      "tensor(0.5162, device='cuda:0')\n",
      "tensor(0.3877, device='cuda:0')\n",
      "tensor(0.3734, device='cuda:0')\n",
      "tensor(0.3695, device='cuda:0')\n",
      "tensor(0.2850, device='cuda:0')\n",
      "tensor(0.3346, device='cuda:0')\n",
      "tensor(0.5935, device='cuda:0')\n",
      "tensor(0.5651, device='cuda:0')\n",
      "tensor(0.4339, device='cuda:0')\n",
      "tensor(0.6147, device='cuda:0')\n",
      "tensor(0.5253, device='cuda:0')\n",
      "tensor(0.3964, device='cuda:0')\n",
      "tensor(0.5378, device='cuda:0')\n",
      "tensor(0.5674, device='cuda:0')\n",
      "tensor(0.3183, device='cuda:0')\n",
      "tensor(0.3150, device='cuda:0')\n",
      "tensor(0.5019, device='cuda:0')\n",
      "tensor(0.4345, device='cuda:0')\n",
      "tensor(0.6231, device='cuda:0')\n",
      "tensor(0.4917, device='cuda:0')\n",
      "tensor(0.7559, device='cuda:0')\n",
      "tensor(0.6342, device='cuda:0')\n",
      "tensor(0.7102, device='cuda:0')\n",
      "tensor(0.6522, device='cuda:0')\n",
      "tensor(0.5408, device='cuda:0')\n",
      "tensor(0.4594, device='cuda:0')\n",
      "tensor(0.4165, device='cuda:0')\n",
      "tensor(0.3223, device='cuda:0')\n",
      "tensor(0.4002, device='cuda:0')\n",
      "tensor(0.4520, device='cuda:0')\n",
      "tensor(0.3799, device='cuda:0')\n",
      "tensor(0.7174, device='cuda:0')\n",
      "tensor(0.6184, device='cuda:0')\n",
      "tensor(0.5289, device='cuda:0')\n",
      "tensor(0.5464, device='cuda:0')\n",
      "tensor(0.4290, device='cuda:0')\n",
      "tensor(0.3878, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(indexs)):\n",
    "    print(F.softmax(test_output, dim=1)[i][indexs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7218\n",
      "15744\n"
     ]
    }
   ],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:0')\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    test_num = 0\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:0'))\n",
    "        idxs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "        for j in range(len(idxs)):\n",
    "            if F.softmax(test_output, dim=1)[j][idxs[j]] > 0.50:\n",
    "                count+=1\n",
    "            test_num += 1\n",
    "print(count)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:0'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            student_model = student_model.to(device)\n",
    "            tokens = tokens.to(device)   #纵使把cuda:1全部替换为cuda:0了，也会报错显卡错误，所以加上这两条就没问题了\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward()  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.1365655637254902\n",
      "0.14375\n",
      "0.134375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "  3%|▎         | 1/30 [02:37<1:15:58, 157.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.3980545343137255\n",
      "验证集精度0.4078125\n",
      "测试集精度0.4703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:12<1:12:49, 156.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6878063725490197\n",
      "验证集精度0.703125\n",
      "测试集精度0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:20<1:04:28, 143.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8193933823529411\n",
      "验证集精度0.8203125\n",
      "测试集精度0.81875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [09:25<58:55, 135.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8641237745098039\n",
      "验证集精度0.8625\n",
      "测试集精度0.853125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [11:30<55:03, 132.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9039522058823529\n",
      "验证集精度0.8875\n",
      "测试集精度0.884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [13:32<51:29, 128.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9240196078431373\n",
      "验证集精度0.91875\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [15:39<49:07, 128.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9142922794117647\n",
      "验证集精度0.9140625\n",
      "测试集精度0.896875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [17:30<44:59, 122.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9242493872549019\n",
      "验证集精度0.928125\n",
      "测试集精度0.915625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [19:22<41:44, 119.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9371170343137255\n",
      "验证集精度0.9390625\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [21:04<38:00, 114.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9275428921568627\n",
      "验证集精度0.9296875\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [22:56<35:51, 113.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9312959558823529\n",
      "验证集精度0.93125\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [24:40<33:07, 110.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9319852941176471\n",
      "验证集精度0.9234375\n",
      "测试集精度0.915625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [26:27<30:59, 109.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9266237745098039\n",
      "验证集精度0.9125\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [28:13<28:57, 108.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9361979166666666\n",
      "验证集精度0.940625\n",
      "测试集精度0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [30:02<27:08, 108.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.930453431372549\n",
      "验证集精度0.9328125\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [31:52<25:28, 109.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9244025735294118\n",
      "验证集精度0.915625\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [33:39<23:28, 108.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9291513480392157\n",
      "验证集精度0.9265625\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [35:27<21:40, 108.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9309895833333334\n",
      "验证集精度0.9359375\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [37:16<19:53, 108.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9264705882352942\n",
      "验证集精度0.9265625\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [39:07<18:11, 109.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9375\n",
      "验证集精度0.94375\n",
      "测试集精度0.9171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [41:03<16:41, 111.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9329044117647058\n",
      "验证集精度0.9265625\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [42:50<14:41, 110.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9334405637254902\n",
      "验证集精度0.9296875\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [44:33<12:34, 107.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9308363970588235\n",
      "验证集精度0.928125\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [46:24<10:52, 108.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9378829656862745\n",
      "验证集精度0.93125\n",
      "测试集精度0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [48:17<09:09, 109.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9358915441176471\n",
      "验证集精度0.9203125\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [50:01<07:13, 108.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9338235294117647\n",
      "验证集精度0.934375\n",
      "测试集精度0.91875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [51:51<05:26, 108.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9422487745098039\n",
      "验证集精度0.9375\n",
      "测试集精度0.91875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [53:42<03:39, 109.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9401807598039216\n",
      "验证集精度0.9328125\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [55:31<01:49, 109.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9385723039215687\n",
      "验证集精度0.921875\n",
      "测试集精度0.91875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [57:20<00:00, 114.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9397212009803921\n",
      "验证集精度0.934375\n",
      "测试集精度0.9125\n",
      "训练集最终精度0.9361979166666666\n",
      "验证集最终精度0.940625\n",
      "测试集最终精度0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, DI_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "#train_KD_student(bert_cnn, bert_cnn_student, DI_datasets_padding, optimizer, loss_func, loss_func2, 5, 30) #用padding后的DI来KD，对比OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:28<00:00, 618.94it/s] \n"
     ]
    }
   ],
   "source": [
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15751\n"
     ]
    }
   ],
   "source": [
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        temp[i].insert(0,101)\n",
    "        temp[i].append(102)\n",
    "        while len(tokens[i]) <100:\n",
    "            temp[i].append(0)  #padding\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取ood数据的平均长度为：31.243857532855056\n"
     ]
    }
   ],
   "source": [
    "counts =0\n",
    "for data in ood_datas:\n",
    "    count = 0\n",
    "    for j in range(len(data)):\n",
    "        if data[j] == 0:\n",
    "            break\n",
    "        count += 1\n",
    "    counts += count\n",
    "ave = counts / len(ood_datas)\n",
    "print('选取ood数据的平均长度为：'+ str(ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_datasets = TensorDataset(torch.tensor(ood_datas).long())\n",
    "ood_datasets = DataLoader(ood_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_number = 8000\n",
    "ood_datas_2 = torch.tensor([])\n",
    "\n",
    "for i,data in enumerate(ood_datasets):\n",
    "    if len(ood_datas_2) > 8000:\n",
    "        break\n",
    "    ood_datas_2 = torch.cat([ood_datas_2, data[0]], dim=0)\n",
    "ood_datasets_4000 = TensorDataset(ood_datas_2.long())\n",
    "ood_datasets_4000 = DataLoader(ood_datasets_4000, batch_size=64, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:55<1:24:44, 175.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.5504748774509803\n",
      "验证集精度0.5359375\n",
      "测试集精度0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:09<1:10:36, 151.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7359068627450981\n",
      "验证集精度0.721875\n",
      "测试集精度0.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:27<1:05:14, 144.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8315716911764706\n",
      "验证集精度0.8375\n",
      "测试集精度0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [09:15<56:36, 130.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8622089460784313\n",
      "验证集精度0.859375\n",
      "测试集精度0.83125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [11:12<52:15, 125.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8834252450980392\n",
      "验证集精度0.8640625\n",
      "测试集精度0.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [13:04<48:20, 120.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9034926470588235\n",
      "验证集精度0.8796875\n",
      "测试集精度0.871875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [15:01<45:56, 119.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9100796568627451\n",
      "验证集精度0.8828125\n",
      "测试集精度0.8828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [16:49<42:29, 115.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9227941176470589\n",
      "验证集精度0.9171875\n",
      "测试集精度0.8921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [18:38<39:51, 113.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9150582107843137\n",
      "验证集精度0.8953125\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [20:25<37:13, 111.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9207261029411765\n",
      "验证集精度0.8984375\n",
      "测试集精度0.896875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [22:19<35:37, 112.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9202665441176471\n",
      "验证集精度0.909375\n",
      "测试集精度0.8984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [24:11<33:41, 112.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9212622549019608\n",
      "验证集精度0.9078125\n",
      "测试集精度0.8984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [26:05<31:58, 112.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9140625\n",
      "验证集精度0.9\n",
      "测试集精度0.8984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [28:06<30:42, 115.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9145986519607843\n",
      "验证集精度0.903125\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [30:06<29:08, 116.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9204197303921569\n",
      "验证集精度0.90625\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [31:55<26:42, 114.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9195772058823529\n",
      "验证集精度0.9171875\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [33:44<24:26, 112.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9201133578431373\n",
      "验证集精度0.9140625\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [35:32<22:15, 111.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9253216911764706\n",
      "验证集精度0.9078125\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [37:23<20:23, 111.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9225643382352942\n",
      "验证集精度0.903125\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [39:15<18:33, 111.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9240962009803921\n",
      "验证集精度0.9140625\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [41:12<16:57, 113.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9193474264705882\n",
      "验证集精度0.8984375\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [43:05<15:04, 113.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9168198529411765\n",
      "验证集精度0.9109375\n",
      "测试集精度0.91875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [44:51<12:56, 111.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9230238970588235\n",
      "验证集精度0.9078125\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [46:34<10:52, 108.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9160539215686274\n",
      "验证集精度0.89375\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [48:25<09:06, 109.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9228707107843137\n",
      "验证集精度0.9\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [50:10<07:11, 107.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9140625\n",
      "验证集精度0.9109375\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [51:58<05:24, 108.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9214154411764706\n",
      "验证集精度0.9140625\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [53:47<03:36, 108.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9120710784313726\n",
      "验证集精度0.8921875\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [55:41<01:50, 110.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9116115196078431\n",
      "验证集精度0.896875\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [57:29<00:00, 114.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9198835784313726\n",
      "验证集精度0.90625\n",
      "测试集精度0.9109375\n",
      "训练集最终精度0.9168198529411765\n",
      "验证集最终精度0.9109375\n",
      "测试集最终精度0.91875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集最终精度0.9100030637254902\n",
      "验证集最终精度0.8953125\n",
      "测试集最终精度0.89375\n"
     ]
    }
   ],
   "source": [
    "'''用ood数据直接进行KL散度蒸馏studentmodel'''\n",
    "print('*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, ood_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hinton few-shotKD'''\n",
    "def train_HintonKD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs, train_original_datas, dev_original_datas, test_original_datas ):\n",
    "    device = 'cuda:0'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    max_acc_fin = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            \n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    " \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.5*loss_func2(probs_student, labels)\n",
    "            loss.backward()#这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:15<04:45, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6135110294117647\n",
      "验证集精度0.615625\n",
      "测试集精度0.5890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:30<04:30, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8386948529411765\n",
      "验证集精度0.8578125\n",
      "测试集精度0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:45<04:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9138327205882353\n",
      "验证集精度0.921875\n",
      "测试集精度0.8859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:49<02:53, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9273897058823529\n",
      "验证集精度0.9375\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:57<02:27,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9501378676470589\n",
      "验证集精度0.9546875\n",
      "测试集精度0.9234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:07<02:17,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9578737745098039\n",
      "验证集精度0.9609375\n",
      "测试集精度0.9359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:15<01:59,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9605545343137255\n",
      "验证集精度0.96875\n",
      "测试集精度0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:21<01:39,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9653033088235294\n",
      "验证集精度0.9671875\n",
      "测试集精度0.946875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:27<01:23,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9677542892156863\n",
      "验证集精度0.9703125\n",
      "测试集精度0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:39<01:27,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9688265931372549\n",
      "验证集精度0.971875\n",
      "测试集精度0.9546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:47<01:16,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9707414215686274\n",
      "验证集精度0.971875\n",
      "测试集精度0.9578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:55<01:07,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9731158088235294\n",
      "验证集精度0.9765625\n",
      "测试集精度0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [02:01<00:54,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9744944852941176\n",
      "验证集精度0.9765625\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [02:07<00:43,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9742647058823529\n",
      "验证集精度0.9765625\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [02:12<00:32,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9744178921568627\n",
      "验证集精度0.9734375\n",
      "测试集精度0.9640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:22<00:29,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9759497549019608\n",
      "验证集精度0.975\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:28<00:21,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9767156862745098\n",
      "验证集精度0.978125\n",
      "测试集精度0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:32<00:12,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9764859068627451\n",
      "验证集精度0.9828125\n",
      "测试集精度0.9640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:42<00:07,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9758731617647058\n",
      "验证集精度0.975\n",
      "测试集精度0.965625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:48<00:00,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9776348039215687\n",
      "验证集精度0.9765625\n",
      "测试集精度0.96875\n",
      "训练集最终精度0.9776348039215687\n",
      "验证集最终精度0.9765625\n",
      "测试集最终精度0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存数据集精度0.9966517857142857\n",
      "训练集最终精度0.9774050245098039\n",
      "验证集最终精度0.978125\n",
      "测试集最终精度0.9609375\n"
     ]
    }
   ],
   "source": [
    "'''随机保存一定数量（和DI数量相同做对比）的原始数据，各个类别保存数量相等'''\n",
    "print('***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************')\n",
    "reserve_num=1000 #一共保存用于KD多少个数据\n",
    "data_num = [0 for i in range(len(train_original_labels))] #记录当前时刻每一类保存了多少个数据\n",
    "tokens_reserved = torch.tensor([])  #用于保存数据\n",
    "labels_reserved = torch.tensor([])\n",
    "\n",
    "\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data_num[data[1][j].item()] < int(reserve_num/len(train_original_labels)): \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "\n",
    "'''\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data[1][j].item() == 0 or data[1][j].item() == 1 or data[1][j].item() == 2 or data[1][j].item() == 3 or data[1][j]==4 or data[1][j]==5 or data[1][j]==6: \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "'''\n",
    "\n",
    "\n",
    "'''将保存的数据装入Dataloader中'''\n",
    "reserved_datasets = TensorDataset(tokens_reserved.long(), labels_reserved.long())\n",
    "reserved_datasets = DataLoader(reserved_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "'''hinton方法KD得到的模型精度'''\n",
    "train_HintonKD_student(teacher_model, bert_student, reserved_datasets, optimizer, loss_func, loss_func2, 5, 20, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_reserved, loss_reserved = Model_Train().eval_for_incremental(bert_student, reserved_datasets, loss_func2)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('保存数据集精度'+str(accuracy_reserved))\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('csuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab6d371e845a933fefd78872ae9ed5c08b7429001c2088fe7b56efc961c495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
