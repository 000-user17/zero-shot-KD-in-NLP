{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        out=self.fc1(encoder_out[:,0,:])\n",
    " \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "'''定义Bert生成模型。通过在一个OOD数据集训练让其输入噪声后可以输出在该OOD上的词汇集'''\n",
    "class Bert_Gen(nn.Module):  #Bert生成模型\n",
    "    def __init__(self, Bert_config): #tokens_len表示生成数据的长度,即最后bert要生成这么长的文本\n",
    "        super(Bert_Gen,self).__init__()\n",
    "        self.device = Bert_config.device\n",
    "        \n",
    "        self.bert1=BertModel.from_pretrained(Bert_config.bertmini_path)  #从路径加载预训练模型\n",
    "        for param in self.bert1.parameters():\n",
    "            param.requires_grad = True # 使参数可更新\n",
    "        \n",
    "        self.fc3= nn.Linear(Bert_config.hidden_size, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 30522)\n",
    "    \n",
    "    def forward(self, z): #tokens表示dataloader中的一个batch的tokens，即去掉label部分的token tensor\n",
    "        \n",
    "\n",
    "        out = z.long()#将经过线性层将正态分布z变为long型整数输入到bert\n",
    "        \n",
    "        encoder_out, pool = self.bert1(out.view(1,-1), output_all_encoded_layers=False) #得到每个token的向量表示\n",
    "        \n",
    "        out = self.fc3(encoder_out.squeeze())  \n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)  #经过线性层处理生成新的向量，和bert词表大小相同\n",
    "        out = F.gumbel_softmax(out, 10, True)\n",
    "        \n",
    "        return out  #输出一个batch的softmax [batch_size, 类别的softmax得分]\n",
    "\n",
    "\n",
    "'''用于生成DI数据印象的模型'''\n",
    "class DI_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super(DI_Gen_model,self).__init__()\n",
    "        \n",
    "        self.bert_gen = torch.load('./model/bert_genMINI3')\n",
    "        for param in self.bert_gen.parameters():    \n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.bert_cnn = teacher_model\n",
    "        for param in self.bert_cnn.parameters():    \n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, z):\n",
    "        \n",
    "        \n",
    "        tokens = self.bert_gen(z)\n",
    "        tokens = torch.argmax(tokens, dim=1, keepdim=False).long().view(1,-1)\n",
    "        \n",
    "        tokens = tokens.squeeze().tolist()\n",
    "        tokens.append(102)#添加sep符号\n",
    "        tokens.insert(0, 101) #添加cls符号\n",
    "        tokens = torch.tensor(tokens).view(1,-1).to('cuda:1')  #感觉加了之后要好一些\n",
    "        \n",
    "        self.bert_cnn.eval()\n",
    "        out = self.bert_cnn(tokens) #输入(batch_size=1, token_len)的tokens, 输出(batch_size=1, num_classes)的out\n",
    "        \n",
    "        return out, tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [29:42<00:00, 178.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9849877450980392, 0.9928002450980392, 0.9954810049019608, 0.9967830882352942, 0.9975490196078431, 0.9977787990196079, 0.9980851715686274, 0.9984681372549019, 0.9999234068627451, 1.0]\n",
      "验证集最终精度0.9890625\n",
      "测试集最终精度0.971875\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train().my_train(teacher_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(teacher_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(teacher_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:27<00:00, 20.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9440104166666666, 0.9682904411764706, 0.975796568627451, 0.9800091911764706, 0.9856770833333334, 0.9874387254901961, 0.9895067401960784, 0.9892003676470589, 0.9918811274509803, 0.9919577205882353]\n",
      "验证集最终精度0.9890625\n",
      "测试集最终精度0.9703125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train().my_train(student_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model.fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:25<00:00, 620.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15774\n"
     ]
    }
   ],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')\n",
    "\n",
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)\n",
    "\n",
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练DI生成模型'''\n",
    "def train_DI_gen(dir_samples, ood_data, DI_gen, optimizer, loss_func, loss_func2, label, temper=10, error=1.2, max_iter=True):\n",
    "    device = 'cuda:1'\n",
    "    DI_gen = DI_gen.to(device)\n",
    "    loss_num=999\n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "    DI_gen.train()\n",
    "    for i in range(len(dir_samples)):\n",
    "        count = 0\n",
    "        ood_data = ood_data.view(-1,1).to(device)\n",
    "        #z = torch.randn(30,1).to(device)\n",
    "        tokens_gens=torch.tensor([]).to(device) #选择最小损失的tokens\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            label = label.to(device).long()\n",
    "            dir_sample = dir_samples[i].to(device).view(1,-1)\n",
    "            \n",
    "            probs, tokens_gen = DI_gen(ood_data)\n",
    "            \n",
    "            #loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample)\n",
    "            #loss = 0.6*loss_func2(probs, label)\n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample) + 0.6*loss_func2(probs, label) #如果不加后面的硬性指标会使得预测的标签混乱\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokens_gens = torch.cat([tokens_gens, tokens_gen], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中bert_cnn的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "    if max_iter == True and len(tokens_gens) > 0:\n",
    "        tokens_gen = tokens_gens[torch.argmin(losses).item()]  #选择loss最小的\n",
    "            \n",
    "    return tokens_gen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义理想情况，DI数据应该对应的真实标签'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_labels = torch.tensor([])\n",
    "for i in range(len(train_original_labels)):\n",
    "    for k in [1,5]:\n",
    "        for j in range(int(DI_num/len(train_original_labels)/2)):\n",
    "            DI_labels = torch.cat([DI_labels, torch.tensor([i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1126 [00:00<?, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 1126/1126 [17:58<00:00,  1.04it/s]\n",
      "100%|██████████| 1126/1126 [17:15<00:00,  1.09it/s] \n",
      "100%|██████████| 1126/1126 [24:36<00:00,  1.31s/it]\n",
      "100%|██████████| 1126/1126 [23:51<00:00,  1.27s/it] \n",
      "100%|██████████| 1126/1126 [2:10:01<00:00,  6.93s/it] \n",
      "100%|██████████| 1126/1126 [2:10:05<00:00,  6.93s/it] \n",
      "100%|██████████| 1126/1126 [08:00<00:00,  2.35it/s]\n",
      "100%|██████████| 1126/1126 [07:56<00:00,  2.36it/s]\n",
      "100%|██████████| 1126/1126 [2:28:06<00:00,  7.89s/it] \n",
      "100%|██████████| 1126/1126 [2:31:56<00:00,  8.10s/it] \n",
      "100%|██████████| 1126/1126 [2:23:50<00:00,  7.66s/it] \n",
      "100%|██████████| 1126/1126 [2:20:59<00:00,  7.51s/it] \n",
      "100%|██████████| 1126/1126 [06:27<00:00,  2.91it/s]\n",
      "100%|██████████| 1126/1126 [06:13<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "'''定义DI的生成模型，以及损失函数和优化器'''\n",
    "DI_gen = DI_Gen_model(teacher_model)\n",
    "loss_func = nn.KLDivLoss(reduction = 'mean')\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "\n",
    "'''生成训练集的DI'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_datas = torch.tensor([])\n",
    "ood_idx = 0\n",
    "for i in range(len(train_original_labels)):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [0.5,0.8]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in tqdm(range(int(DI_num/len(train_original_labels)/2))):\n",
    "            x = m.sample().view(1,-1)\n",
    "            \n",
    "            DI_gen = DI_Gen_model(teacher_model)\n",
    "            optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "            \n",
    "            tokens = train_DI_gen(x, torch.tensor(ood_datas[ood_idx]), DI_gen, optimizer, loss_func, loss_func2, torch.tensor([i]))\n",
    "            ood_idx += 1\n",
    "            \n",
    "            tokens = tokens.squeeze().tolist()\n",
    "            while len(tokens)<100:\n",
    "                tokens.append(0)  #padding到100\n",
    "        \n",
    "            tokens = torch.tensor(tokens)\n",
    "            DI_datas = torch.cat([DI_datas, tokens.to('cpu').view(1,-1)], dim=0)\n",
    "            \n",
    "            '''\n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(tokens.to('cuda:1').long().view(1,-1))\n",
    "                print('当前bert_cnn对本token的预测情况'+str(torch.argmax(F.softmax(out), dim=1)))\n",
    "            \n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(DI_datas.to('cuda:1').long())\n",
    "                print(torch.argmax(F.softmax(out), dim=1))\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'accuse', 'excessive', '[unused715]', 'を', 'sucked', 'enzyme', 'donnelly', 'aisle', 'prompt', 'ethanol', 'departed', 'aus', 'parent', 'dub', '104', '##aldi', 'went', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 590, 1: 2565, 2: 396, 3: 5238, 4: 51, 5: 89, 6: 6835}\n"
     ]
    }
   ],
   "source": [
    "'''随机测试DI对应的英文'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "text = tokenizer.convert_ids_to_tokens(DI_datas[10].tolist())\n",
    "print(text)\n",
    "\n",
    "DI_datasets = TensorDataset(DI_datas.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "'''观察生成DI数据的预测标签特性'''\n",
    "teacher_model.eval()\n",
    "teacher_model = teacher_model.to('cuda:1')\n",
    "DI_pred_labels = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(DI_datasets):\n",
    "        out = teacher_model(data[0].to('cuda:1').long())\n",
    "        DI_pred = torch.argmax(F.softmax(out), dim=1) #DI数据输入到bert_cnn中对应的标签\n",
    "        DI_pred_labels = torch.cat([DI_pred_labels, DI_pred.to('cpu')])\n",
    "\n",
    "DI_pred_dict = {} #记录DI预测的不同种类标签个数\n",
    "for i in range(len(train_original_labels)):\n",
    "    DI_pred_dict[i] = 0\n",
    "for i in range(len(DI_pred_labels)):\n",
    "    DI_pred_dict[DI_pred_labels[i].item()] += 1 \n",
    "print(DI_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''将DI文件装入Dataloader中'''\n",
    "DI_datasets = TensorDataset(DI_datas.long(), DI_pred_labels.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        x = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 1, 6, 1, 3, 1, 1, 1, 6, 1, 1, 6, 6, 1,\n",
      "        6, 6, 1, 5, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 6, 6, 1, 1, 1, 6, 6, 1, 2, 6,\n",
      "        1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 0,\n",
      "        1, 6, 6, 6, 6, 1, 6, 0, 1, 6, 6, 1, 1, 1, 6, 1, 6, 6, 1, 1, 5, 1, 6, 1,\n",
      "        1, 1, 1, 6, 1, 1, 6, 6, 1, 6, 1, 1, 6, 6, 1, 1, 0, 6, 6, 6, 1, 1, 1, 6,\n",
      "        6, 1, 1, 6, 6, 1, 1, 1], device='cuda:1')\n",
      "tensor([[0.0676, 0.5149, 0.0347, 0.0387, 0.0172, 0.0164, 0.3105],\n",
      "        [0.0316, 0.3164, 0.1102, 0.0681, 0.0098, 0.0630, 0.4009],\n",
      "        [0.1840, 0.1163, 0.0123, 0.0265, 0.0061, 0.0186, 0.6361],\n",
      "        [0.0458, 0.1628, 0.0462, 0.0170, 0.0079, 0.0205, 0.6997],\n",
      "        [0.0286, 0.4435, 0.0275, 0.0353, 0.0096, 0.0100, 0.4454],\n",
      "        [0.0258, 0.5832, 0.0478, 0.0352, 0.0292, 0.0068, 0.2719],\n",
      "        [0.0262, 0.2595, 0.0267, 0.0336, 0.0081, 0.0467, 0.5993],\n",
      "        [0.0183, 0.7276, 0.0229, 0.0109, 0.0087, 0.0107, 0.2010],\n",
      "        [0.0160, 0.1242, 0.0174, 0.0680, 0.0187, 0.0150, 0.7406],\n",
      "        [0.0369, 0.2702, 0.0383, 0.0392, 0.0134, 0.0107, 0.5914],\n",
      "        [0.0179, 0.6276, 0.0183, 0.0418, 0.0061, 0.0084, 0.2799],\n",
      "        [0.0291, 0.6587, 0.0622, 0.0299, 0.0210, 0.0123, 0.1867],\n",
      "        [0.0266, 0.4090, 0.0289, 0.0279, 0.0071, 0.0115, 0.4890],\n",
      "        [0.0388, 0.5008, 0.0436, 0.0140, 0.0066, 0.0160, 0.3801],\n",
      "        [0.0157, 0.1927, 0.0432, 0.3651, 0.0385, 0.0855, 0.2594],\n",
      "        [0.0370, 0.5124, 0.0416, 0.0267, 0.0089, 0.0232, 0.3502],\n",
      "        [0.1104, 0.5516, 0.0287, 0.0260, 0.0127, 0.0206, 0.2500],\n",
      "        [0.0181, 0.7718, 0.0347, 0.0235, 0.0061, 0.0066, 0.1392],\n",
      "        [0.0297, 0.3047, 0.0261, 0.0380, 0.0140, 0.0168, 0.5706],\n",
      "        [0.1180, 0.5675, 0.0318, 0.0594, 0.0116, 0.0370, 0.1748],\n",
      "        [0.0053, 0.9067, 0.0137, 0.0084, 0.0056, 0.0036, 0.0567],\n",
      "        [0.0204, 0.1280, 0.1757, 0.2040, 0.0189, 0.0631, 0.3899],\n",
      "        [0.0316, 0.3180, 0.0264, 0.1425, 0.0096, 0.0113, 0.4606],\n",
      "        [0.1934, 0.3991, 0.0388, 0.0737, 0.0087, 0.0274, 0.2588],\n",
      "        [0.0115, 0.0415, 0.0354, 0.0883, 0.0140, 0.0263, 0.7830],\n",
      "        [0.1092, 0.1540, 0.0254, 0.0319, 0.0061, 0.0133, 0.6601],\n",
      "        [0.0137, 0.7252, 0.0541, 0.0244, 0.0179, 0.0253, 0.1395],\n",
      "        [0.0148, 0.0141, 0.0968, 0.0399, 0.0071, 0.7312, 0.0961],\n",
      "        [0.0426, 0.1434, 0.0534, 0.0319, 0.0079, 0.0206, 0.7003],\n",
      "        [0.0462, 0.3071, 0.0336, 0.0575, 0.0514, 0.0103, 0.4939],\n",
      "        [0.0436, 0.4040, 0.0103, 0.0230, 0.0199, 0.0162, 0.4830],\n",
      "        [0.0354, 0.7059, 0.0448, 0.0142, 0.0072, 0.0174, 0.1752],\n",
      "        [0.0678, 0.6355, 0.0304, 0.0225, 0.0104, 0.0103, 0.2230],\n",
      "        [0.0580, 0.3916, 0.0966, 0.0399, 0.0089, 0.0307, 0.3743],\n",
      "        [0.1753, 0.5889, 0.0183, 0.0399, 0.0149, 0.0440, 0.1187],\n",
      "        [0.0460, 0.3838, 0.0311, 0.0171, 0.0069, 0.0165, 0.4987],\n",
      "        [0.0187, 0.5438, 0.0778, 0.0434, 0.0197, 0.0185, 0.2781],\n",
      "        [0.0528, 0.5801, 0.0244, 0.0558, 0.0179, 0.0072, 0.2617],\n",
      "        [0.0328, 0.2862, 0.0327, 0.0201, 0.0041, 0.0250, 0.5990],\n",
      "        [0.0133, 0.2776, 0.0350, 0.0317, 0.0128, 0.0102, 0.6195],\n",
      "        [0.0420, 0.4415, 0.0511, 0.0148, 0.0079, 0.0170, 0.4257],\n",
      "        [0.0138, 0.4173, 0.0418, 0.0971, 0.0213, 0.0171, 0.3916],\n",
      "        [0.0301, 0.7340, 0.0162, 0.0261, 0.0059, 0.0091, 0.1786],\n",
      "        [0.0538, 0.2151, 0.0747, 0.0350, 0.0080, 0.0660, 0.5473],\n",
      "        [0.0249, 0.1977, 0.0289, 0.0219, 0.0106, 0.0625, 0.6537],\n",
      "        [0.0210, 0.4622, 0.0303, 0.0163, 0.0245, 0.0245, 0.4212],\n",
      "        [0.0381, 0.1894, 0.3025, 0.0914, 0.0191, 0.2174, 0.1423],\n",
      "        [0.0344, 0.2372, 0.0336, 0.0507, 0.0446, 0.0282, 0.5713],\n",
      "        [0.0864, 0.6407, 0.0200, 0.0165, 0.0067, 0.0101, 0.2195],\n",
      "        [0.0404, 0.0890, 0.1001, 0.0315, 0.0057, 0.0949, 0.6383],\n",
      "        [0.1574, 0.1963, 0.0316, 0.0698, 0.0113, 0.0163, 0.5173],\n",
      "        [0.0236, 0.6112, 0.0252, 0.0138, 0.0091, 0.0128, 0.3042],\n",
      "        [0.0270, 0.3099, 0.0363, 0.0373, 0.0141, 0.0133, 0.5621],\n",
      "        [0.0455, 0.4728, 0.0905, 0.0205, 0.0166, 0.0189, 0.3352],\n",
      "        [0.0174, 0.3213, 0.0535, 0.0287, 0.0072, 0.0133, 0.5585],\n",
      "        [0.0442, 0.2883, 0.0385, 0.0553, 0.0062, 0.0336, 0.5338],\n",
      "        [0.0160, 0.0913, 0.0198, 0.0695, 0.0077, 0.0175, 0.7782],\n",
      "        [0.0651, 0.1361, 0.0439, 0.2075, 0.1226, 0.0603, 0.3645],\n",
      "        [0.0259, 0.7062, 0.0639, 0.0254, 0.0070, 0.0085, 0.1632],\n",
      "        [0.0255, 0.7262, 0.0400, 0.0192, 0.0070, 0.0075, 0.1747],\n",
      "        [0.0562, 0.4774, 0.0154, 0.0353, 0.0167, 0.0065, 0.3925],\n",
      "        [0.0275, 0.5372, 0.1293, 0.0337, 0.0302, 0.0063, 0.2357],\n",
      "        [0.1568, 0.3683, 0.0207, 0.0486, 0.0229, 0.0172, 0.3655],\n",
      "        [0.0228, 0.4950, 0.0973, 0.0453, 0.0325, 0.0164, 0.2907],\n",
      "        [0.0124, 0.8711, 0.0177, 0.0191, 0.0060, 0.0053, 0.0684],\n",
      "        [0.0523, 0.7337, 0.0212, 0.0179, 0.0605, 0.0165, 0.0978],\n",
      "        [0.0169, 0.5531, 0.0535, 0.0250, 0.0333, 0.0093, 0.3089],\n",
      "        [0.0298, 0.2378, 0.0159, 0.0990, 0.0047, 0.0170, 0.5959],\n",
      "        [0.0433, 0.0895, 0.0329, 0.0413, 0.0050, 0.0096, 0.7783],\n",
      "        [0.0772, 0.3405, 0.0432, 0.0281, 0.0091, 0.0155, 0.4864],\n",
      "        [0.0459, 0.7371, 0.0204, 0.0412, 0.0129, 0.0089, 0.1336],\n",
      "        [0.7397, 0.0554, 0.0145, 0.0290, 0.0264, 0.0617, 0.0733],\n",
      "        [0.0586, 0.4520, 0.0497, 0.0280, 0.0136, 0.0400, 0.3581],\n",
      "        [0.0612, 0.2961, 0.0206, 0.2703, 0.0271, 0.0182, 0.3065],\n",
      "        [0.0680, 0.1686, 0.0330, 0.0182, 0.0028, 0.0163, 0.6932],\n",
      "        [0.0143, 0.0762, 0.0398, 0.0718, 0.0117, 0.0400, 0.7461],\n",
      "        [0.0240, 0.1092, 0.0255, 0.0218, 0.0043, 0.0069, 0.8084],\n",
      "        [0.0250, 0.4932, 0.0326, 0.0142, 0.0052, 0.0105, 0.4194],\n",
      "        [0.0424, 0.3746, 0.0330, 0.0411, 0.0186, 0.0132, 0.4772],\n",
      "        [0.2678, 0.2638, 0.0442, 0.0192, 0.0110, 0.1787, 0.2153],\n",
      "        [0.1369, 0.4586, 0.0738, 0.0319, 0.0076, 0.0268, 0.2644],\n",
      "        [0.0775, 0.3970, 0.0261, 0.0307, 0.0141, 0.0264, 0.4282],\n",
      "        [0.0307, 0.3904, 0.0600, 0.0308, 0.0117, 0.0128, 0.4636],\n",
      "        [0.0234, 0.5018, 0.1177, 0.0241, 0.0182, 0.0107, 0.3042],\n",
      "        [0.0333, 0.4354, 0.0564, 0.0487, 0.0286, 0.0100, 0.3875],\n",
      "        [0.1457, 0.6992, 0.0433, 0.0270, 0.0078, 0.0312, 0.0457],\n",
      "        [0.1065, 0.0262, 0.0328, 0.0174, 0.0053, 0.0195, 0.7922],\n",
      "        [0.0208, 0.5777, 0.0282, 0.0413, 0.0222, 0.0230, 0.2868],\n",
      "        [0.0530, 0.0575, 0.0335, 0.0245, 0.0039, 0.0328, 0.7948],\n",
      "        [0.0892, 0.1540, 0.0596, 0.0280, 0.0192, 0.0243, 0.6257],\n",
      "        [0.0171, 0.6296, 0.0819, 0.0199, 0.0153, 0.0121, 0.2242],\n",
      "        [0.0270, 0.8063, 0.0255, 0.0151, 0.0088, 0.0150, 0.1023],\n",
      "        [0.0161, 0.0205, 0.0743, 0.0300, 0.0064, 0.4887, 0.3640],\n",
      "        [0.0367, 0.6948, 0.0264, 0.0205, 0.0071, 0.0144, 0.2001],\n",
      "        [0.0159, 0.0877, 0.0275, 0.0387, 0.0064, 0.1109, 0.7128],\n",
      "        [0.0244, 0.7276, 0.0339, 0.0444, 0.0186, 0.0129, 0.1382],\n",
      "        [0.0167, 0.5749, 0.2087, 0.0225, 0.0153, 0.0188, 0.1430],\n",
      "        [0.0160, 0.4895, 0.2605, 0.0342, 0.0633, 0.0091, 0.1275],\n",
      "        [0.0253, 0.4185, 0.0197, 0.1185, 0.0419, 0.0181, 0.3580],\n",
      "        [0.0353, 0.3678, 0.0285, 0.0192, 0.0133, 0.0139, 0.5221],\n",
      "        [0.0166, 0.6584, 0.0256, 0.0142, 0.0033, 0.0106, 0.2714],\n",
      "        [0.0234, 0.4745, 0.0427, 0.0886, 0.0144, 0.0077, 0.3487],\n",
      "        [0.1132, 0.2048, 0.0188, 0.0641, 0.0101, 0.0385, 0.5505],\n",
      "        [0.1256, 0.0967, 0.0188, 0.0274, 0.0064, 0.1028, 0.6224],\n",
      "        [0.0712, 0.5582, 0.0258, 0.0227, 0.0164, 0.0653, 0.2403],\n",
      "        [0.1973, 0.2412, 0.0726, 0.0659, 0.0274, 0.1336, 0.2620],\n",
      "        [0.0429, 0.6214, 0.0367, 0.0370, 0.0096, 0.0095, 0.2429],\n",
      "        [0.0864, 0.5613, 0.0213, 0.1230, 0.0160, 0.0163, 0.1757],\n",
      "        [0.0173, 0.1634, 0.0180, 0.0318, 0.0048, 0.0230, 0.7417],\n",
      "        [0.1159, 0.1105, 0.0251, 0.0346, 0.0059, 0.0601, 0.6480],\n",
      "        [0.0329, 0.5354, 0.0482, 0.0443, 0.0075, 0.0088, 0.3229],\n",
      "        [0.0387, 0.7423, 0.0284, 0.0383, 0.0239, 0.0075, 0.1210],\n",
      "        [0.6884, 0.0863, 0.0111, 0.0217, 0.0085, 0.0128, 0.1711],\n",
      "        [0.0926, 0.1068, 0.0123, 0.0241, 0.0068, 0.0189, 0.7386],\n",
      "        [0.0205, 0.3326, 0.0200, 0.0271, 0.0083, 0.0084, 0.5832],\n",
      "        [0.0391, 0.1791, 0.0295, 0.2006, 0.0609, 0.0412, 0.4496],\n",
      "        [0.0368, 0.4684, 0.0422, 0.0307, 0.0138, 0.0146, 0.3934],\n",
      "        [0.0223, 0.5040, 0.0278, 0.0251, 0.0075, 0.0216, 0.3918],\n",
      "        [0.1080, 0.7027, 0.0232, 0.0139, 0.0060, 0.0134, 0.1327],\n",
      "        [0.1147, 0.0664, 0.0291, 0.0181, 0.0106, 0.1522, 0.6088],\n",
      "        [0.1002, 0.2157, 0.0097, 0.1430, 0.2052, 0.0137, 0.3126],\n",
      "        [0.0161, 0.6283, 0.0611, 0.0164, 0.0080, 0.0372, 0.2330],\n",
      "        [0.1112, 0.5538, 0.0170, 0.0482, 0.0103, 0.0241, 0.2354],\n",
      "        [0.0463, 0.2108, 0.0374, 0.0214, 0.0111, 0.1921, 0.4809],\n",
      "        [0.0317, 0.3577, 0.0168, 0.0234, 0.0223, 0.0210, 0.5271],\n",
      "        [0.0227, 0.6474, 0.0445, 0.0561, 0.0398, 0.0120, 0.1776],\n",
      "        [0.0299, 0.8182, 0.0166, 0.0171, 0.0063, 0.0081, 0.1039],\n",
      "        [0.0160, 0.6696, 0.0370, 0.0585, 0.0229, 0.0092, 0.1868]],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(F.softmax(test_output, dim=1), dim=1))\n",
    "indexs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "print(F.softmax(test_output, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5149, device='cuda:1')\n",
      "tensor(0.4009, device='cuda:1')\n",
      "tensor(0.6361, device='cuda:1')\n",
      "tensor(0.6997, device='cuda:1')\n",
      "tensor(0.4454, device='cuda:1')\n",
      "tensor(0.5832, device='cuda:1')\n",
      "tensor(0.5993, device='cuda:1')\n",
      "tensor(0.7276, device='cuda:1')\n",
      "tensor(0.7406, device='cuda:1')\n",
      "tensor(0.5914, device='cuda:1')\n",
      "tensor(0.6276, device='cuda:1')\n",
      "tensor(0.6587, device='cuda:1')\n",
      "tensor(0.4890, device='cuda:1')\n",
      "tensor(0.5008, device='cuda:1')\n",
      "tensor(0.3651, device='cuda:1')\n",
      "tensor(0.5124, device='cuda:1')\n",
      "tensor(0.5516, device='cuda:1')\n",
      "tensor(0.7718, device='cuda:1')\n",
      "tensor(0.5706, device='cuda:1')\n",
      "tensor(0.5675, device='cuda:1')\n",
      "tensor(0.9067, device='cuda:1')\n",
      "tensor(0.3899, device='cuda:1')\n",
      "tensor(0.4606, device='cuda:1')\n",
      "tensor(0.3991, device='cuda:1')\n",
      "tensor(0.7830, device='cuda:1')\n",
      "tensor(0.6601, device='cuda:1')\n",
      "tensor(0.7252, device='cuda:1')\n",
      "tensor(0.7312, device='cuda:1')\n",
      "tensor(0.7003, device='cuda:1')\n",
      "tensor(0.4939, device='cuda:1')\n",
      "tensor(0.4830, device='cuda:1')\n",
      "tensor(0.7059, device='cuda:1')\n",
      "tensor(0.6355, device='cuda:1')\n",
      "tensor(0.3916, device='cuda:1')\n",
      "tensor(0.5889, device='cuda:1')\n",
      "tensor(0.4987, device='cuda:1')\n",
      "tensor(0.5438, device='cuda:1')\n",
      "tensor(0.5801, device='cuda:1')\n",
      "tensor(0.5990, device='cuda:1')\n",
      "tensor(0.6195, device='cuda:1')\n",
      "tensor(0.4415, device='cuda:1')\n",
      "tensor(0.4173, device='cuda:1')\n",
      "tensor(0.7340, device='cuda:1')\n",
      "tensor(0.5473, device='cuda:1')\n",
      "tensor(0.6537, device='cuda:1')\n",
      "tensor(0.4622, device='cuda:1')\n",
      "tensor(0.3025, device='cuda:1')\n",
      "tensor(0.5713, device='cuda:1')\n",
      "tensor(0.6407, device='cuda:1')\n",
      "tensor(0.6383, device='cuda:1')\n",
      "tensor(0.5173, device='cuda:1')\n",
      "tensor(0.6112, device='cuda:1')\n",
      "tensor(0.5621, device='cuda:1')\n",
      "tensor(0.4728, device='cuda:1')\n",
      "tensor(0.5585, device='cuda:1')\n",
      "tensor(0.5338, device='cuda:1')\n",
      "tensor(0.7782, device='cuda:1')\n",
      "tensor(0.3645, device='cuda:1')\n",
      "tensor(0.7062, device='cuda:1')\n",
      "tensor(0.7262, device='cuda:1')\n",
      "tensor(0.4774, device='cuda:1')\n",
      "tensor(0.5372, device='cuda:1')\n",
      "tensor(0.3683, device='cuda:1')\n",
      "tensor(0.4950, device='cuda:1')\n",
      "tensor(0.8711, device='cuda:1')\n",
      "tensor(0.7337, device='cuda:1')\n",
      "tensor(0.5531, device='cuda:1')\n",
      "tensor(0.5959, device='cuda:1')\n",
      "tensor(0.7783, device='cuda:1')\n",
      "tensor(0.4864, device='cuda:1')\n",
      "tensor(0.7371, device='cuda:1')\n",
      "tensor(0.7397, device='cuda:1')\n",
      "tensor(0.4520, device='cuda:1')\n",
      "tensor(0.3065, device='cuda:1')\n",
      "tensor(0.6932, device='cuda:1')\n",
      "tensor(0.7461, device='cuda:1')\n",
      "tensor(0.8084, device='cuda:1')\n",
      "tensor(0.4932, device='cuda:1')\n",
      "tensor(0.4772, device='cuda:1')\n",
      "tensor(0.2678, device='cuda:1')\n",
      "tensor(0.4586, device='cuda:1')\n",
      "tensor(0.4282, device='cuda:1')\n",
      "tensor(0.4636, device='cuda:1')\n",
      "tensor(0.5018, device='cuda:1')\n",
      "tensor(0.4354, device='cuda:1')\n",
      "tensor(0.6992, device='cuda:1')\n",
      "tensor(0.7922, device='cuda:1')\n",
      "tensor(0.5777, device='cuda:1')\n",
      "tensor(0.7948, device='cuda:1')\n",
      "tensor(0.6257, device='cuda:1')\n",
      "tensor(0.6296, device='cuda:1')\n",
      "tensor(0.8063, device='cuda:1')\n",
      "tensor(0.4887, device='cuda:1')\n",
      "tensor(0.6948, device='cuda:1')\n",
      "tensor(0.7128, device='cuda:1')\n",
      "tensor(0.7276, device='cuda:1')\n",
      "tensor(0.5749, device='cuda:1')\n",
      "tensor(0.4895, device='cuda:1')\n",
      "tensor(0.4185, device='cuda:1')\n",
      "tensor(0.5221, device='cuda:1')\n",
      "tensor(0.6584, device='cuda:1')\n",
      "tensor(0.4745, device='cuda:1')\n",
      "tensor(0.5505, device='cuda:1')\n",
      "tensor(0.6224, device='cuda:1')\n",
      "tensor(0.5582, device='cuda:1')\n",
      "tensor(0.2620, device='cuda:1')\n",
      "tensor(0.6214, device='cuda:1')\n",
      "tensor(0.5613, device='cuda:1')\n",
      "tensor(0.7417, device='cuda:1')\n",
      "tensor(0.6480, device='cuda:1')\n",
      "tensor(0.5354, device='cuda:1')\n",
      "tensor(0.7423, device='cuda:1')\n",
      "tensor(0.6884, device='cuda:1')\n",
      "tensor(0.7386, device='cuda:1')\n",
      "tensor(0.5832, device='cuda:1')\n",
      "tensor(0.4496, device='cuda:1')\n",
      "tensor(0.4684, device='cuda:1')\n",
      "tensor(0.5040, device='cuda:1')\n",
      "tensor(0.7027, device='cuda:1')\n",
      "tensor(0.6088, device='cuda:1')\n",
      "tensor(0.3126, device='cuda:1')\n",
      "tensor(0.6283, device='cuda:1')\n",
      "tensor(0.5538, device='cuda:1')\n",
      "tensor(0.4809, device='cuda:1')\n",
      "tensor(0.5271, device='cuda:1')\n",
      "tensor(0.6474, device='cuda:1')\n",
      "tensor(0.8182, device='cuda:1')\n",
      "tensor(0.6696, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(indexs)):\n",
    "    print(F.softmax(test_output, dim=1)[i][indexs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10684\n",
      "15744\n"
     ]
    }
   ],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    test_num = 0\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        idxs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "        for j in range(len(idxs)):\n",
    "            if F.softmax(test_output, dim=1)[j][idxs[j]] > 0.50:\n",
    "                count+=1\n",
    "            test_num += 1\n",
    "print(count)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:1'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward()  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.17080269607843138\n",
      "0.1359375\n",
      "0.1359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [01:48<52:31, 108.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.19087009803921567\n",
      "验证集精度0.2140625\n",
      "测试集精度0.2140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:34<1:22:59, 177.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.5961243872549019\n",
      "验证集精度0.596875\n",
      "测试集精度0.5828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:42<1:09:47, 155.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6387867647058824\n",
      "验证集精度0.646875\n",
      "测试集精度0.64375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [10:04<1:04:50, 149.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7214307598039216\n",
      "验证集精度0.721875\n",
      "测试集精度0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [12:44<1:03:59, 153.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8111213235294118\n",
      "验证集精度0.809375\n",
      "测试集精度0.8109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [14:58<58:43, 146.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8241421568627451\n",
      "验证集精度0.8328125\n",
      "测试集精度0.834375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [17:16<55:11, 143.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8540900735294118\n",
      "验证集精度0.85625\n",
      "测试集精度0.8453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [19:32<51:48, 141.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.858609068627451\n",
      "验证集精度0.8703125\n",
      "测试集精度0.8578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [21:48<48:53, 139.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8705575980392157\n",
      "验证集精度0.8765625\n",
      "测试集精度0.8734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [23:47<44:30, 133.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8772212009803921\n",
      "验证集精度0.884375\n",
      "测试集精度0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [25:53<41:29, 131.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8802083333333334\n",
      "验证集精度0.89375\n",
      "测试集精度0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [27:39<37:03, 123.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8789828431372549\n",
      "验证集精度0.8890625\n",
      "测试集精度0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [29:43<35:00, 123.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8860294117647058\n",
      "验证集精度0.89375\n",
      "测试集精度0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [31:47<33:00, 123.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8935355392156863\n",
      "验证集精度0.9046875\n",
      "测试集精度0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [33:49<30:48, 123.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8965226715686274\n",
      "验证集精度0.921875\n",
      "测试集精度0.884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [35:55<28:54, 123.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8896292892156863\n",
      "验证集精度0.9109375\n",
      "测试集精度0.878125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [37:52<26:24, 121.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8884803921568627\n",
      "验证集精度0.9015625\n",
      "测试集精度0.88125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [39:51<24:11, 120.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8808976715686274\n",
      "验证集精度0.9015625\n",
      "测试集精度0.8796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [41:50<22:04, 120.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9057904411764706\n",
      "验证集精度0.91875\n",
      "测试集精度0.884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [43:53<20:13, 121.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9029564950980392\n",
      "验证集精度0.9140625\n",
      "测试集精度0.8859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [45:59<18:25, 122.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.91015625\n",
      "验证集精度0.9296875\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [48:05<16:30, 123.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.907015931372549\n",
      "验证集精度0.921875\n",
      "测试集精度0.8859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [50:04<14:15, 122.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9125306372549019\n",
      "验证集精度0.925\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [51:57<11:56, 119.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9028799019607843\n",
      "验证集精度0.921875\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [54:05<10:09, 121.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9025735294117647\n",
      "验证集精度0.921875\n",
      "测试集精度0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [56:11<08:13, 123.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9026501225490197\n",
      "验证集精度0.9203125\n",
      "测试集精度0.8921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [58:18<06:12, 124.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8956035539215687\n",
      "验证集精度0.9140625\n",
      "测试集精度0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [1:00:14<04:03, 121.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8991268382352942\n",
      "验证集精度0.915625\n",
      "测试集精度0.8859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [1:02:24<02:04, 124.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9003523284313726\n",
      "验证集精度0.9109375\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:04:35<00:00, 129.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8998161764705882\n",
      "验证集精度0.91875\n",
      "测试集精度0.8875\n",
      "训练集最终精度0.9026501225490197\n",
      "验证集最终精度0.9203125\n",
      "测试集最终精度0.8921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, DI_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "#train_KD_student(bert_cnn, bert_cnn_student, DI_datasets_padding, optimizer, loss_func, loss_func2, 5, 30) #用padding后的DI来KD，对比OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:16<00:00, 625.16it/s]  \n"
     ]
    }
   ],
   "source": [
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15751\n"
     ]
    }
   ],
   "source": [
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        temp[i].insert(0,101)\n",
    "        temp[i].append(102)\n",
    "        while len(tokens[i]) <100:\n",
    "            temp[i].append(0)  #padding\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取ood数据的平均长度为：31.243857532855056\n"
     ]
    }
   ],
   "source": [
    "counts =0\n",
    "for data in ood_datas:\n",
    "    count = 0\n",
    "    for j in range(len(data)):\n",
    "        if data[j] == 0:\n",
    "            break\n",
    "        count += 1\n",
    "    counts += count\n",
    "ave = counts / len(ood_datas)\n",
    "print('选取ood数据的平均长度为：'+ str(ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_datasets = TensorDataset(torch.tensor(ood_datas).long())\n",
    "ood_datasets = DataLoader(ood_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_number = 8000\n",
    "ood_datas_2 = torch.tensor([])\n",
    "\n",
    "for i,data in enumerate(ood_datasets):\n",
    "    if len(ood_datas_2) > 8000:\n",
    "        break\n",
    "    ood_datas_2 = torch.cat([ood_datas_2, data[0]], dim=0)\n",
    "ood_datasets_4000 = TensorDataset(ood_datas_2.long())\n",
    "ood_datasets_4000 = DataLoader(ood_datasets_4000, batch_size=64, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [03:15<1:34:22, 195.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6183363970588235\n",
      "验证集精度0.609375\n",
      "测试集精度0.6234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:32<1:15:16, 161.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6929381127450981\n",
      "验证集精度0.678125\n",
      "测试集精度0.70625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:47<1:07:07, 149.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.754672181372549\n",
      "验证集精度0.746875\n",
      "测试集精度0.7671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [09:53<1:00:43, 140.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8435968137254902\n",
      "验证集精度0.859375\n",
      "测试集精度0.834375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [11:55<55:41, 133.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8355545343137255\n",
      "验证集精度0.8234375\n",
      "测试集精度0.8359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [14:12<53:47, 134.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8496476715686274\n",
      "验证集精度0.8484375\n",
      "测试集精度0.8484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [16:16<50:18, 131.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8602175245098039\n",
      "验证集精度0.8625\n",
      "测试集精度0.846875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [18:17<46:57, 128.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8654258578431373\n",
      "验证集精度0.878125\n",
      "测试集精度0.8546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [20:29<45:12, 129.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8754595588235294\n",
      "验证集精度0.8796875\n",
      "测试集精度0.85625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [22:34<42:38, 127.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8748468137254902\n",
      "验证集精度0.878125\n",
      "测试集精度0.8609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [24:43<40:36, 128.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.871859681372549\n",
      "验证集精度0.8828125\n",
      "测试集精度0.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [26:50<38:19, 127.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8770680147058824\n",
      "验证集精度0.8796875\n",
      "测试集精度0.878125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [28:52<35:45, 126.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8813572303921569\n",
      "验证集精度0.8921875\n",
      "测试集精度0.8703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [30:50<32:58, 123.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8802083333333334\n",
      "验证集精度0.8859375\n",
      "测试集精度0.8640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [32:56<31:03, 124.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8801317401960784\n",
      "验证集精度0.88125\n",
      "测试集精度0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [34:54<28:32, 122.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8763020833333334\n",
      "验证集精度0.8796875\n",
      "测试集精度0.8703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [37:03<26:59, 124.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8836550245098039\n",
      "验证集精度0.878125\n",
      "测试集精度0.878125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [39:20<25:39, 128.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8811274509803921\n",
      "验证集精度0.8734375\n",
      "测试集精度0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [41:15<22:46, 124.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8812806372549019\n",
      "验证集精度0.8765625\n",
      "测试集精度0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [43:21<20:46, 124.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8851868872549019\n",
      "验证集精度0.88125\n",
      "测试集精度0.878125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [45:34<19:06, 127.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8821231617647058\n",
      "验证集精度0.88125\n",
      "测试集精度0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [47:46<17:09, 128.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8771446078431373\n",
      "验证集精度0.8796875\n",
      "测试集精度0.871875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [49:48<14:47, 126.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8684129901960784\n",
      "验证集精度0.8734375\n",
      "测试集精度0.871875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [51:55<12:39, 126.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8805912990196079\n",
      "验证集精度0.8875\n",
      "测试集精度0.871875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [54:04<10:37, 127.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.874234068627451\n",
      "验证集精度0.8703125\n",
      "测试集精度0.871875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [56:14<08:32, 128.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8766850490196079\n",
      "验证集精度0.8734375\n",
      "测试集精度0.8796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [58:29<06:30, 130.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8779871323529411\n",
      "验证集精度0.8734375\n",
      "测试集精度0.8796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [1:00:22<04:09, 124.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8771446078431373\n",
      "验证集精度0.884375\n",
      "测试集精度0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [1:02:31<02:06, 126.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8730851715686274\n",
      "验证集精度0.875\n",
      "测试集精度0.86875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:04:23<00:00, 128.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8743106617647058\n",
      "验证集精度0.8625\n",
      "测试集精度0.8796875\n",
      "训练集最终精度0.8766850490196079\n",
      "验证集最终精度0.8734375\n",
      "测试集最终精度0.8796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集最终精度0.8575367647058824\n",
      "验证集最终精度0.840625\n",
      "测试集最终精度0.8453125\n"
     ]
    }
   ],
   "source": [
    "'''用ood数据直接进行KL散度蒸馏studentmodel'''\n",
    "print('*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, ood_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hinton few-shotKD'''\n",
    "def train_HintonKD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs, train_original_datas, dev_original_datas, test_original_datas ):\n",
    "    device = 'cuda:1'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    max_acc_fin = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            \n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    " \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.5*loss_func2(probs_student, labels)\n",
    "            loss.backward()#这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:31<04:40, 31.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8581495098039216\n",
      "验证集精度0.8390625\n",
      "测试集精度0.8296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:02<04:09, 31.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9507506127450981\n",
      "验证集精度0.9453125\n",
      "测试集精度0.934375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:23<03:05, 26.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9646139705882353\n",
      "验证集精度0.9671875\n",
      "测试集精度0.9421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:39<02:14, 22.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9715073529411765\n",
      "验证集精度0.9734375\n",
      "测试集精度0.946875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:52<01:35, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9771752450980392\n",
      "验证集精度0.978125\n",
      "测试集精度0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:13<01:18, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9793964460784313\n",
      "验证集精度0.978125\n",
      "测试集精度0.965625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:31<00:57, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9799325980392157\n",
      "验证集精度0.9796875\n",
      "测试集精度0.9703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:52<00:39, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9792432598039216\n",
      "验证集精度0.9828125\n",
      "测试集精度0.9703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:11<00:19, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9811580882352942\n",
      "验证集精度0.978125\n",
      "测试集精度0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:24<00:00, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9778645833333334\n",
      "验证集精度0.9828125\n",
      "测试集精度0.971875\n",
      "训练集最终精度0.9778645833333334\n",
      "验证集最终精度0.9828125\n",
      "测试集最终精度0.971875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存数据集精度0.996875\n",
      "训练集最终精度0.9823835784313726\n",
      "验证集最终精度0.9796875\n",
      "测试集最终精度0.9609375\n"
     ]
    }
   ],
   "source": [
    "'''随机保存一定数量（和DI数量相同做对比）的原始数据，各个类别保存数量相等'''\n",
    "print('***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************')\n",
    "reserve_num=2000 #一共保存用于KD多少个数据\n",
    "data_num = [0 for i in range(len(train_original_labels))] #记录当前时刻每一类保存了多少个数据\n",
    "tokens_reserved = torch.tensor([])  #用于保存数据\n",
    "labels_reserved = torch.tensor([])\n",
    "\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data_num[data[1][j].item()] < int(reserve_num/len(train_original_labels)): \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "\n",
    "'''将保存的数据装入Dataloader中'''\n",
    "reserved_datasets = TensorDataset(tokens_reserved.long(), labels_reserved.long())\n",
    "reserved_datasets = DataLoader(reserved_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "'''hinton方法KD得到的模型精度'''\n",
    "train_HintonKD_student(teacher_model, bert_student, reserved_datasets, optimizer, loss_func, loss_func2, 5, 10, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_reserved, loss_reserved = Model_Train().eval_for_incremental(bert_student, reserved_datasets, loss_func2)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('保存数据集精度'+str(accuracy_reserved))\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
