{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental, Data_Init\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        out=self.fc1(encoder_out[:,0,:])\n",
    " \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "'''定义Bert生成模型。通过在一个OOD数据集训练让其输入噪声后可以输出在该OOD上的词汇集'''\n",
    "class Bert_Gen(nn.Module):  #Bert生成模型\n",
    "    def __init__(self, Bert_config): #tokens_len表示生成数据的长度,即最后bert要生成这么长的文本\n",
    "        super(Bert_Gen,self).__init__()\n",
    "        self.device = Bert_config.device\n",
    "        \n",
    "        self.bert1=BertModel.from_pretrained(Bert_config.bertmini_path)  #从路径加载预训练模型\n",
    "        for param in self.bert1.parameters():\n",
    "            param.requires_grad = True # 使参数可更新\n",
    "        \n",
    "        self.fc3= nn.Linear(Bert_config.hidden_size, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 30522)\n",
    "    \n",
    "    def forward(self, z): #tokens表示dataloader中的一个batch的tokens，即去掉label部分的token tensor\n",
    "        \n",
    "\n",
    "        out = z.long()#将经过线性层将正态分布z变为long型整数输入到bert\n",
    "        \n",
    "        encoder_out, pool = self.bert1(out.view(1,-1), output_all_encoded_layers=False) #得到每个token的向量表示\n",
    "        \n",
    "        out = self.fc3(encoder_out.squeeze())  \n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)  #经过线性层处理生成新的向量，和bert词表大小相同\n",
    "        out = F.gumbel_softmax(out, 10, True)\n",
    "        \n",
    "        return out  #输出一个batch的softmax [batch_size, 类别的softmax得分]\n",
    "\n",
    "\n",
    "'''用于生成DI数据印象的模型'''\n",
    "class DI_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super(DI_Gen_model,self).__init__()\n",
    "        \n",
    "        self.bert_gen = torch.load('./model/bert_genMINI3')\n",
    "        for param in self.bert_gen.parameters():    \n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.bert_cnn = teacher_model\n",
    "        for param in self.bert_cnn.parameters():    \n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, z):\n",
    "        \n",
    "        \n",
    "        tokens = self.bert_gen(z)\n",
    "        tokens = torch.argmax(tokens, dim=1, keepdim=False).long().view(1,-1)\n",
    "        \n",
    "        tokens = tokens.squeeze().tolist()\n",
    "        tokens.append(102)#添加sep符号\n",
    "        tokens.insert(0, 101) #添加cls符号\n",
    "        tokens = torch.tensor(tokens).view(1,-1).to('cuda:1')  #感觉加了之后要好一些\n",
    "        \n",
    "        self.bert_cnn.eval()\n",
    "        out = self.bert_cnn(tokens) #输入(batch_size=1, token_len)的tokens, 输出(batch_size=1, num_classes)的out\n",
    "        \n",
    "        return out, tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Train_ipynb(object):\n",
    "    def __init__(self, isTPCIL=False): #\n",
    "        #self.epochs = MyModel_Config.epochs #训练几个epochs\n",
    "        self.device = 'cuda:0'\n",
    "        self.isTPCIL = isTPCIL\n",
    "        \n",
    "    '''测试集和验证集的精度计算,用于全体验证集或测试集的精度计算\n",
    "    model：要评估的模型\n",
    "    datapath：输入字符串如'./data/snips/valid.csv'，表明要测试的验证集或测试集路径\n",
    "    mode:输入字符串'csv'或'tsv' ，表明要测试的文件格式'''\n",
    "    def my_eval(self, model, datapath, loss_func, mode, label_to_idx_train):\n",
    "        device = self.device\n",
    "        tensor_datas, labels_idx = Data_Init(datapath, 64, mode, 'eval', label_to_idx_train).datas_to_tensors()#输出都是tensor形式\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval() #eval()将我们的模型置于评估模式，而不是训练模式。在这种情况下，评估模式关闭了训练中使用的dropout正则化。\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "        with torch.no_grad():\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                #虽然这里的probs没有经过softmax处理，但也可以用下面的这个argmax公式，因为softmax不会改变原本数值元素的大小排名\n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = accuracy / (idx*tensor_datas.batch_size + last_size)\n",
    "        accuracy = accuracy.item()\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "    \n",
    "    '''由于增量学习要求对相应的增量类和原始类数据进行精度的计算，所以如果直接输入验证集路径进去，会导致计算所有类精度，所以这里输入变为直接输入数据\n",
    "    model:要进行精度计算的模型\n",
    "tensor_datas:验证集/测试集的经过Dataloader封装的数据\n",
    "loss_function:用于计算验证集/测试集损失'''\n",
    "\n",
    "    def eval_for_incremental(self, model, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        model = model.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        model.eval() #关闭模型dropout\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "#用法：\n",
    "#eval_for_incremental(model, tensor_datas, loss_function),用法在incremental_learning文件的类中\n",
    "\n",
    "\n",
    "    '''参数：\n",
    "    model：训练模型\n",
    "    loss_func:损失函数\n",
    "    optimizer:优化器\n",
    "    epochs:迭代次数\n",
    "    tensor_datas:要输入的Dataloader封装的数据，默认为MyModel_Config里面的数据\n",
    "    datapath_eval: 如果等于'none'说明不对验证集或测试集进行每个batch训练后的精度和损失计算；如果等于验证集或测试集路径，则进行计算\n",
    "    eval_mode：验证集或测试集的格式，为'csv'或'tsv'.\n",
    "    label_to_idx_train:训练集的标签字典，只有当datapath_eval不为none时候才设置初值'''\n",
    "    def my_train(self, model, loss_func, optimizer, epochs, tensor_datas, datapath_eval='none', eval_mode='csv', label_to_idx_train={}): #增加了需要自己输入的epochs\n",
    "        device = self.device\n",
    "        #epochs = self.epochs\n",
    "        model.train()\n",
    "\n",
    "        model = model.to(device)\n",
    "        losses = [] #存放所有样本一个epoch的损失\n",
    "        accuracies = []\n",
    "        iter = [] #用于绘图的横坐标\n",
    "\n",
    "        #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            '''对每个batch的训练'''\n",
    "            for idx, datas in enumerate(tensor_datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "                tokens = datas[0].to(device)\n",
    "                labels = datas[1].to(device)\n",
    "                #labels_one_hot = datas[1].to(device)  #one-hot形式标签，用于损失计算，[batch_size, labels_nums]\n",
    "                #labels = torch.topk(labels_one_hot, 1)[1].view(-1,1)   #要计算精度，就需要非one-hot形式的标签，转化为(batch_size,1)形式的标签\n",
    "        \n",
    "                optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()#学习率递减\n",
    "            accuracy_train, loss_sum = self.eval_for_incremental(model, tensor_datas, loss_func)\n",
    "    \n",
    "            if datapath_eval != 'none': \n",
    "                if label_to_idx_train == {}:\n",
    "                    raise ValueError(\"要输出测试集精度模式下需要输入训练集对应的标签字典\")\n",
    "                accuracy_eval, loss_eval = self.my_eval(model, datapath_eval, loss_func, eval_mode, label_to_idx_train)\n",
    "                print('第'+str(epoch)+'的验证集失为：'+str(loss_eval))\n",
    "                print('第'+str(epoch)+'的验证集精度为：'+str(accuracy_eval))\n",
    "            \n",
    "            accuracies.append(accuracy_train) #accuracy上的数据在cuda上，需要放到cpu上才能作图，而loss.item()已经加到cpu上了\n",
    "            losses.append(loss_sum)\n",
    "            iter.append(epoch)\n",
    "            #print(\"the loss of  training data \"+ str(epoch) + \"  is-----------\" + str(loss_sum))\n",
    "            #print(\"the accuracy of training data   \"+ str(epoch) + \"  is-----------\" + str(accuracy_train))\n",
    "    \n",
    "        #plt.figure(1)\n",
    "        #plt.title(\"loss of epoch per————\"+str(loss_func)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"loss per epoch\")\n",
    "        #plt.ylabel(\"LOSS\")\n",
    "        #plt.plot(iter, losses)\n",
    "\n",
    "        #plt.figure(2)\n",
    "        #plt.title(\"accuracy of epoch per————\"+str(accuracy_train)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"accuracy per epoch\")\n",
    "        #plt.ylabel(\"ACCURACY\")\n",
    "        #plt.plot(iter, accuracies)\n",
    "\n",
    "        #plt.show()\n",
    "        return accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:08<00:00, 54.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9849877450980392, 0.9928002450980392, 0.9954810049019608, 0.9967830882352942, 0.9975490196078431, 0.9977787990196079, 0.9980851715686274, 0.9984681372549019, 0.9999234068627451, 1.0]\n",
      "验证集最终精度0.9890625\n",
      "测试集最终精度0.971875\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(teacher_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(teacher_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(teacher_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:51<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9440104166666666, 0.9682904411764706, 0.975796568627451, 0.9800091911764706, 0.9856770833333334, 0.9874387254901961, 0.9895067401960784, 0.9892003676470589, 0.9918811274509803, 0.9919577205882353]\n",
      "验证集最终精度0.9890625\n",
      "测试集最终精度0.9703125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(student_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(student_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(student_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''直接优化noise网络，来达到生成符合迪利克雷分布采样的tokens embeddings, 即直接优化了teacher model的embedding层'''\n",
    "'''训练DI生成模型'''\n",
    "def DI_embedding_trian(dir_samples, ood_data, DI_gen, optimizer, loss_func, loss_func2, label, temper=10, error=1.2, max_iter=True):\n",
    "    device = 'cuda:0'\n",
    "    DI_gen = DI_gen.to(device)\n",
    "    loss_num=999\n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "    DI_gen.train()\n",
    "    for i in range(len(dir_samples)):\n",
    "        count = 0\n",
    "        ood_data = ood_data.view(-1,1).to(device)\n",
    "        #z = torch.randn(30,1).to(device)\n",
    "        tokens_gens=torch.tensor([]).to(device) #选择最小损失的tokens\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            label = label.to(device).long()\n",
    "            dir_sample = dir_samples[i].to(device).view(1,-1)\n",
    "            \n",
    "            probs, tokens_gen = DI_gen(ood_data)\n",
    "            \n",
    "            #loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample)\n",
    "            #loss = 0.6*loss_func2(probs, label)\n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample) + 0.6*loss_func2(probs, label) #如果不加后面的硬性指标会使得预测的标签混乱\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokens_gens = torch.cat([tokens_gens, tokens_gen], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中bert_cnn的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "    if max_iter == True and len(tokens_gens) > 0:\n",
    "        tokens_gen = tokens_gens[torch.argmin(losses).item()]  #选择loss最小的\n",
    "            \n",
    "    return tokens_gen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model.fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:25<00:00, 620.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15774\n"
     ]
    }
   ],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')\n",
    "\n",
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)\n",
    "\n",
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练DI生成模型'''\n",
    "def train_DI_gen(dir_samples, ood_data, DI_gen, optimizer, loss_func, loss_func2, label, temper=10, error=1.2, max_iter=True):\n",
    "    device = 'cuda:0'\n",
    "    DI_gen = DI_gen.to(device)\n",
    "    loss_num=999\n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "    DI_gen.train()\n",
    "    for i in range(len(dir_samples)):\n",
    "        count = 0\n",
    "        ood_data = ood_data.view(-1,1).to(device)\n",
    "        #z = torch.randn(30,1).to(device)\n",
    "        tokens_gens=torch.tensor([]).to(device) #选择最小损失的tokens\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            label = label.to(device).long()\n",
    "            dir_sample = dir_samples[i].to(device).view(1,-1)\n",
    "            \n",
    "            probs, tokens_gen = DI_gen(ood_data)\n",
    "            \n",
    "            #loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample)\n",
    "            #loss = 0.6*loss_func2(probs, label)\n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_sample) + 0.6*loss_func2(probs, label) #如果不加后面的硬性指标会使得预测的标签混乱\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokens_gens = torch.cat([tokens_gens, tokens_gen], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中bert_cnn的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "    if max_iter == True and len(tokens_gens) > 0:\n",
    "        tokens_gen = tokens_gens[torch.argmin(losses).item()]  #选择loss最小的\n",
    "            \n",
    "    return tokens_gen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义理想情况，DI数据应该对应的真实标签'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_labels = torch.tensor([])\n",
    "for i in range(len(train_original_labels)):\n",
    "    for k in [1,5]:\n",
    "        for j in range(int(DI_num/len(train_original_labels)/2)):\n",
    "            DI_labels = torch.cat([DI_labels, torch.tensor([i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1126 [00:00<?, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 1126/1126 [17:58<00:00,  1.04it/s]\n",
      "100%|██████████| 1126/1126 [17:15<00:00,  1.09it/s] \n",
      "100%|██████████| 1126/1126 [24:36<00:00,  1.31s/it]\n",
      "100%|██████████| 1126/1126 [23:51<00:00,  1.27s/it] \n",
      " 78%|███████▊  | 883/1126 [1:42:45<12:48,  3.16s/it]  "
     ]
    }
   ],
   "source": [
    "'''定义DI的生成模型，以及损失函数和优化器'''\n",
    "DI_gen = DI_Gen_model(teacher_model)\n",
    "loss_func = nn.KLDivLoss(reduction = 'mean')\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "\n",
    "'''生成训练集的DI'''\n",
    "DI_num = len(ood_datas)\n",
    "DI_datas = torch.tensor([])\n",
    "ood_idx = 0\n",
    "for i in range(len(train_original_labels)):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [0.5,0.8]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in tqdm(range(int(DI_num/len(train_original_labels)/2))):\n",
    "            x = m.sample().view(1,-1)\n",
    "            \n",
    "            DI_gen = DI_Gen_model(teacher_model)\n",
    "            optimizer = torch.optim.SGD(DI_gen.parameters(), lr=1e-5)\n",
    "            \n",
    "            tokens = train_DI_gen(x, torch.tensor(ood_datas[ood_idx]), DI_gen, optimizer, loss_func, loss_func2, torch.tensor([i]))\n",
    "            ood_idx += 1\n",
    "            \n",
    "            tokens = tokens.squeeze().tolist()\n",
    "            while len(tokens)<100:\n",
    "                tokens.append(0)  #padding到100\n",
    "        \n",
    "            tokens = torch.tensor(tokens)\n",
    "            DI_datas = torch.cat([DI_datas, tokens.to('cpu').view(1,-1)], dim=0)\n",
    "            \n",
    "            '''\n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(tokens.to('cuda:1').long().view(1,-1))\n",
    "                print('当前bert_cnn对本token的预测情况'+str(torch.argmax(F.softmax(out), dim=1)))\n",
    "            \n",
    "            bert_cnn.eval()\n",
    "            bert_cnn = bert_cnn.to('cuda:1')\n",
    "            with torch.no_grad():\n",
    "                out = bert_cnn(DI_datas.to('cuda:1').long())\n",
    "                print(torch.argmax(F.softmax(out), dim=1))\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'stability', 'drunk', 'toured', 'horst', 'humour', 'mara', 'nielsen', 'seizure', 'colloquially', 'demand', 'guzman', 'headline', '##uno', '1970', 'mitchell', 'majority', 'fc', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 597, 1: 8447, 2: 217, 3: 1551, 4: 1061, 5: 814, 6: 3077}\n"
     ]
    }
   ],
   "source": [
    "'''随机测试DI对应的英文'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "text = tokenizer.convert_ids_to_tokens(DI_datas[10].tolist())\n",
    "print(text)\n",
    "\n",
    "DI_datasets = TensorDataset(DI_datas.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "'''观察生成DI数据的预测标签特性'''\n",
    "teacher_model.eval()\n",
    "teacher_model = teacher_model.to('cuda:1')\n",
    "DI_pred_labels = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(DI_datasets):\n",
    "        out = teacher_model(data[0].to('cuda:1').long())\n",
    "        DI_pred = torch.argmax(F.softmax(out), dim=1) #DI数据输入到bert_cnn中对应的标签\n",
    "        DI_pred_labels = torch.cat([DI_pred_labels, DI_pred.to('cpu')])\n",
    "\n",
    "DI_pred_dict = {} #记录DI预测的不同种类标签个数\n",
    "for i in range(len(train_original_labels)):\n",
    "    DI_pred_dict[i] = 0\n",
    "for i in range(len(DI_pred_labels)):\n",
    "    DI_pred_dict[DI_pred_labels[i].item()] += 1 \n",
    "print(DI_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''将DI文件装入Dataloader中'''\n",
    "DI_datasets = TensorDataset(DI_datas.long(), DI_pred_labels.long())\n",
    "DI_datasets = DataLoader(DI_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        x = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 6, 6, 0, 6, 3, 6, 5, 4, 6, 6, 0, 0, 6, 0, 6, 0, 3, 6, 6, 0, 6, 4,\n",
      "        6, 1, 0, 3, 0, 0, 6, 6, 6, 2, 3, 2, 6, 0, 0, 6, 6, 0, 6, 6, 0, 6, 6, 6,\n",
      "        6, 6, 3, 0, 6, 6, 0, 1, 6, 6, 6, 0, 6, 3, 6, 0, 6, 0, 6, 0, 6, 0, 0, 6,\n",
      "        6, 0, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 1, 0, 6, 6, 6,\n",
      "        0, 1, 6, 3, 6, 0, 0, 0, 0, 6, 3, 0, 6, 6, 6, 0, 6, 6, 6, 0, 6, 0, 6, 0,\n",
      "        6, 6, 3, 6, 6, 0, 0, 4], device='cuda:1')\n",
      "tensor([[0.8928, 0.0117, 0.0093, 0.0049, 0.0090, 0.0109, 0.0613],\n",
      "        [0.3312, 0.1498, 0.0206, 0.0381, 0.0208, 0.0120, 0.4275],\n",
      "        [0.0991, 0.0803, 0.0399, 0.1987, 0.0120, 0.0194, 0.5505],\n",
      "        [0.0451, 0.0278, 0.0977, 0.0437, 0.0105, 0.0046, 0.7707],\n",
      "        [0.4445, 0.1643, 0.0844, 0.0842, 0.0487, 0.0094, 0.1645],\n",
      "        [0.3225, 0.1675, 0.0434, 0.0426, 0.0231, 0.0408, 0.3600],\n",
      "        [0.0238, 0.0506, 0.0858, 0.4285, 0.0461, 0.0451, 0.3200],\n",
      "        [0.0684, 0.2565, 0.0720, 0.0373, 0.0149, 0.0096, 0.5413],\n",
      "        [0.0172, 0.0233, 0.0094, 0.3153, 0.0760, 0.4392, 0.1195],\n",
      "        [0.2597, 0.1504, 0.0251, 0.0697, 0.3749, 0.0277, 0.0925],\n",
      "        [0.0362, 0.0373, 0.0333, 0.2883, 0.0113, 0.0053, 0.5882],\n",
      "        [0.3112, 0.1104, 0.0446, 0.0234, 0.0096, 0.0178, 0.4830],\n",
      "        [0.6035, 0.2599, 0.0252, 0.0181, 0.0243, 0.0092, 0.0597],\n",
      "        [0.3706, 0.3104, 0.0257, 0.0771, 0.0259, 0.0152, 0.1752],\n",
      "        [0.1860, 0.0408, 0.0113, 0.1769, 0.1709, 0.0212, 0.3929],\n",
      "        [0.3686, 0.0892, 0.0167, 0.0562, 0.1726, 0.0271, 0.2696],\n",
      "        [0.0880, 0.0325, 0.0172, 0.0538, 0.0144, 0.0218, 0.7723],\n",
      "        [0.3254, 0.2593, 0.0944, 0.1379, 0.0152, 0.0120, 0.1558],\n",
      "        [0.1112, 0.1968, 0.0725, 0.2752, 0.0855, 0.0394, 0.2193],\n",
      "        [0.0433, 0.0180, 0.0243, 0.0388, 0.0102, 0.0106, 0.8548],\n",
      "        [0.2052, 0.1864, 0.0376, 0.0498, 0.0154, 0.0160, 0.4897],\n",
      "        [0.2861, 0.2271, 0.0782, 0.0428, 0.0654, 0.0237, 0.2767],\n",
      "        [0.0755, 0.1120, 0.1731, 0.0386, 0.0301, 0.0201, 0.5506],\n",
      "        [0.1927, 0.1460, 0.0445, 0.1598, 0.3187, 0.0240, 0.1144],\n",
      "        [0.1247, 0.0612, 0.0843, 0.0413, 0.2381, 0.0163, 0.4341],\n",
      "        [0.2422, 0.5471, 0.0777, 0.0392, 0.0380, 0.0133, 0.0425],\n",
      "        [0.3994, 0.2240, 0.0262, 0.1659, 0.0287, 0.0418, 0.1140],\n",
      "        [0.0824, 0.0603, 0.0168, 0.3641, 0.2117, 0.0265, 0.2383],\n",
      "        [0.4433, 0.2688, 0.0269, 0.0789, 0.0536, 0.0126, 0.1159],\n",
      "        [0.4033, 0.1505, 0.0266, 0.1077, 0.1090, 0.0199, 0.1831],\n",
      "        [0.0993, 0.0266, 0.0184, 0.0852, 0.0092, 0.0131, 0.7482],\n",
      "        [0.0487, 0.1663, 0.0950, 0.0397, 0.0105, 0.0079, 0.6319],\n",
      "        [0.2767, 0.0920, 0.0737, 0.0739, 0.0970, 0.0567, 0.3300],\n",
      "        [0.0218, 0.0386, 0.3962, 0.1081, 0.0103, 0.0354, 0.3895],\n",
      "        [0.0367, 0.1199, 0.2270, 0.3811, 0.0253, 0.0202, 0.1898],\n",
      "        [0.0187, 0.0231, 0.8027, 0.0894, 0.0078, 0.0216, 0.0365],\n",
      "        [0.0593, 0.0148, 0.0136, 0.0137, 0.0271, 0.0050, 0.8665],\n",
      "        [0.4189, 0.1415, 0.0218, 0.2812, 0.0405, 0.0061, 0.0898],\n",
      "        [0.4144, 0.1240, 0.0221, 0.0188, 0.0089, 0.0101, 0.4018],\n",
      "        [0.1159, 0.2536, 0.1165, 0.1036, 0.0176, 0.0160, 0.3767],\n",
      "        [0.0420, 0.0258, 0.1367, 0.2905, 0.0255, 0.0215, 0.4579],\n",
      "        [0.5663, 0.0609, 0.0176, 0.0216, 0.0123, 0.0126, 0.3086],\n",
      "        [0.2505, 0.0657, 0.0146, 0.0238, 0.0176, 0.0153, 0.6126],\n",
      "        [0.1825, 0.3207, 0.0521, 0.0804, 0.0193, 0.0134, 0.3316],\n",
      "        [0.4932, 0.0478, 0.0098, 0.0708, 0.0126, 0.0178, 0.3479],\n",
      "        [0.1174, 0.0844, 0.0933, 0.0810, 0.0263, 0.0274, 0.5702],\n",
      "        [0.3118, 0.1223, 0.0570, 0.1164, 0.0461, 0.0203, 0.3260],\n",
      "        [0.2452, 0.1207, 0.0328, 0.0139, 0.0120, 0.0165, 0.5588],\n",
      "        [0.0747, 0.1155, 0.0408, 0.2090, 0.0598, 0.0191, 0.4810],\n",
      "        [0.0328, 0.0237, 0.1327, 0.1841, 0.0407, 0.1149, 0.4711],\n",
      "        [0.0741, 0.0842, 0.0493, 0.3283, 0.0986, 0.0647, 0.3008],\n",
      "        [0.3586, 0.1937, 0.0264, 0.0867, 0.0994, 0.0250, 0.2102],\n",
      "        [0.0264, 0.0169, 0.0290, 0.2414, 0.0170, 0.0061, 0.6633],\n",
      "        [0.1412, 0.0546, 0.0308, 0.0434, 0.0412, 0.0953, 0.5934],\n",
      "        [0.5179, 0.1412, 0.0278, 0.0839, 0.0751, 0.0120, 0.1422],\n",
      "        [0.3651, 0.4227, 0.0166, 0.0187, 0.1134, 0.0188, 0.0447],\n",
      "        [0.1227, 0.1583, 0.0682, 0.0299, 0.0102, 0.0110, 0.5997],\n",
      "        [0.1185, 0.0883, 0.0191, 0.0208, 0.0127, 0.0085, 0.7322],\n",
      "        [0.0252, 0.0325, 0.0340, 0.0146, 0.0045, 0.0050, 0.8843],\n",
      "        [0.4821, 0.1618, 0.0325, 0.0718, 0.1609, 0.0109, 0.0800],\n",
      "        [0.1621, 0.0978, 0.1028, 0.0702, 0.1792, 0.0209, 0.3670],\n",
      "        [0.1450, 0.1270, 0.0630, 0.3634, 0.0945, 0.0244, 0.1826],\n",
      "        [0.0464, 0.0457, 0.0130, 0.0612, 0.0431, 0.0485, 0.7421],\n",
      "        [0.3991, 0.2477, 0.0263, 0.0542, 0.0514, 0.0109, 0.2104],\n",
      "        [0.0692, 0.0964, 0.0224, 0.0462, 0.0110, 0.0503, 0.7045],\n",
      "        [0.4196, 0.2112, 0.0434, 0.0416, 0.0483, 0.0152, 0.2207],\n",
      "        [0.1651, 0.0481, 0.0486, 0.3258, 0.0201, 0.0244, 0.3679],\n",
      "        [0.4076, 0.1358, 0.1021, 0.1328, 0.0884, 0.0146, 0.1188],\n",
      "        [0.3505, 0.1218, 0.0229, 0.0170, 0.0173, 0.0241, 0.4464],\n",
      "        [0.2924, 0.2014, 0.0550, 0.1675, 0.0498, 0.0081, 0.2259],\n",
      "        [0.8245, 0.0214, 0.0156, 0.0110, 0.0222, 0.0195, 0.0857],\n",
      "        [0.2297, 0.0337, 0.0227, 0.0196, 0.0125, 0.0156, 0.6663],\n",
      "        [0.0828, 0.0297, 0.0647, 0.1565, 0.0131, 0.0591, 0.5940],\n",
      "        [0.4110, 0.1854, 0.0895, 0.0534, 0.0246, 0.0237, 0.2123],\n",
      "        [0.2926, 0.0707, 0.0266, 0.0135, 0.0122, 0.0157, 0.5687],\n",
      "        [0.0894, 0.0252, 0.0071, 0.0246, 0.0176, 0.0128, 0.8234],\n",
      "        [0.1890, 0.6332, 0.0348, 0.0272, 0.0204, 0.0076, 0.0878],\n",
      "        [0.3604, 0.0716, 0.0163, 0.0250, 0.0410, 0.0242, 0.4614],\n",
      "        [0.0510, 0.0384, 0.0120, 0.0331, 0.0124, 0.0101, 0.8431],\n",
      "        [0.0131, 0.0480, 0.0441, 0.0882, 0.0067, 0.0149, 0.7850],\n",
      "        [0.0347, 0.0298, 0.0320, 0.1382, 0.0060, 0.0248, 0.7344],\n",
      "        [0.2985, 0.0986, 0.1194, 0.1355, 0.0215, 0.0204, 0.3061],\n",
      "        [0.0184, 0.0122, 0.1973, 0.1380, 0.0099, 0.0633, 0.5610],\n",
      "        [0.0665, 0.0768, 0.0657, 0.1847, 0.0246, 0.0085, 0.5733],\n",
      "        [0.0437, 0.0225, 0.0250, 0.0341, 0.0213, 0.0260, 0.8274],\n",
      "        [0.2195, 0.1235, 0.0550, 0.0490, 0.0573, 0.0128, 0.4828],\n",
      "        [0.6735, 0.0666, 0.0176, 0.0551, 0.0487, 0.0083, 0.1302],\n",
      "        [0.2436, 0.1547, 0.1027, 0.1292, 0.0720, 0.0174, 0.2805],\n",
      "        [0.1848, 0.1530, 0.1139, 0.0702, 0.0223, 0.0160, 0.4398],\n",
      "        [0.1051, 0.0500, 0.0258, 0.0867, 0.0311, 0.0349, 0.6664],\n",
      "        [0.1125, 0.1111, 0.0839, 0.1132, 0.1409, 0.0501, 0.3883],\n",
      "        [0.2718, 0.3076, 0.1068, 0.0255, 0.0196, 0.0233, 0.2454],\n",
      "        [0.3783, 0.2561, 0.0394, 0.0335, 0.0329, 0.0228, 0.2371],\n",
      "        [0.3227, 0.1379, 0.0832, 0.0393, 0.0353, 0.0363, 0.3453],\n",
      "        [0.2197, 0.2672, 0.0249, 0.1303, 0.0345, 0.0151, 0.3084],\n",
      "        [0.1656, 0.1667, 0.0910, 0.0498, 0.0380, 0.0149, 0.4740],\n",
      "        [0.3810, 0.2409, 0.0203, 0.0338, 0.0355, 0.0125, 0.2759],\n",
      "        [0.1318, 0.5852, 0.0361, 0.0313, 0.0665, 0.0278, 0.1215],\n",
      "        [0.2697, 0.1592, 0.1182, 0.0419, 0.0472, 0.0160, 0.3479],\n",
      "        [0.0259, 0.0918, 0.0383, 0.4016, 0.0931, 0.0742, 0.2751],\n",
      "        [0.0536, 0.0645, 0.0723, 0.0412, 0.0545, 0.0336, 0.6803],\n",
      "        [0.4029, 0.1194, 0.1034, 0.1413, 0.0174, 0.0261, 0.1895],\n",
      "        [0.3959, 0.1441, 0.0827, 0.0631, 0.0472, 0.0123, 0.2546],\n",
      "        [0.7026, 0.0526, 0.0141, 0.0139, 0.0201, 0.0129, 0.1838],\n",
      "        [0.4014, 0.0667, 0.0322, 0.0881, 0.1874, 0.0378, 0.1864],\n",
      "        [0.0918, 0.0849, 0.0669, 0.1528, 0.1148, 0.1061, 0.3828],\n",
      "        [0.2353, 0.0351, 0.0246, 0.3468, 0.0317, 0.0158, 0.3107],\n",
      "        [0.5006, 0.1581, 0.0237, 0.0450, 0.1068, 0.0112, 0.1546],\n",
      "        [0.2019, 0.0756, 0.0228, 0.0509, 0.3105, 0.0099, 0.3283],\n",
      "        [0.0281, 0.0563, 0.0694, 0.1521, 0.1188, 0.0731, 0.5022],\n",
      "        [0.0514, 0.0765, 0.0625, 0.3381, 0.0070, 0.0059, 0.4586],\n",
      "        [0.5467, 0.2852, 0.0413, 0.0174, 0.0407, 0.0082, 0.0605],\n",
      "        [0.0670, 0.0902, 0.0206, 0.0671, 0.0355, 0.0203, 0.6992],\n",
      "        [0.3347, 0.0523, 0.0275, 0.0994, 0.1004, 0.0184, 0.3673],\n",
      "        [0.0372, 0.0366, 0.0110, 0.0984, 0.0261, 0.0167, 0.7739],\n",
      "        [0.6524, 0.1902, 0.0182, 0.0265, 0.0857, 0.0094, 0.0177],\n",
      "        [0.1500, 0.1946, 0.0563, 0.1424, 0.0903, 0.0297, 0.3366],\n",
      "        [0.4118, 0.1015, 0.0358, 0.1280, 0.0141, 0.0207, 0.2881],\n",
      "        [0.0392, 0.0212, 0.0352, 0.3525, 0.0520, 0.0256, 0.4743],\n",
      "        [0.3900, 0.2240, 0.0571, 0.0406, 0.1168, 0.0205, 0.1510],\n",
      "        [0.1804, 0.1704, 0.1120, 0.1056, 0.0050, 0.0232, 0.4035],\n",
      "        [0.1530, 0.1326, 0.0495, 0.0671, 0.0685, 0.0291, 0.5003],\n",
      "        [0.0439, 0.0407, 0.0455, 0.4179, 0.0929, 0.0151, 0.3440],\n",
      "        [0.0992, 0.0496, 0.0823, 0.0857, 0.0981, 0.0396, 0.5455],\n",
      "        [0.0917, 0.0912, 0.1485, 0.0676, 0.0326, 0.1302, 0.4382],\n",
      "        [0.4477, 0.0685, 0.0176, 0.0266, 0.0088, 0.0105, 0.4204],\n",
      "        [0.3248, 0.1920, 0.1204, 0.0537, 0.1653, 0.0339, 0.1099],\n",
      "        [0.2526, 0.0624, 0.0214, 0.0454, 0.4417, 0.0260, 0.1507]],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(F.softmax(test_output, dim=1), dim=1))\n",
    "indexs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "print(F.softmax(test_output, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8928, device='cuda:1')\n",
      "tensor(0.4275, device='cuda:1')\n",
      "tensor(0.5505, device='cuda:1')\n",
      "tensor(0.7707, device='cuda:1')\n",
      "tensor(0.4445, device='cuda:1')\n",
      "tensor(0.3600, device='cuda:1')\n",
      "tensor(0.4285, device='cuda:1')\n",
      "tensor(0.5413, device='cuda:1')\n",
      "tensor(0.4392, device='cuda:1')\n",
      "tensor(0.3749, device='cuda:1')\n",
      "tensor(0.5882, device='cuda:1')\n",
      "tensor(0.4830, device='cuda:1')\n",
      "tensor(0.6035, device='cuda:1')\n",
      "tensor(0.3706, device='cuda:1')\n",
      "tensor(0.3929, device='cuda:1')\n",
      "tensor(0.3686, device='cuda:1')\n",
      "tensor(0.7723, device='cuda:1')\n",
      "tensor(0.3254, device='cuda:1')\n",
      "tensor(0.2752, device='cuda:1')\n",
      "tensor(0.8548, device='cuda:1')\n",
      "tensor(0.4897, device='cuda:1')\n",
      "tensor(0.2861, device='cuda:1')\n",
      "tensor(0.5506, device='cuda:1')\n",
      "tensor(0.3187, device='cuda:1')\n",
      "tensor(0.4341, device='cuda:1')\n",
      "tensor(0.5471, device='cuda:1')\n",
      "tensor(0.3994, device='cuda:1')\n",
      "tensor(0.3641, device='cuda:1')\n",
      "tensor(0.4433, device='cuda:1')\n",
      "tensor(0.4033, device='cuda:1')\n",
      "tensor(0.7482, device='cuda:1')\n",
      "tensor(0.6319, device='cuda:1')\n",
      "tensor(0.3300, device='cuda:1')\n",
      "tensor(0.3962, device='cuda:1')\n",
      "tensor(0.3811, device='cuda:1')\n",
      "tensor(0.8027, device='cuda:1')\n",
      "tensor(0.8665, device='cuda:1')\n",
      "tensor(0.4189, device='cuda:1')\n",
      "tensor(0.4144, device='cuda:1')\n",
      "tensor(0.3767, device='cuda:1')\n",
      "tensor(0.4579, device='cuda:1')\n",
      "tensor(0.5663, device='cuda:1')\n",
      "tensor(0.6126, device='cuda:1')\n",
      "tensor(0.3316, device='cuda:1')\n",
      "tensor(0.4932, device='cuda:1')\n",
      "tensor(0.5702, device='cuda:1')\n",
      "tensor(0.3260, device='cuda:1')\n",
      "tensor(0.5588, device='cuda:1')\n",
      "tensor(0.4810, device='cuda:1')\n",
      "tensor(0.4711, device='cuda:1')\n",
      "tensor(0.3283, device='cuda:1')\n",
      "tensor(0.3586, device='cuda:1')\n",
      "tensor(0.6633, device='cuda:1')\n",
      "tensor(0.5934, device='cuda:1')\n",
      "tensor(0.5179, device='cuda:1')\n",
      "tensor(0.4227, device='cuda:1')\n",
      "tensor(0.5997, device='cuda:1')\n",
      "tensor(0.7322, device='cuda:1')\n",
      "tensor(0.8843, device='cuda:1')\n",
      "tensor(0.4821, device='cuda:1')\n",
      "tensor(0.3670, device='cuda:1')\n",
      "tensor(0.3634, device='cuda:1')\n",
      "tensor(0.7421, device='cuda:1')\n",
      "tensor(0.3991, device='cuda:1')\n",
      "tensor(0.7045, device='cuda:1')\n",
      "tensor(0.4196, device='cuda:1')\n",
      "tensor(0.3679, device='cuda:1')\n",
      "tensor(0.4076, device='cuda:1')\n",
      "tensor(0.4464, device='cuda:1')\n",
      "tensor(0.2924, device='cuda:1')\n",
      "tensor(0.8245, device='cuda:1')\n",
      "tensor(0.6663, device='cuda:1')\n",
      "tensor(0.5940, device='cuda:1')\n",
      "tensor(0.4110, device='cuda:1')\n",
      "tensor(0.5687, device='cuda:1')\n",
      "tensor(0.8234, device='cuda:1')\n",
      "tensor(0.6332, device='cuda:1')\n",
      "tensor(0.4614, device='cuda:1')\n",
      "tensor(0.8431, device='cuda:1')\n",
      "tensor(0.7850, device='cuda:1')\n",
      "tensor(0.7344, device='cuda:1')\n",
      "tensor(0.3061, device='cuda:1')\n",
      "tensor(0.5610, device='cuda:1')\n",
      "tensor(0.5733, device='cuda:1')\n",
      "tensor(0.8274, device='cuda:1')\n",
      "tensor(0.4828, device='cuda:1')\n",
      "tensor(0.6735, device='cuda:1')\n",
      "tensor(0.2805, device='cuda:1')\n",
      "tensor(0.4398, device='cuda:1')\n",
      "tensor(0.6664, device='cuda:1')\n",
      "tensor(0.3883, device='cuda:1')\n",
      "tensor(0.3076, device='cuda:1')\n",
      "tensor(0.3783, device='cuda:1')\n",
      "tensor(0.3453, device='cuda:1')\n",
      "tensor(0.3084, device='cuda:1')\n",
      "tensor(0.4740, device='cuda:1')\n",
      "tensor(0.3810, device='cuda:1')\n",
      "tensor(0.5852, device='cuda:1')\n",
      "tensor(0.3479, device='cuda:1')\n",
      "tensor(0.4016, device='cuda:1')\n",
      "tensor(0.6803, device='cuda:1')\n",
      "tensor(0.4029, device='cuda:1')\n",
      "tensor(0.3959, device='cuda:1')\n",
      "tensor(0.7026, device='cuda:1')\n",
      "tensor(0.4014, device='cuda:1')\n",
      "tensor(0.3828, device='cuda:1')\n",
      "tensor(0.3468, device='cuda:1')\n",
      "tensor(0.5006, device='cuda:1')\n",
      "tensor(0.3283, device='cuda:1')\n",
      "tensor(0.5022, device='cuda:1')\n",
      "tensor(0.4586, device='cuda:1')\n",
      "tensor(0.5467, device='cuda:1')\n",
      "tensor(0.6992, device='cuda:1')\n",
      "tensor(0.3673, device='cuda:1')\n",
      "tensor(0.7739, device='cuda:1')\n",
      "tensor(0.6524, device='cuda:1')\n",
      "tensor(0.3366, device='cuda:1')\n",
      "tensor(0.4118, device='cuda:1')\n",
      "tensor(0.4743, device='cuda:1')\n",
      "tensor(0.3900, device='cuda:1')\n",
      "tensor(0.4035, device='cuda:1')\n",
      "tensor(0.5003, device='cuda:1')\n",
      "tensor(0.4179, device='cuda:1')\n",
      "tensor(0.5455, device='cuda:1')\n",
      "tensor(0.4382, device='cuda:1')\n",
      "tensor(0.4477, device='cuda:1')\n",
      "tensor(0.3248, device='cuda:1')\n",
      "tensor(0.4417, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(indexs)):\n",
    "    print(F.softmax(test_output, dim=1)[i][indexs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199\n",
      "15744\n"
     ]
    }
   ],
   "source": [
    "student_model.eval()\n",
    "student_model = student_model.to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    test_num = 0\n",
    "    for i , data in enumerate(DI_datasets):\n",
    "        test_output = student_model(data[0].to('cuda:1'))\n",
    "        idxs = torch.argmax(F.softmax(test_output, dim=1), dim=1).to('cpu')\n",
    "        for j in range(len(idxs)):\n",
    "            if F.softmax(test_output, dim=1)[j][idxs[j]] > 0.50:\n",
    "                count+=1\n",
    "            test_num += 1\n",
    "print(count)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:1'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward()  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.14070159313725492\n",
      "0.1484375\n",
      "0.1515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:25<1:10:18, 145.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.40732230392156865\n",
      "验证集精度0.390625\n",
      "测试集精度0.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:15<1:14:37, 159.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7701439950980392\n",
      "验证集精度0.753125\n",
      "测试集精度0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:33<1:07:24, 149.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8641237745098039\n",
      "验证集精度0.8546875\n",
      "测试集精度0.8609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [09:28<59:04, 136.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9050245098039216\n",
      "验证集精度0.9015625\n",
      "测试集精度0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [11:18<52:43, 126.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9188112745098039\n",
      "验证集精度0.91875\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [13:05<47:59, 119.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9184283088235294\n",
      "验证集精度0.925\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [14:54<44:38, 116.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9241727941176471\n",
      "验证集精度0.940625\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [16:47<42:20, 115.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.934359681372549\n",
      "验证集精度0.94375\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [18:40<40:02, 114.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9413296568627451\n",
      "验证集精度0.94375\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [20:27<37:24, 112.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9402573529411765\n",
      "验证集精度0.934375\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [22:12<34:50, 110.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9319087009803921\n",
      "验证集精度0.9296875\n",
      "测试集精度0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [23:59<32:44, 109.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9437040441176471\n",
      "验证集精度0.946875\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [25:53<31:18, 110.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9365808823529411\n",
      "验证集精度0.94375\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [27:40<29:11, 109.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9424785539215687\n",
      "验证集精度0.940625\n",
      "测试集精度0.915625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [29:32<27:32, 110.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9410998774509803\n",
      "验证集精度0.946875\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [31:17<25:20, 108.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9291513480392157\n",
      "验证集精度0.9421875\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [33:11<23:53, 110.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9377297794117647\n",
      "验证集精度0.94375\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [35:00<22:01, 110.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9325980392156863\n",
      "验证集精度0.9453125\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [36:50<20:08, 109.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9405637254901961\n",
      "验证集精度0.9421875\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [38:39<18:16, 109.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9351256127450981\n",
      "验证集精度0.94375\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [40:33<16:38, 110.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9433976715686274\n",
      "验证集精度0.946875\n",
      "测试集精度0.915625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [42:18<14:33, 109.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.936734068627451\n",
      "验证集精度0.9484375\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [44:16<13:03, 111.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9306832107843137\n",
      "验证集精度0.9390625\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [46:01<10:58, 109.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9363511029411765\n",
      "验证集精度0.940625\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [47:49<09:06, 109.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9349724264705882\n",
      "验证集精度0.9375\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [49:51<07:32, 113.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9329044117647058\n",
      "验证集精度0.9328125\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [51:38<05:34, 111.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9293811274509803\n",
      "验证集精度0.940625\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [53:27<03:41, 110.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9286151960784313\n",
      "验证集精度0.9375\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [55:13<01:49, 109.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9362745098039216\n",
      "验证集精度0.946875\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [57:00<00:00, 114.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9320618872549019\n",
      "验证集精度0.9375\n",
      "测试集精度0.903125\n",
      "训练集最终精度0.9319087009803921\n",
      "验证集最终精度0.9296875\n",
      "测试集最终精度0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, DI_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "#train_KD_student(bert_cnn, bert_cnn_student, DI_datasets_padding, optimizer, loss_func, loss_func2, 5, 30) #用padding后的DI来KD，对比OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:28<00:00, 618.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15751\n"
     ]
    }
   ],
   "source": [
    "ood_num = 16000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        temp[i].insert(0,101)\n",
    "        temp[i].append(102)\n",
    "        while len(tokens[i]) <100:\n",
    "            temp[i].append(0)  #padding\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取ood数据的平均长度为：31.243857532855056\n"
     ]
    }
   ],
   "source": [
    "counts =0\n",
    "for data in ood_datas:\n",
    "    count = 0\n",
    "    for j in range(len(data)):\n",
    "        if data[j] == 0:\n",
    "            break\n",
    "        count += 1\n",
    "    counts += count\n",
    "ave = counts / len(ood_datas)\n",
    "print('选取ood数据的平均长度为：'+ str(ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_datasets = TensorDataset(torch.tensor(ood_datas).long())\n",
    "ood_datasets = DataLoader(ood_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_number = 8000\n",
    "ood_datas_2 = torch.tensor([])\n",
    "\n",
    "for i,data in enumerate(ood_datasets):\n",
    "    if len(ood_datas_2) > 8000:\n",
    "        break\n",
    "    ood_datas_2 = torch.cat([ood_datas_2, data[0]], dim=0)\n",
    "ood_datasets_4000 = TensorDataset(ood_datas_2.long())\n",
    "ood_datasets_4000 = DataLoader(ood_datasets_4000, batch_size=64, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:49<1:21:43, 169.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.5876991421568627\n",
      "验证集精度0.5953125\n",
      "测试集精度0.60625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:05<1:10:01, 150.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.7598039215686274\n",
      "验证集精度0.7640625\n",
      "测试集精度0.753125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:02<1:00:44, 134.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8391544117647058\n",
      "验证集精度0.85\n",
      "测试集精度0.821875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [09:00<55:27, 127.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8870251225490197\n",
      "验证集精度0.8625\n",
      "测试集精度0.865625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [10:57<51:40, 124.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9058670343137255\n",
      "验证集精度0.8859375\n",
      "测试集精度0.884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [12:47<47:45, 119.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8965992647058824\n",
      "验证集精度0.88125\n",
      "测试集精度0.8890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [14:38<44:44, 116.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9096200980392157\n",
      "验证集精度0.8859375\n",
      "测试集精度0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [16:31<42:19, 115.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9122242647058824\n",
      "验证集精度0.9\n",
      "测试集精度0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [18:28<40:33, 115.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9159773284313726\n",
      "验证集精度0.903125\n",
      "测试集精度0.8984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [20:21<38:19, 114.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9155943627450981\n",
      "验证集精度0.90625\n",
      "测试集精度0.89375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [22:09<35:47, 113.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9221813725490197\n",
      "验证集精度0.90625\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [23:57<33:25, 111.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9210324754901961\n",
      "验证集精度0.9\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [25:52<31:53, 112.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.921109068627451\n",
      "验证集精度0.9140625\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [27:41<29:40, 111.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9201899509803921\n",
      "验证集精度0.89375\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [29:33<27:55, 111.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9242493872549019\n",
      "验证集精度0.909375\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [31:26<26:09, 112.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9234834558823529\n",
      "验证集精度0.9109375\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [33:10<23:45, 109.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9258578431372549\n",
      "验证集精度0.903125\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [35:12<22:39, 113.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9231770833333334\n",
      "验证集精度0.9046875\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [37:00<20:29, 111.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9216452205882353\n",
      "验证集精度0.903125\n",
      "测试集精度0.9109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [38:51<18:34, 111.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.91796875\n",
      "验证集精度0.9\n",
      "测试集精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [40:44<16:46, 111.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9194240196078431\n",
      "验证集精度0.896875\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [42:37<14:57, 112.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9205729166666666\n",
      "验证集精度0.903125\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [44:23<12:52, 110.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9171262254901961\n",
      "验证集精度0.8921875\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [46:15<11:05, 110.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9244025735294118\n",
      "验证集精度0.903125\n",
      "测试集精度0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [48:08<09:17, 111.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9223345588235294\n",
      "验证集精度0.9\n",
      "测试集精度0.903125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [50:05<07:32, 113.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9200367647058824\n",
      "验证集精度0.90625\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [52:09<05:48, 116.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9209558823529411\n",
      "验证集精度0.8984375\n",
      "测试集精度0.9046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [53:57<03:48, 114.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9196537990196079\n",
      "验证集精度0.9\n",
      "测试集精度0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [55:50<01:53, 113.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9225643382352942\n",
      "验证集精度0.90625\n",
      "测试集精度0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [57:47<00:00, 115.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9234834558823529\n",
      "验证集精度0.90625\n",
      "测试集精度0.909375\n",
      "训练集最终精度0.91796875\n",
      "验证集最终精度0.9\n",
      "测试集最终精度0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集最终精度0.9096200980392157\n",
      "验证集最终精度0.9\n",
      "测试集最终精度0.890625\n"
     ]
    }
   ],
   "source": [
    "'''用ood数据直接进行KL散度蒸馏studentmodel'''\n",
    "print('*******************利用ood训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "train_KD_student(teacher_model, bert_student, ood_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hinton few-shotKD'''\n",
    "def train_HintonKD_student(teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs, train_original_datas, dev_original_datas, test_original_datas ):\n",
    "    device = 'cuda:0'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    max_acc_fin = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            \n",
    "            student_model.train()\n",
    "            tokens = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs_teacher = teacher_model(tokens)\n",
    "            \n",
    "            probs_student = student_model(tokens)\n",
    " \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.5*loss_func2(probs_student, labels)\n",
    "            loss.backward()#这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train().eval_for_incremental(student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train().eval_for_incremental(student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train().eval_for_incremental(student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:15<04:45, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.6135110294117647\n",
      "验证集精度0.615625\n",
      "测试集精度0.5890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:30<04:30, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.8386948529411765\n",
      "验证集精度0.8578125\n",
      "测试集精度0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:45<04:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9138327205882353\n",
      "验证集精度0.921875\n",
      "测试集精度0.8859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:49<02:53, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9273897058823529\n",
      "验证集精度0.9375\n",
      "测试集精度0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:57<02:27,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9501378676470589\n",
      "验证集精度0.9546875\n",
      "测试集精度0.9234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:07<02:17,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9578737745098039\n",
      "验证集精度0.9609375\n",
      "测试集精度0.9359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:15<01:59,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9605545343137255\n",
      "验证集精度0.96875\n",
      "测试集精度0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:21<01:39,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9653033088235294\n",
      "验证集精度0.9671875\n",
      "测试集精度0.946875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:27<01:23,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9677542892156863\n",
      "验证集精度0.9703125\n",
      "测试集精度0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:39<01:27,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9688265931372549\n",
      "验证集精度0.971875\n",
      "测试集精度0.9546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:47<01:16,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9707414215686274\n",
      "验证集精度0.971875\n",
      "测试集精度0.9578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:55<01:07,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9731158088235294\n",
      "验证集精度0.9765625\n",
      "测试集精度0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [02:01<00:54,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9744944852941176\n",
      "验证集精度0.9765625\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [02:07<00:43,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9742647058823529\n",
      "验证集精度0.9765625\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [02:12<00:32,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9744178921568627\n",
      "验证集精度0.9734375\n",
      "测试集精度0.9640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:22<00:29,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9759497549019608\n",
      "验证集精度0.975\n",
      "测试集精度0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:28<00:21,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9767156862745098\n",
      "验证集精度0.978125\n",
      "测试集精度0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:32<00:12,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9764859068627451\n",
      "验证集精度0.9828125\n",
      "测试集精度0.9640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:42<00:07,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9758731617647058\n",
      "验证集精度0.975\n",
      "测试集精度0.965625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:48<00:00,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.9776348039215687\n",
      "验证集精度0.9765625\n",
      "测试集精度0.96875\n",
      "训练集最终精度0.9776348039215687\n",
      "验证集最终精度0.9765625\n",
      "测试集最终精度0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存数据集精度0.9966517857142857\n",
      "训练集最终精度0.9774050245098039\n",
      "验证集最终精度0.978125\n",
      "测试集最终精度0.9609375\n"
     ]
    }
   ],
   "source": [
    "'''随机保存一定数量（和DI数量相同做对比）的原始数据，各个类别保存数量相等'''\n",
    "print('***********************随机保存一定数量的原始数据训练student model,即hinton的few-shot KD******************')\n",
    "reserve_num=1000 #一共保存用于KD多少个数据\n",
    "data_num = [0 for i in range(len(train_original_labels))] #记录当前时刻每一类保存了多少个数据\n",
    "tokens_reserved = torch.tensor([])  #用于保存数据\n",
    "labels_reserved = torch.tensor([])\n",
    "\n",
    "\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data_num[data[1][j].item()] < int(reserve_num/len(train_original_labels)): \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "\n",
    "'''\n",
    "for _, data in enumerate(train_original_datas):\n",
    "    for j in range(len(data[1])):\n",
    "        if data[1][j].item() == 0 or data[1][j].item() == 1 or data[1][j].item() == 2 or data[1][j].item() == 3 or data[1][j]==4 or data[1][j]==5 or data[1][j]==6: \n",
    "            tokens_reserved = torch.cat([tokens_reserved, data[0][j].view(1,-1)], dim=0)\n",
    "            labels_reserved = torch.cat([labels_reserved, data[1][j].view(1)])\n",
    "            data_num[data[1][j].item()] += 1\n",
    "'''\n",
    "\n",
    "\n",
    "'''将保存的数据装入Dataloader中'''\n",
    "reserved_datasets = TensorDataset(tokens_reserved.long(), labels_reserved.long())\n",
    "reserved_datasets = DataLoader(reserved_datasets, batch_size=128, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "bert_student = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(bert_student.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "'''hinton方法KD得到的模型精度'''\n",
    "train_HintonKD_student(teacher_model, bert_student, reserved_datasets, optimizer, loss_func, loss_func2, 5, 20, train_original_datas, dev_original_datas, test_original_datas)\n",
    "accuracy_reserved, loss_reserved = Model_Train().eval_for_incremental(bert_student, reserved_datasets, loss_func2)\n",
    "accuracy_train, loss_train = Model_Train().eval_for_incremental(bert_student, train_original_datas, loss_func2)\n",
    "accuracy_dev, loss_dev = Model_Train().eval_for_incremental(bert_student, dev_original_datas, loss_func2)\n",
    "accuracy_test, loss_test = Model_Train().eval_for_incremental(bert_student, test_original_datas, loss_func2)\n",
    "print('保存数据集精度'+str(accuracy_reserved))\n",
    "print('训练集最终精度'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('csuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab6d371e845a933fefd78872ae9ed5c08b7429001c2088fe7b56efc961c495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
