{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental, Data_Init\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc = nn.Linear(768, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    " \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Train_ipynb(object):\n",
    "    def __init__(self, isTPCIL=False): #\n",
    "        #self.epochs = MyModel_Config.epochs #训练几个epochs\n",
    "        self.device = 'cuda:0'\n",
    "        self.isTPCIL = isTPCIL\n",
    "        \n",
    "    '''测试集和验证集的精度计算,用于全体验证集或测试集的精度计算\n",
    "    model：要评估的模型\n",
    "    datapath：输入字符串如'./data/snips/valid.csv'，表明要测试的验证集或测试集路径\n",
    "    mode:输入字符串'csv'或'tsv' ，表明要测试的文件格式'''\n",
    "    def my_eval(self, model, datapath, loss_func, mode, label_to_idx_train):\n",
    "        device = self.device\n",
    "        tensor_datas, labels_idx = Data_Init(datapath, 64, mode, 'eval', label_to_idx_train).datas_to_tensors()#输出都是tensor形式\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval() #eval()将我们的模型置于评估模式，而不是训练模式。在这种情况下，评估模式关闭了训练中使用的dropout正则化。\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "        with torch.no_grad():\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                #虽然这里的probs没有经过softmax处理，但也可以用下面的这个argmax公式，因为softmax不会改变原本数值元素的大小排名\n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = accuracy / (idx*tensor_datas.batch_size + last_size)\n",
    "        accuracy = accuracy.item()\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "    \n",
    "    '''由于增量学习要求对相应的增量类和原始类数据进行精度的计算，所以如果直接输入验证集路径进去，会导致计算所有类精度，所以这里输入变为直接输入数据\n",
    "    model:要进行精度计算的模型\n",
    "tensor_datas:验证集/测试集的经过Dataloader封装的数据\n",
    "loss_function:用于计算验证集/测试集损失'''\n",
    "\n",
    "    def eval_for_incremental(self, model, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        model = model.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        model.eval() #关闭模型dropout\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "#用法：\n",
    "#eval_for_incremental(model, tensor_datas, loss_function),用法在incremental_learning文件的类中\n",
    "\n",
    "    def eval_for_embeddingKD(self, teacher_embed_model, student_revise, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        teacher_embed_model = teacher_embed_model.to(device)\n",
    "        student_revise = student_revise.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        teacher_embed_model.eval() #关闭模型dropout\n",
    "        student_revise.eval()\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "\n",
    "                teacher_embed = teacher_embed_model(tokens)\n",
    "                probs = student_revise(teacher_embed)\n",
    "\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        student_revise.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "\n",
    "\n",
    "    '''参数：\n",
    "    model：训练模型\n",
    "    loss_func:损失函数\n",
    "    optimizer:优化器\n",
    "    epochs:迭代次数\n",
    "    tensor_datas:要输入的Dataloader封装的数据，默认为MyModel_Config里面的数据\n",
    "    datapath_eval: 如果等于'none'说明不对验证集或测试集进行每个batch训练后的精度和损失计算；如果等于验证集或测试集路径，则进行计算\n",
    "    eval_mode：验证集或测试集的格式，为'csv'或'tsv'.\n",
    "    label_to_idx_train:训练集的标签字典，只有当datapath_eval不为none时候才设置初值'''\n",
    "    def my_train(self, model, loss_func, optimizer, epochs, tensor_datas, datapath_eval='none', eval_mode='csv', label_to_idx_train={}): #增加了需要自己输入的epochs\n",
    "        device = self.device\n",
    "        #epochs = self.epochs\n",
    "        model.train()\n",
    "\n",
    "        model = model.to(device)\n",
    "        losses = [] #存放所有样本一个epoch的损失\n",
    "        accuracies = []\n",
    "        iter = [] #用于绘图的横坐标\n",
    "\n",
    "        #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            '''对每个batch的训练'''\n",
    "            for idx, datas in enumerate(tensor_datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "                tokens = datas[0].to(device)\n",
    "                labels = datas[1].to(device)\n",
    "                #labels_one_hot = datas[1].to(device)  #one-hot形式标签，用于损失计算，[batch_size, labels_nums]\n",
    "                #labels = torch.topk(labels_one_hot, 1)[1].view(-1,1)   #要计算精度，就需要非one-hot形式的标签，转化为(batch_size,1)形式的标签\n",
    "        \n",
    "                optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()#学习率递减\n",
    "            accuracy_train, loss_sum = self.eval_for_incremental(model, tensor_datas, loss_func)\n",
    "    \n",
    "            if datapath_eval != 'none': \n",
    "                if label_to_idx_train == {}:\n",
    "                    raise ValueError(\"要输出测试集精度模式下需要输入训练集对应的标签字典\")\n",
    "                accuracy_eval, loss_eval = self.my_eval(model, datapath_eval, loss_func, eval_mode, label_to_idx_train)\n",
    "                print('第'+str(epoch)+'的验证集失为：'+str(loss_eval))\n",
    "                print('第'+str(epoch)+'的验证集精度为：'+str(accuracy_eval))\n",
    "            \n",
    "            accuracies.append(accuracy_train) #accuracy上的数据在cuda上，需要放到cpu上才能作图，而loss.item()已经加到cpu上了\n",
    "            losses.append(loss_sum)\n",
    "            iter.append(epoch)\n",
    "            #print(\"the loss of  training data \"+ str(epoch) + \"  is-----------\" + str(loss_sum))\n",
    "            #print(\"the accuracy of training data   \"+ str(epoch) + \"  is-----------\" + str(accuracy_train))\n",
    "    \n",
    "        #plt.figure(1)\n",
    "        #plt.title(\"loss of epoch per————\"+str(loss_func)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"loss per epoch\")\n",
    "        #plt.ylabel(\"LOSS\")\n",
    "        #plt.plot(iter, losses)\n",
    "\n",
    "        #plt.figure(2)\n",
    "        #plt.title(\"accuracy of epoch per————\"+str(accuracy_train)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"accuracy per epoch\")\n",
    "        #plt.ylabel(\"ACCURACY\")\n",
    "        #plt.plot(iter, accuracies)\n",
    "\n",
    "        #plt.show()\n",
    "        return accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''teacher模型,embedding层的参数不可修改'''\n",
    "class Teachermodel_revise(nn.Module):\n",
    "    def __init__(self,teacher_model, device):\n",
    "        super(Teachermodel_revise,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.teacher_model_embedding = teacher_model.bert.embeddings\n",
    "        for param in self.teacher_model_embedding.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = True   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_dropout = teacher_model.dropout\n",
    "                                                      \n",
    "        for param in self.teacher_model_dropout.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.teacher_model_fc = teacher_model.fc\n",
    "                                                      \n",
    "        for param in self.teacher_model_fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        out = self.teacher_model_embedding(tokens)\n",
    "        \n",
    "        out = self.teacher_model_encoder(out, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_dropout(pooled_output)\n",
    "        probs = self.teacher_model_fc(probs)\n",
    "        \n",
    "        return probs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:09<00:00, 48.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9781709558823529, 0.9898897058823529, 0.9934895833333334, 0.9957873774509803, 0.99609375, 0.9980085784313726, 0.9966299019607843, 0.9980085784313726, 0.9990042892156863, 0.999234068627451]\n",
      "验证集最终精度0.990625\n",
      "测试集最终精度0.9828125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "teacher_model_reviese = Teachermodel_revise(teacher_model, 'cuda:0')\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(teacher_model_reviese, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(teacher_model_reviese, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(teacher_model_reviese, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model_reviese.teacher_model_fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''通过teacher model和direclet samples训练生成DI的embeddings，用于蒸馏student model\n",
    "DIemb_Gen_model:用于生成DI embedding的模型\n",
    "dir_samples:用Dataloader包装的迪利克雷分布及其标签\n",
    "opitmizer:用于优化DIemb_Gen_model\n",
    "loss_func:KL散度\n",
    "loss_func2:交叉熵\n",
    "'''\n",
    "def train_DI_Embeddings_gen(DIemb_Gen_model, DIemb_datasets, optimizer, loss_func, loss_func2, temper=10, error=0.3, batch_size=64, max_iter=True):\n",
    "    device = 'cuda:0'\n",
    "    loss_num=999\n",
    "    DIemb_Gen_model = DIemb_Gen_model.to(device)\n",
    "    embeddings = torch.tensor([]).to(device)  #用于存放最终生成的tokens embeddings\n",
    "    embedding_labels = torch.tensor([]).to(device)\n",
    "\n",
    "    for _, data in tqdm(enumerate(DIemb_datasets)):\n",
    "            \n",
    "        dir_samples = data[0].to(device)\n",
    "        labels = data[1].long().to(device)\n",
    "\n",
    "        z = torch.randn(batch_size,30,768).to(device)   #噪声为[batch_size, seq_len, embedding_size]形式输入到改动了embedding层后的teacher model\n",
    "\n",
    "        tokensemb_gens = torch.tensor([]).to(device)\n",
    "        emb_probs = torch.tensor([]).to(device)\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        count = 0\n",
    "        loss_num = 999\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            probs, emb_gens = DIemb_Gen_model(z)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_samples) + 0.6*loss_func2(probs, labels)\n",
    "\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_num = loss.item()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokensemb_gens = torch.cat([tokensemb_gens, emb_gens], dim=0)\n",
    "                emb_probs = torch.cat([emb_probs, probs], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中teacher model的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "        if max_iter == True and len(tokensemb_gens) > 0:\n",
    "            num = torch.argmin(losses).item()\n",
    "            tokensemb_gen = tokensemb_gens[num*batch_size : (num+1)*batch_size]  #选择loss最小的\n",
    "            emb_probs_batch = emb_probs[num*batch_size : (num+1)*batch_size]\n",
    "        \n",
    "        embeddings = torch.cat([embeddings, tokensemb_gen], dim=0)\n",
    "        emb_label = torch.argmax(emb_probs_batch, dim=1)  #找到对应的标签\n",
    "        embedding_labels = torch.cat([embedding_labels, emb_label], dim=0)\n",
    "            \n",
    "    return embeddings.detach(), embedding_labels.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''用于生成DI_embedding数据印象的模型'''\n",
    "class DIemb_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model, device):\n",
    "        super(DIemb_Gen_model,self).__init__()\n",
    "        self.device = device\n",
    "        self.fc1 = nn.Linear(768,1024)\n",
    "        self.fc2 = nn.Linear(1024,768)       #用于训练网络生成符合条件的噪声\n",
    "        \n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = False   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_classifier = nn.Sequential(teacher_model.dropout,\n",
    "                                                      teacher_model.fc)\n",
    "        for param in self.teacher_model_classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = torch.relu(out)\n",
    "        emb_gen = self.fc2(out)\n",
    "        self.teacher_model_encoder.eval()\n",
    "        self.teacher_model_remain.eval()\n",
    "        \n",
    "        out = self.teacher_model_encoder(emb_gen, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_classifier(pooled_output)   \n",
    "        \n",
    "        return probs, emb_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  9.92it/s]\n"
     ]
    }
   ],
   "source": [
    "'''生成并打包迪利克雷分布采样进入Dataloader中,并且定义模型和损失函数,优化器'''\n",
    "dir_samples = torch.tensor([])\n",
    "dir_labels = torch.tensor([])\n",
    "DIemb_num = 10000\n",
    "for i in tqdm(range(len(train_original_labels))):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [1,5]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in range(int(DIemb_num/len(train_original_labels)/2)):\n",
    "\n",
    "            x = m.sample().view(1,-1)\n",
    "\n",
    "            dir_samples = torch.cat([dir_samples, x], dim=0)\n",
    "            dir_labels = torch.cat([dir_labels,torch.tensor([i]).long()], dim=0)\n",
    "            \n",
    "dirsample_datasets = TensorDataset(dir_samples, dir_labels)\n",
    "dirsample_datasets = DataLoader(dirsample_datasets, batch_size=64, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "model = DIemb_Gen_model(teacher_model, 'cuda:0')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "156it [03:26,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "'''训练生成tokens embedding'''\n",
    "embeddings_gen, embedding_labels = train_DI_Embeddings_gen(model, dirsample_datasets, optimizer, loss_func, loss_func2)\n",
    "embedding_gen = embeddings_gen.to('cpu')\n",
    "embedding_labels = embedding_labels.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIemb_datasets = TensorDataset(embedding_gen, embedding_labels)   #这里不用detach接下来就不能训练\n",
    "DIemb_datasets = DataLoader(DIemb_datasets, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([])\n",
    "for i, data in enumerate(DIemb_datasets):\n",
    "    labels = torch.cat([labels, data[1]], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1441, 1: 1430, 2: 1419, 3: 1428, 4: 1431, 5: 1412, 6: 1423}\n"
     ]
    }
   ],
   "source": [
    "'''标签更加均衡'''\n",
    "label_idx = {}\n",
    "for i in range(len(train_original_labels)):\n",
    "    label_idx[i] = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label_idx[labels[i].item()] += 1\n",
    "print(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model_embedding, teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:0'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model_embedding = teacher_model_embedding.to(device)\n",
    "    teacher_model_embedding.eval()\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens_embedding = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "        \n",
    "            probs_teacher = teacher_model(tokens_embedding)\n",
    "            \n",
    "            probs_student = student_model(tokens_embedding)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward(retain_graph=True)  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            print(loss.item())\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义用于蒸馏的模型'''\n",
    "class Teachermodel_revise(nn.Module):\n",
    "    def __init__(self,teacher_model, device):\n",
    "        super(Teachermodel_revise,self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = False   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_classifier = nn.Sequential(teacher_model.dropout,\n",
    "                                                      teacher_model.fc)\n",
    "        for param in self.teacher_model_classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, tokens_embedding):\n",
    "        \n",
    "        out = self.teacher_model_encoder(tokens_embedding, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_classifier(pooled_output) \n",
    "        \n",
    "        return probs\n",
    "\n",
    "\n",
    "\n",
    "'''student模型'''\n",
    "class Studentmodel_revise(nn.Module):\n",
    "    def __init__(self,student_model, device, teacher_dim=768, student_dim=768):\n",
    "        super(Studentmodel_revise,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        #self.fc1 = nn.Linear(teacher_dim, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, student_dim)\n",
    "\n",
    "        self.student_model_encoder = student_model.bert.encoder\n",
    "        for param in self.student_model_encoder.parameters():    \n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.student_model_remain = student_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.student_model_remain.parameters():    \n",
    "            param.requires_grad = True   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.student_model_classifier = nn.Sequential(student_model.dropout,\n",
    "                                                      student_model.fc)\n",
    "        for param in self.student_model_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, tokens_embedding):\n",
    "        #out = self.fc1(tokens_embedding)\n",
    "        #out = torch.tanh(out)\n",
    "        #out = self.fc2(out)\n",
    "        \n",
    "        out = self.student_model_encoder(tokens_embedding, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.student_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.student_model_classifier(pooled_output)\n",
    "        \n",
    "        return probs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.1448376225490196\n",
      "0.146875\n",
      "0.1453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009786389768123627\n",
      "0.010480468161404133\n",
      "0.009848935529589653\n",
      "0.010290158912539482\n",
      "0.009549036622047424\n",
      "0.009586542844772339\n",
      "0.009305066429078579\n",
      "0.01004403829574585\n",
      "0.00946862157434225\n",
      "0.009270223788917065\n",
      "0.010301705449819565\n",
      "0.008950476534664631\n",
      "0.009691943414509296\n",
      "0.009045371785759926\n",
      "0.00945785641670227\n",
      "0.009237909689545631\n",
      "0.0097710145637393\n",
      "0.00957106426358223\n",
      "0.009280693717300892\n",
      "0.00968222040683031\n",
      "0.009299893863499165\n",
      "0.009740900248289108\n",
      "0.01052599586546421\n",
      "0.00994446687400341\n",
      "0.00989268533885479\n",
      "0.009451551362872124\n",
      "0.00935200322419405\n",
      "0.00972864218056202\n",
      "0.009685925208032131\n",
      "0.00899769738316536\n",
      "0.00971146859228611\n",
      "0.009951695799827576\n",
      "0.009569428861141205\n",
      "0.009816705249249935\n",
      "0.009954008273780346\n",
      "0.009737934917211533\n",
      "0.009664103388786316\n",
      "0.009814813733100891\n",
      "0.009404798038303852\n",
      "0.010313047096133232\n",
      "0.009154317900538445\n",
      "0.009052249602973461\n",
      "0.00942167080938816\n",
      "0.009644653648138046\n",
      "0.00905646663159132\n",
      "0.00991235114634037\n",
      "0.009481596760451794\n",
      "0.009557430632412434\n",
      "0.009540456347167492\n",
      "0.009179380722343922\n",
      "0.00940394215285778\n",
      "0.009134081192314625\n",
      "0.010117728263139725\n",
      "0.00915292464196682\n",
      "0.009647330269217491\n",
      "0.009456864558160305\n",
      "0.009498432278633118\n",
      "0.009449256584048271\n",
      "0.010197405703365803\n",
      "0.009457903914153576\n",
      "0.008973831310868263\n",
      "0.0092750433832407\n",
      "0.00928996130824089\n",
      "0.00959082879126072\n",
      "0.009434006176888943\n",
      "0.008685429580509663\n",
      "0.009491847828030586\n",
      "0.009381722658872604\n",
      "0.009658711031079292\n",
      "0.01008074451237917\n",
      "0.0095510333776474\n",
      "0.008815077133476734\n",
      "0.009584386833012104\n",
      "0.008404391817748547\n",
      "0.008620168082416058\n",
      "0.010218045674264431\n",
      "0.009658053517341614\n",
      "0.009928582236170769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:08<1:02:07, 128.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14476102941176472\n",
      "验证集精度0.1421875\n",
      "测试集精度0.159375\n",
      "0.00913891103118658\n",
      "0.009418470785021782\n",
      "0.010003295727074146\n",
      "0.009424984455108643\n",
      "0.0097428597509861\n",
      "0.00901773851364851\n",
      "0.009203930385410786\n",
      "0.010098590515553951\n",
      "0.009589025750756264\n",
      "0.009240569546818733\n",
      "0.009333135560154915\n",
      "0.009275304153561592\n",
      "0.009684333577752113\n",
      "0.009522383101284504\n",
      "0.009117539040744305\n",
      "0.009040726348757744\n",
      "0.00973618682473898\n",
      "0.009163230657577515\n",
      "0.009789982810616493\n",
      "0.009367311373353004\n",
      "0.008600692264735699\n",
      "0.008547092787921429\n",
      "0.009241553023457527\n",
      "0.009188114665448666\n",
      "0.009243331849575043\n",
      "0.009164391085505486\n",
      "0.00974983535706997\n",
      "0.008936494588851929\n",
      "0.009613022208213806\n",
      "0.009669849649071693\n",
      "0.00929801631718874\n",
      "0.009603545069694519\n",
      "0.009659024886786938\n",
      "0.009204132482409477\n",
      "0.009692007675766945\n",
      "0.009656903333961964\n",
      "0.0088634192943573\n",
      "0.009405906312167645\n",
      "0.009444421157240868\n",
      "0.009667234495282173\n",
      "0.008994286879897118\n",
      "0.009389355778694153\n",
      "0.009544993750751019\n",
      "0.00980977714061737\n",
      "0.009547632187604904\n",
      "0.009443191811442375\n",
      "0.008971055038273335\n",
      "0.00970434956252575\n",
      "0.00947701558470726\n",
      "0.009402969852089882\n",
      "0.008919941261410713\n",
      "0.009523093700408936\n",
      "0.009354650042951107\n",
      "0.00915475469082594\n",
      "0.008816561661660671\n",
      "0.009546710178256035\n",
      "0.009544449858367443\n",
      "0.00986073911190033\n",
      "0.00869473535567522\n",
      "0.00932377204298973\n",
      "0.009473194368183613\n",
      "0.009643587283790112\n",
      "0.009483984671533108\n",
      "0.00928670633584261\n",
      "0.009648722596466541\n",
      "0.00927022099494934\n",
      "0.009163964539766312\n",
      "0.00942241307348013\n",
      "0.009494559839367867\n",
      "0.009111898951232433\n",
      "0.009718667715787888\n",
      "0.009271658025681973\n",
      "0.009097017347812653\n",
      "0.009766961447894573\n",
      "0.009373484179377556\n",
      "0.00969401653856039\n",
      "0.009302307851612568\n",
      "0.008585331961512566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [03:52<53:18, 114.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1448376225490196\n",
      "验证集精度0.1453125\n",
      "测试集精度0.15625\n",
      "0.008294584229588509\n",
      "0.009247592650353909\n",
      "0.008977551944553852\n",
      "0.00869415421038866\n",
      "0.008941789157688618\n",
      "0.009200788103044033\n",
      "0.009278959594666958\n",
      "0.009560111910104752\n",
      "0.009747225791215897\n",
      "0.008795867674052715\n",
      "0.009852927178144455\n",
      "0.00937377568334341\n",
      "0.009405422955751419\n",
      "0.00946707185357809\n",
      "0.009256799705326557\n",
      "0.008974249474704266\n",
      "0.009291792288422585\n",
      "0.008694957010447979\n",
      "0.008988900110125542\n",
      "0.010172133333981037\n",
      "0.009351122193038464\n",
      "0.009279227815568447\n",
      "0.0098806731402874\n",
      "0.01000208966434002\n",
      "0.009313656017184258\n",
      "0.009513268247246742\n",
      "0.009626874700188637\n",
      "0.009042046032845974\n",
      "0.008912567049264908\n",
      "0.009248606860637665\n",
      "0.009549024514853954\n",
      "0.008637446910142899\n",
      "0.009742021560668945\n",
      "0.008792146109044552\n",
      "0.00857611931860447\n",
      "0.008805041201412678\n",
      "0.009329459629952908\n",
      "0.008522416464984417\n",
      "0.008815089240670204\n",
      "0.009506589733064175\n",
      "0.009016230702400208\n",
      "0.00879200454801321\n",
      "0.008935431018471718\n",
      "0.009160554967820644\n",
      "0.008841989561915398\n",
      "0.00887360330671072\n",
      "0.00804883986711502\n",
      "0.009184096939861774\n",
      "0.008435050025582314\n",
      "0.009200919419527054\n",
      "0.009455088526010513\n",
      "0.00916387140750885\n",
      "0.009549093432724476\n",
      "0.009327820502221584\n",
      "0.00908145122230053\n",
      "0.008297963067889214\n",
      "0.00817070621997118\n",
      "0.009167343378067017\n",
      "0.00901289563626051\n",
      "0.008896762505173683\n",
      "0.008925837464630604\n",
      "0.008918262086808681\n",
      "0.008659188635647297\n",
      "0.008707751519978046\n",
      "0.008773733861744404\n",
      "0.008779672905802727\n",
      "0.009049398824572563\n",
      "0.008852156810462475\n",
      "0.009305713698267937\n",
      "0.009265473112463951\n",
      "0.009287562221288681\n",
      "0.008326500654220581\n",
      "0.009220234118402004\n",
      "0.009049097076058388\n",
      "0.009228814393281937\n",
      "0.008493519388139248\n",
      "0.009005328640341759\n",
      "0.008842062205076218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [06:01<54:25, 120.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1451439950980392\n",
      "验证集精度0.1484375\n",
      "测试集精度0.1578125\n",
      "0.00856431107968092\n",
      "0.009378282353281975\n",
      "0.008796040900051594\n",
      "0.009219743311405182\n",
      "0.007860688492655754\n",
      "0.008807271718978882\n",
      "0.00834702979773283\n",
      "0.00901343859732151\n",
      "0.008833706378936768\n",
      "0.008798163384199142\n",
      "0.008245292119681835\n",
      "0.009067635983228683\n",
      "0.008541546761989594\n",
      "0.00873959343880415\n",
      "0.008632732555270195\n",
      "0.008190007880330086\n",
      "0.008854863233864307\n",
      "0.008634003810584545\n",
      "0.008524132892489433\n",
      "0.009141300804913044\n",
      "0.008856216445565224\n",
      "0.008887412957847118\n",
      "0.00981789268553257\n",
      "0.00876941904425621\n",
      "0.008895284496247768\n",
      "0.009756912477314472\n",
      "0.009283591993153095\n",
      "0.008432779461145401\n",
      "0.00852157175540924\n",
      "0.008867483586072922\n",
      "0.0088728629052639\n",
      "0.00914289802312851\n",
      "0.009582743048667908\n",
      "0.008561477065086365\n",
      "0.008644417859613895\n",
      "0.00824066624045372\n",
      "0.008700813166797161\n",
      "0.008862528018653393\n",
      "0.00784559827297926\n",
      "0.008543897420167923\n",
      "0.00847107544541359\n",
      "0.008216517977416515\n",
      "0.00883704237639904\n",
      "0.008457270450890064\n",
      "0.009437652304768562\n",
      "0.008616012521088123\n",
      "0.008793127723038197\n",
      "0.008329309523105621\n",
      "0.008541716262698174\n",
      "0.00832536444067955\n",
      "0.008741496130824089\n",
      "0.009372320957481861\n",
      "0.008280252106487751\n",
      "0.008655628189444542\n",
      "0.009040643461048603\n",
      "0.008843288756906986\n",
      "0.008678067475557327\n",
      "0.00813197810202837\n",
      "0.008067266084253788\n",
      "0.008200307376682758\n",
      "0.008929029107093811\n",
      "0.0082205506041646\n",
      "0.008999355137348175\n",
      "0.008266639895737171\n",
      "0.008201180025935173\n",
      "0.008708976209163666\n",
      "0.008686480112373829\n",
      "0.00814677495509386\n",
      "0.008505191653966904\n",
      "0.008864912204444408\n",
      "0.008465835824608803\n",
      "0.008459028787910938\n",
      "0.008137313649058342\n",
      "0.00801540445536375\n",
      "0.008631909266114235\n",
      "0.0089257275685668\n",
      "0.008806432597339153\n",
      "0.0091099813580513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [08:23<55:54, 129.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14491421568627452\n",
      "验证集精度0.146875\n",
      "测试集精度0.15625\n",
      "0.009170686826109886\n",
      "0.008268756791949272\n",
      "0.008677845820784569\n",
      "0.008366928435862064\n",
      "0.007385101169347763\n",
      "0.008057505823671818\n",
      "0.008151490241289139\n",
      "0.008819321170449257\n",
      "0.00865598302334547\n",
      "0.008125290274620056\n",
      "0.008944946341216564\n",
      "0.008379379287362099\n",
      "0.008453527465462685\n",
      "0.00833154283463955\n",
      "0.008290914818644524\n",
      "0.008898900821805\n",
      "0.008206838741898537\n",
      "0.008168785832822323\n",
      "0.00785507820546627\n",
      "0.00807005725800991\n",
      "0.007920078001916409\n",
      "0.008702335879206657\n",
      "0.007684976328164339\n",
      "0.008202102035284042\n",
      "0.00777279632166028\n",
      "0.008949989452958107\n",
      "0.008523453958332539\n",
      "0.008142267353832722\n",
      "0.008339140564203262\n",
      "0.008313830941915512\n",
      "0.008072796277701855\n",
      "0.008103247731924057\n",
      "0.008399385958909988\n",
      "0.008143439888954163\n",
      "0.008034874685108662\n",
      "0.008302287198603153\n",
      "0.007551841903477907\n",
      "0.008852038532495499\n",
      "0.008156408555805683\n",
      "0.008449049666523933\n",
      "0.008323965594172478\n",
      "0.00820193812251091\n",
      "0.008410781621932983\n",
      "0.007624363526701927\n",
      "0.007696385495364666\n",
      "0.008795914240181446\n",
      "0.008160635828971863\n",
      "0.008480488322675228\n",
      "0.008083401247859001\n",
      "0.008768519386649132\n",
      "0.008088922128081322\n",
      "0.00787932425737381\n",
      "0.008316602557897568\n",
      "0.008816346526145935\n",
      "0.008125419728457928\n",
      "0.008187800645828247\n",
      "0.0075820619240403175\n",
      "0.008958572521805763\n",
      "0.008427969180047512\n",
      "0.00857824832201004\n",
      "0.008902880363166332\n",
      "0.008688154630362988\n",
      "0.00839085504412651\n",
      "0.008468697778880596\n",
      "0.00827823206782341\n",
      "0.008854096755385399\n",
      "0.008251341059803963\n",
      "0.00787157192826271\n",
      "0.008059540763497353\n",
      "0.007591744884848595\n",
      "0.007729580160230398\n",
      "0.007676882669329643\n",
      "0.007814375683665276\n",
      "0.008074970915913582\n",
      "0.0077591403387486935\n",
      "0.007794252596795559\n",
      "0.007862995378673077\n",
      "0.008425628766417503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [10:31<53:43, 128.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14476102941176472\n",
      "验证集精度0.14375\n",
      "测试集精度0.15625\n",
      "0.008055659011006355\n",
      "0.008287635631859303\n",
      "0.007603941485285759\n",
      "0.008481435477733612\n",
      "0.007904731668531895\n",
      "0.008098956197500229\n",
      "0.007448432967066765\n",
      "0.0071516865864396095\n",
      "0.007457395549863577\n",
      "0.008499501273036003\n",
      "0.008726758882403374\n",
      "0.007636253256350756\n",
      "0.008054619655013084\n",
      "0.008081557229161263\n",
      "0.007590834982693195\n",
      "0.00829743966460228\n",
      "0.007996617816388607\n",
      "0.007852448150515556\n",
      "0.007736916188150644\n",
      "0.0074063865467906\n",
      "0.008423996157944202\n",
      "0.008065418340265751\n",
      "0.00816652737557888\n",
      "0.007947525009512901\n",
      "0.007951637730002403\n",
      "0.00824800319969654\n",
      "0.00743267685174942\n",
      "0.008093699812889099\n",
      "0.007810535375028849\n",
      "0.007611532229930162\n",
      "0.00816372036933899\n",
      "0.007697349414229393\n",
      "0.00815504789352417\n",
      "0.008024530485272408\n",
      "0.007773433346301317\n",
      "0.007276443764567375\n",
      "0.007459568325430155\n",
      "0.008357269689440727\n",
      "0.007692182902246714\n",
      "0.008265047334134579\n",
      "0.007858245633542538\n",
      "0.007370476145297289\n",
      "0.008817416615784168\n",
      "0.008214295841753483\n",
      "0.008077372796833515\n",
      "0.007532060611993074\n",
      "0.008076358586549759\n",
      "0.00822000578045845\n",
      "0.0077168624848127365\n",
      "0.007976124063134193\n",
      "0.00775386206805706\n",
      "0.0077351354993879795\n",
      "0.00892178900539875\n",
      "0.007741362322121859\n",
      "0.007655860390514135\n",
      "0.008132665418088436\n",
      "0.007638744078576565\n",
      "0.00762737262994051\n",
      "0.007440811023116112\n",
      "0.006950117647647858\n",
      "0.007775094360113144\n",
      "0.007421760819852352\n",
      "0.00727630453184247\n",
      "0.007610168308019638\n",
      "0.007508017122745514\n",
      "0.007561265490949154\n",
      "0.008321981877088547\n",
      "0.007198619190603495\n",
      "0.007459311280399561\n",
      "0.0075703212060034275\n",
      "0.008037377148866653\n",
      "0.007406814489513636\n",
      "0.007438044995069504\n",
      "0.007603744976222515\n",
      "0.007955447770655155\n",
      "0.00692728953436017\n",
      "0.008077094331383705\n",
      "0.007107581943273544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [12:40<51:33, 128.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1449908088235294\n",
      "验证集精度0.1390625\n",
      "测试集精度0.1578125\n",
      "0.00737786153331399\n",
      "0.0070479451678693295\n",
      "0.007276555988937616\n",
      "0.007250362541526556\n",
      "0.0075102560222148895\n",
      "0.006997032556682825\n",
      "0.008160088211297989\n",
      "0.007901903241872787\n",
      "0.0072957901284098625\n",
      "0.007827211171388626\n",
      "0.007481020875275135\n",
      "0.007306548301130533\n",
      "0.0070727490819990635\n",
      "0.007383821532130241\n",
      "0.008010964840650558\n",
      "0.007407289929687977\n",
      "0.007030557841062546\n",
      "0.00707058422267437\n",
      "0.007341956719756126\n",
      "0.008499842137098312\n",
      "0.0076660760678350925\n",
      "0.0074136205948889256\n",
      "0.00751511100679636\n",
      "0.007376356050372124\n",
      "0.00728701613843441\n",
      "0.00760766351595521\n",
      "0.007038449868559837\n",
      "0.006985468789935112\n",
      "0.007123585790395737\n",
      "0.007809672504663467\n",
      "0.00765333091840148\n",
      "0.00733885308727622\n",
      "0.008021092042326927\n",
      "0.00777798518538475\n",
      "0.007587017025798559\n",
      "0.0074029285460710526\n",
      "0.006965425331145525\n",
      "0.007968801073729992\n",
      "0.007876160554587841\n",
      "0.007833522744476795\n",
      "0.00738931680098176\n",
      "0.007171649485826492\n",
      "0.007803283631801605\n",
      "0.008541656658053398\n",
      "0.006960025988519192\n",
      "0.007723062299191952\n",
      "0.00812993012368679\n",
      "0.007414406165480614\n",
      "0.007394523825496435\n",
      "0.007588593289256096\n",
      "0.0073612346313893795\n",
      "0.007279873359948397\n",
      "0.006916938349604607\n",
      "0.007438051048666239\n",
      "0.006807762198150158\n",
      "0.008010819554328918\n",
      "0.00721499091014266\n",
      "0.00729187810793519\n",
      "0.007497822865843773\n",
      "0.0073387958109378815\n",
      "0.006683437153697014\n",
      "0.007054249756038189\n",
      "0.007199430372565985\n",
      "0.007115823216736317\n",
      "0.007533239666372538\n",
      "0.007505354471504688\n",
      "0.007233048789203167\n",
      "0.00749545730650425\n",
      "0.007280096411705017\n",
      "0.006741495802998543\n",
      "0.0064933025278151035\n",
      "0.007382398005574942\n",
      "0.00764715950936079\n",
      "0.006971031427383423\n",
      "0.007386700715869665\n",
      "0.007210541982203722\n",
      "0.007310884539037943\n",
      "0.0072004348039627075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [14:49<49:23, 128.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14506740196078433\n",
      "验证集精度0.1421875\n",
      "测试集精度0.159375\n",
      "0.006599925924092531\n",
      "0.006914184894412756\n",
      "0.006929730996489525\n",
      "0.007345097605139017\n",
      "0.006726579740643501\n",
      "0.006695254240185022\n",
      "0.007095721550285816\n",
      "0.007492909673601389\n",
      "0.00666439812630415\n",
      "0.006760085001587868\n",
      "0.006874254904687405\n",
      "0.007335389032959938\n",
      "0.00681355269625783\n",
      "0.006879270076751709\n",
      "0.00680105946958065\n",
      "0.006920833606272936\n",
      "0.007342856377363205\n",
      "0.007510263938456774\n",
      "0.007727432996034622\n",
      "0.007213521748781204\n",
      "0.007454319391399622\n",
      "0.007516182027757168\n",
      "0.006982198916375637\n",
      "0.00833512656390667\n",
      "0.006996334996074438\n",
      "0.007083775941282511\n",
      "0.0072858622297644615\n",
      "0.007004468701779842\n",
      "0.0066480254754424095\n",
      "0.00711805559694767\n",
      "0.007731368765234947\n",
      "0.006816284265369177\n",
      "0.006782939191907644\n",
      "0.007176508195698261\n",
      "0.007870889268815517\n",
      "0.006951454095542431\n",
      "0.007553952746093273\n",
      "0.007869738154113293\n",
      "0.0072823637165129185\n",
      "0.007563053630292416\n",
      "0.007063394412398338\n",
      "0.006559084635227919\n",
      "0.007029412314295769\n",
      "0.006677625700831413\n",
      "0.006876920349895954\n",
      "0.007461072411388159\n",
      "0.0076132891699671745\n",
      "0.006373513024300337\n",
      "0.007312890142202377\n",
      "0.006949362810701132\n",
      "0.006647592410445213\n",
      "0.007090858183801174\n",
      "0.006856566295027733\n",
      "0.007118884939700365\n",
      "0.006842342671006918\n",
      "0.007767231669276953\n",
      "0.006712010130286217\n",
      "0.006510349456220865\n",
      "0.006828547455370426\n",
      "0.00675919558852911\n",
      "0.007067756727337837\n",
      "0.00705714151263237\n",
      "0.007245534565299749\n",
      "0.007537274155765772\n",
      "0.007663831114768982\n",
      "0.007062847260385752\n",
      "0.007021049968898296\n",
      "0.006954179611057043\n",
      "0.006898161955177784\n",
      "0.007322946097701788\n",
      "0.007254267577081919\n",
      "0.007316522765904665\n",
      "0.007174910511821508\n",
      "0.007189405150711536\n",
      "0.0065213413909077644\n",
      "0.007285404019057751\n",
      "0.006822912022471428\n",
      "0.00650486396625638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [16:58<47:14, 128.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14476102941176472\n",
      "验证集精度0.1359375\n",
      "测试集精度0.15625\n",
      "0.006388944573700428\n",
      "0.006428752560168505\n",
      "0.006902641151100397\n",
      "0.006554604507982731\n",
      "0.006749196909368038\n",
      "0.006476281210780144\n",
      "0.006113356910645962\n",
      "0.006623199675232172\n",
      "0.006487698759883642\n",
      "0.006881971377879381\n",
      "0.006777599919587374\n",
      "0.00665493868291378\n",
      "0.005625917110592127\n",
      "0.006458369083702564\n",
      "0.00725381076335907\n",
      "0.00655571511015296\n",
      "0.006243300624191761\n",
      "0.007242385298013687\n",
      "0.006361787207424641\n",
      "0.006496494635939598\n",
      "0.007255670614540577\n",
      "0.006990518420934677\n",
      "0.006588236428797245\n",
      "0.0065156808122992516\n",
      "0.006635712925344706\n",
      "0.006608263123780489\n",
      "0.0064525180496275425\n",
      "0.007016452495008707\n",
      "0.006750622298568487\n",
      "0.006654470693320036\n",
      "0.006916526705026627\n",
      "0.00720636360347271\n",
      "0.006250281352549791\n",
      "0.006650370080024004\n",
      "0.005721601191908121\n",
      "0.007275253999978304\n",
      "0.0073538366705179214\n",
      "0.0062280865386128426\n",
      "0.00526814442127943\n",
      "0.006679357495158911\n",
      "0.006870421115309\n",
      "0.007525199558585882\n",
      "0.0062825861386954784\n",
      "0.007089792750775814\n",
      "0.0060890065506100655\n",
      "0.006253167055547237\n",
      "0.006776026450097561\n",
      "0.006390183698385954\n",
      "0.0069505698047578335\n",
      "0.006386735942214727\n",
      "0.0068563311360776424\n",
      "0.006828689016401768\n",
      "0.0061104693450033665\n",
      "0.006927947048097849\n",
      "0.006418593693524599\n",
      "0.005714510567486286\n",
      "0.007502468768507242\n",
      "0.006726807914674282\n",
      "0.006342640146613121\n",
      "0.00720022851601243\n",
      "0.006649075075984001\n",
      "0.006363498512655497\n",
      "0.006134177092462778\n",
      "0.006185624282807112\n",
      "0.006821247283369303\n",
      "0.0067462860606610775\n",
      "0.00634676031768322\n",
      "0.007046081125736237\n",
      "0.00616026995703578\n",
      "0.006884512957185507\n",
      "0.007124718278646469\n",
      "0.007033494301140308\n",
      "0.00726193655282259\n",
      "0.006065984256565571\n",
      "0.007149383891373873\n",
      "0.00654852157458663\n",
      "0.006829885765910149\n",
      "0.006249916739761829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [19:19<46:28, 132.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1449908088235294\n",
      "验证集精度0.1421875\n",
      "测试集精度0.1609375\n",
      "0.00667553348466754\n",
      "0.006773296743631363\n",
      "0.006823254283517599\n",
      "0.0066338833421468735\n",
      "0.006244147662073374\n",
      "0.006512275896966457\n",
      "0.005707277916371822\n",
      "0.0062596057541668415\n",
      "0.0059470972046256065\n",
      "0.0060801077634096146\n",
      "0.00664489297196269\n",
      "0.006804240867495537\n",
      "0.006648022215813398\n",
      "0.006354822777211666\n",
      "0.006920457351952791\n",
      "0.006017114035785198\n",
      "0.005924021825194359\n",
      "0.007150263991206884\n",
      "0.006550705526024103\n",
      "0.006653202697634697\n",
      "0.0058611175045371056\n",
      "0.007279832847416401\n",
      "0.006045459304004908\n",
      "0.00644178269430995\n",
      "0.006752640008926392\n",
      "0.005893239751458168\n",
      "0.00647543091326952\n",
      "0.006529020611196756\n",
      "0.006571600679308176\n",
      "0.006052317563444376\n",
      "0.006603776477277279\n",
      "0.006861080415546894\n",
      "0.005967074539512396\n",
      "0.006507669109851122\n",
      "0.006464894395321608\n",
      "0.006274939980357885\n",
      "0.007200055755674839\n",
      "0.006500743795186281\n",
      "0.006413810886442661\n",
      "0.005579219665378332\n",
      "0.006195335183292627\n",
      "0.006702404469251633\n",
      "0.006450896617025137\n",
      "0.006682659033685923\n",
      "0.006508839316666126\n",
      "0.0067093707621097565\n",
      "0.006604914553463459\n",
      "0.0066742305643856525\n",
      "0.006598519627004862\n",
      "0.006315736565738916\n",
      "0.006317978259176016\n",
      "0.006523153278976679\n",
      "0.006966202519834042\n",
      "0.005986384116113186\n",
      "0.006862722337245941\n",
      "0.006171670276671648\n",
      "0.005723173264414072\n",
      "0.005905834957957268\n",
      "0.006733167916536331\n",
      "0.00626090494915843\n",
      "0.006969650276005268\n",
      "0.00642200605943799\n",
      "0.006099137011915445\n",
      "0.006047030445188284\n",
      "0.0061236536130309105\n",
      "0.00667960662394762\n",
      "0.006609712727367878\n",
      "0.006451788358390331\n",
      "0.006681505125015974\n",
      "0.005868085194379091\n",
      "0.007187467999756336\n",
      "0.0057372902520000935\n",
      "0.007198033854365349\n",
      "0.006441973615437746\n",
      "0.0065751513466238976\n",
      "0.006021576933562756\n",
      "0.006780287250876427\n",
      "0.006024581380188465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [21:53<46:22, 139.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1449908088235294\n",
      "验证集精度0.146875\n",
      "测试集精度0.159375\n",
      "0.00543628167361021\n",
      "0.006490630097687244\n",
      "0.006359566934406757\n",
      "0.005928791128098965\n",
      "0.005254472140222788\n",
      "0.0061519150622189045\n",
      "0.005910112522542477\n",
      "0.006411355920135975\n",
      "0.005857317708432674\n",
      "0.005309483967721462\n",
      "0.006151688285171986\n",
      "0.005870758555829525\n",
      "0.006381173152476549\n",
      "0.006454086396843195\n",
      "0.005726756528019905\n",
      "0.00572104612365365\n",
      "0.005702632945030928\n",
      "0.0063394163735210896\n",
      "0.006049571558833122\n",
      "0.006556978449225426\n",
      "0.006034286692738533\n",
      "0.005113407038152218\n",
      "0.006002696231007576\n",
      "0.006835507694631815\n",
      "0.005643343552947044\n",
      "0.0057567423209548\n",
      "0.006019039545208216\n",
      "0.005965855438262224\n",
      "0.006012944970279932\n",
      "0.006832717917859554\n",
      "0.0065265437588095665\n",
      "0.0059780520386993885\n",
      "0.006367326248437166\n",
      "0.0070974030531942844\n",
      "0.006795209366828203\n",
      "0.005877608899027109\n",
      "0.0062040407210588455\n",
      "0.006156495306640863\n",
      "0.007026199251413345\n",
      "0.005663748364895582\n",
      "0.00667044660076499\n",
      "0.006282465066760778\n",
      "0.0063834297470748425\n",
      "0.006906424183398485\n",
      "0.005920033436268568\n",
      "0.005731870420277119\n",
      "0.005766561254858971\n",
      "0.006141409743577242\n",
      "0.00577121926471591\n",
      "0.006039734464138746\n",
      "0.005357653833925724\n",
      "0.006118322256952524\n",
      "0.0069857072085142136\n",
      "0.005583067890256643\n",
      "0.006264143157750368\n",
      "0.00657056737691164\n",
      "0.007098052650690079\n",
      "0.005976234562695026\n",
      "0.007228431291878223\n",
      "0.0070473067462444305\n",
      "0.0062486096285283566\n",
      "0.006350263021886349\n",
      "0.006005147006362677\n",
      "0.006375872530043125\n",
      "0.006435633637011051\n",
      "0.006268188823014498\n",
      "0.005686309654265642\n",
      "0.006248417776077986\n",
      "0.00609117466956377\n",
      "0.005738126114010811\n",
      "0.006176968105137348\n",
      "0.006074068136513233\n",
      "0.00610722042620182\n",
      "0.006491875741630793\n",
      "0.005931837949901819\n",
      "0.006038106046617031\n",
      "0.005816162098199129\n",
      "0.0057773771695792675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [24:26<45:26, 143.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14545036764705882\n",
      "验证集精度0.146875\n",
      "测试集精度0.1640625\n",
      "0.006287337746471167\n",
      "0.006235878448933363\n",
      "0.005871917586773634\n",
      "0.006189362145960331\n",
      "0.006117324810475111\n",
      "0.005790168419480324\n",
      "0.0060701752081513405\n",
      "0.005909724626690149\n",
      "0.006323735695332289\n",
      "0.006307489238679409\n",
      "0.0060738082975149155\n",
      "0.006223885342478752\n",
      "0.006214641500264406\n",
      "0.005518807098269463\n",
      "0.006252103019505739\n",
      "0.005514615681022406\n",
      "0.005571797955781221\n",
      "0.005627295933663845\n",
      "0.0058309948071837425\n",
      "0.0062911915592849255\n",
      "0.0065406616777181625\n",
      "0.006048684474080801\n",
      "0.006037944462150335\n",
      "0.005706810858100653\n",
      "0.0056375255808234215\n",
      "0.00562844006344676\n",
      "0.0058869849890470505\n",
      "0.00568975368514657\n",
      "0.0061937314458191395\n",
      "0.005773631855845451\n",
      "0.006018226034939289\n",
      "0.005893384106457233\n",
      "0.006597047671675682\n",
      "0.006141421385109425\n",
      "0.004780224524438381\n",
      "0.006277748383581638\n",
      "0.006086945999413729\n",
      "0.005512624513357878\n",
      "0.006539198569953442\n",
      "0.005803235340863466\n",
      "0.0061020320281386375\n",
      "0.005968754179775715\n",
      "0.005407183896750212\n",
      "0.005973777733743191\n",
      "0.005836458411067724\n",
      "0.005613576155155897\n",
      "0.005818705540150404\n",
      "0.006019491236656904\n",
      "0.005859388504177332\n",
      "0.005881804041564465\n",
      "0.006301145534962416\n",
      "0.005382123403251171\n",
      "0.0057143294252455235\n",
      "0.005448619369417429\n",
      "0.0051090288907289505\n",
      "0.005738342646509409\n",
      "0.005583817604929209\n",
      "0.005622506607323885\n",
      "0.0054452973417937756\n",
      "0.005811681039631367\n",
      "0.006083476822823286\n",
      "0.005954677704721689\n",
      "0.004914028104394674\n",
      "0.005818439647555351\n",
      "0.005796863231807947\n",
      "0.005875336937606335\n",
      "0.0069224052131175995\n",
      "0.0056564961560070515\n",
      "0.005718113388866186\n",
      "0.005401856265962124\n",
      "0.005859171040356159\n",
      "0.0062332553789019585\n",
      "0.006517366506159306\n",
      "0.006123135797679424\n",
      "0.005691675469279289\n",
      "0.006114533171057701\n",
      "0.005707103293389082\n",
      "0.005548321176320314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [27:12<45:04, 150.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14682904411764705\n",
      "验证集精度0.1703125\n",
      "测试集精度0.16875\n",
      "0.005490427371114492\n",
      "0.005818834528326988\n",
      "0.005868417676538229\n",
      "0.0054575675167143345\n",
      "0.005726241040974855\n",
      "0.005678167566657066\n",
      "0.0049911136738955975\n",
      "0.0053508891724050045\n",
      "0.005224940367043018\n",
      "0.0051607852801680565\n",
      "0.005362363997846842\n",
      "0.005366154480725527\n",
      "0.005338849034160376\n",
      "0.00544464448466897\n",
      "0.0057846191339194775\n",
      "0.004755587317049503\n",
      "0.005519569851458073\n",
      "0.006386893801391125\n",
      "0.004940545652061701\n",
      "0.005274457391351461\n",
      "0.005111181642860174\n",
      "0.005460726097226143\n",
      "0.005863399710506201\n",
      "0.005028559826314449\n",
      "0.005316701252013445\n",
      "0.005197952035814524\n",
      "0.0053118253126740456\n",
      "0.005733306985348463\n",
      "0.004967901390045881\n",
      "0.00584836583584547\n",
      "0.005295807961374521\n",
      "0.005908564198762178\n",
      "0.005763707682490349\n",
      "0.0052598402835428715\n",
      "0.005908097606152296\n",
      "0.0061603509820997715\n",
      "0.005522192921489477\n",
      "0.0050355675630271435\n",
      "0.0054940590634942055\n",
      "0.00545245548710227\n",
      "0.0052531748078763485\n",
      "0.005587826017290354\n",
      "0.005261631682515144\n",
      "0.005089868791401386\n",
      "0.0067065563052892685\n",
      "0.00681239552795887\n",
      "0.005690496880561113\n",
      "0.005755169317126274\n",
      "0.0047403499484062195\n",
      "0.005904484074562788\n",
      "0.006391276605427265\n",
      "0.005715822800993919\n",
      "0.00563036696985364\n",
      "0.0049549671821296215\n",
      "0.005769072100520134\n",
      "0.004940870683640242\n",
      "0.005511350464075804\n",
      "0.005876301787793636\n",
      "0.005395849235355854\n",
      "0.006296825595200062\n",
      "0.006449633743613958\n",
      "0.005299851763993502\n",
      "0.005725208204239607\n",
      "0.005273302085697651\n",
      "0.005366548430174589\n",
      "0.0052322749979794025\n",
      "0.0059156259521842\n",
      "0.005900853779166937\n",
      "0.006100169382989407\n",
      "0.005557544995099306\n",
      "0.00534066604450345\n",
      "0.005772189702838659\n",
      "0.005576343275606632\n",
      "0.005132309161126614\n",
      "0.006193548906594515\n",
      "0.006112073548138142\n",
      "0.006241313181817532\n",
      "0.004799081012606621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [29:45<42:50, 151.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14744178921568626\n",
      "验证集精度0.1640625\n",
      "测试集精度0.1703125\n",
      "0.004454275127500296\n",
      "0.005738838575780392\n",
      "0.005700154695659876\n",
      "0.005100467707961798\n",
      "0.005440190900117159\n",
      "0.005650933366268873\n",
      "0.005612591281533241\n",
      "0.006228955462574959\n",
      "0.005716226063668728\n",
      "0.005615981761366129\n",
      "0.005695630796253681\n",
      "0.006165053229779005\n",
      "0.005150617565959692\n",
      "0.0048325094394385815\n",
      "0.00575563870370388\n",
      "0.005843444261699915\n",
      "0.005849974229931831\n",
      "0.005864307750016451\n",
      "0.005273144226521254\n",
      "0.005547958891838789\n",
      "0.006592039950191975\n",
      "0.00570652587339282\n",
      "0.005958046298474073\n",
      "0.005434060003608465\n",
      "0.005830308422446251\n",
      "0.005449576303362846\n",
      "0.005923207383602858\n",
      "0.0054679615423083305\n",
      "0.0054032220505177975\n",
      "0.0057595353573560715\n",
      "0.004845040384680033\n",
      "0.006040556821972132\n",
      "0.005121964495629072\n",
      "0.005030281841754913\n",
      "0.0051275077275931835\n",
      "0.005388731136918068\n",
      "0.006106934510171413\n",
      "0.005634027533233166\n",
      "0.005162882152944803\n",
      "0.005777814891189337\n",
      "0.005994988139718771\n",
      "0.006358517333865166\n",
      "0.005635934416204691\n",
      "0.005379884038120508\n",
      "0.006065587978810072\n",
      "0.0059640188701450825\n",
      "0.005848253611475229\n",
      "0.005399365909397602\n",
      "0.005404973868280649\n",
      "0.005426601506769657\n",
      "0.0056941150687634945\n",
      "0.005690485704690218\n",
      "0.005156049970537424\n",
      "0.005556080024689436\n",
      "0.005327682476490736\n",
      "0.005968662444502115\n",
      "0.005336024332791567\n",
      "0.0052443803288042545\n",
      "0.005438405554741621\n",
      "0.004804903641343117\n",
      "0.005351392086595297\n",
      "0.004887348972260952\n",
      "0.0063241394236683846\n",
      "0.005158781073987484\n",
      "0.005160889588296413\n",
      "0.005347044672816992\n",
      "0.0054116337560117245\n",
      "0.004958360455930233\n",
      "0.005258180666714907\n",
      "0.005691244266927242\n",
      "0.005325437989085913\n",
      "0.0062421346083283424\n",
      "0.005235158372670412\n",
      "0.004912883043289185\n",
      "0.0050771706737577915\n",
      "0.005712615791708231\n",
      "0.00503478292375803\n",
      "0.005632092710584402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [33:08<44:28, 166.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.15693933823529413\n",
      "验证集精度0.2078125\n",
      "测试集精度0.2078125\n",
      "0.005070789717137814\n",
      "0.004779654089361429\n",
      "0.005020285490900278\n",
      "0.0054592471569776535\n",
      "0.0044496674090623856\n",
      "0.005153330508619547\n",
      "0.004377728793770075\n",
      "0.004819695837795734\n",
      "0.005363659467548132\n",
      "0.0050603109411895275\n",
      "0.005087250843644142\n",
      "0.0049867527559399605\n",
      "0.0055353473871946335\n",
      "0.005630727391690016\n",
      "0.004879025276750326\n",
      "0.004208364989608526\n",
      "0.005578336305916309\n",
      "0.005869189742952585\n",
      "0.0049818227998912334\n",
      "0.004719803109765053\n",
      "0.005261710844933987\n",
      "0.005179262720048428\n",
      "0.00452067656442523\n",
      "0.004559965338557959\n",
      "0.004739704076200724\n",
      "0.004756356123834848\n",
      "0.005519687198102474\n",
      "0.004722268786281347\n",
      "0.005315455608069897\n",
      "0.0054587326012551785\n",
      "0.004928880836814642\n",
      "0.004482765682041645\n",
      "0.005289115477353334\n",
      "0.00491061806678772\n",
      "0.005773414857685566\n",
      "0.005096539855003357\n",
      "0.005180886946618557\n",
      "0.0051668970845639706\n",
      "0.0051362477242946625\n",
      "0.005206590052694082\n",
      "0.0043394435197114944\n",
      "0.005210045259445906\n",
      "0.005897064693272114\n",
      "0.005038740113377571\n",
      "0.004942099563777447\n",
      "0.005587744060903788\n",
      "0.005329159088432789\n",
      "0.005049232393503189\n",
      "0.005258035846054554\n",
      "0.005067700054496527\n",
      "0.0052033946849405766\n",
      "0.0051611014641821384\n",
      "0.005652678199112415\n",
      "0.005014902912080288\n",
      "0.004683668725192547\n",
      "0.005539285484701395\n",
      "0.005223455373197794\n",
      "0.005276072304695845\n",
      "0.005489618517458439\n",
      "0.005561428144574165\n",
      "0.005262205842882395\n",
      "0.005378903355449438\n",
      "0.005816356744617224\n",
      "0.005731275305151939\n",
      "0.005620461888611317\n",
      "0.0043417830020189285\n",
      "0.0047153290361166\n",
      "0.005728087853640318\n",
      "0.004718468524515629\n",
      "0.005269766319543123\n",
      "0.005452353041619062\n",
      "0.004703145008534193\n",
      "0.004487060010433197\n",
      "0.004991019610315561\n",
      "0.005136504769325256\n",
      "0.004293624311685562\n",
      "0.0053362539038062096\n",
      "0.005145512521266937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [35:42<40:42, 162.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1640625\n",
      "验证集精度0.221875\n",
      "测试集精度0.2140625\n",
      "0.004528374411165714\n",
      "0.004638885147869587\n",
      "0.00508266594260931\n",
      "0.004303868860006332\n",
      "0.004556337837129831\n",
      "0.005234259646385908\n",
      "0.0048162373714149\n",
      "0.004945363849401474\n",
      "0.004709503147751093\n",
      "0.0052908663637936115\n",
      "0.005239285994321108\n",
      "0.005645679775625467\n",
      "0.0047812433913350105\n",
      "0.004381156526505947\n",
      "0.004385098349303007\n",
      "0.0046759312972426414\n",
      "0.004616757854819298\n",
      "0.004768936894834042\n",
      "0.004725067410618067\n",
      "0.0042082518339157104\n",
      "0.004678459372371435\n",
      "0.00494132936000824\n",
      "0.004564441274851561\n",
      "0.005338170100003481\n",
      "0.005253190640360117\n",
      "0.005269740708172321\n",
      "0.005091158673167229\n",
      "0.004743899684399366\n",
      "0.005573957227170467\n",
      "0.005044966004788876\n",
      "0.004820698406547308\n",
      "0.004586524795740843\n",
      "0.0055260928347706795\n",
      "0.004919913597404957\n",
      "0.005017776973545551\n",
      "0.005234131123870611\n",
      "0.004996621981263161\n",
      "0.004571074154227972\n",
      "0.005370513070374727\n",
      "0.004379849880933762\n",
      "0.004823743831366301\n",
      "0.004771214909851551\n",
      "0.004483293276280165\n",
      "0.004857789259403944\n",
      "0.005200589075684547\n",
      "0.004912780597805977\n",
      "0.004706239327788353\n",
      "0.0053065125830471516\n",
      "0.004651552997529507\n",
      "0.005324219353497028\n",
      "0.005017626564949751\n",
      "0.005024298094213009\n",
      "0.005058853421360254\n",
      "0.005418835207819939\n",
      "0.0044378056190907955\n",
      "0.004658532328903675\n",
      "0.005472823511809111\n",
      "0.004780018236488104\n",
      "0.005068688653409481\n",
      "0.005340187810361385\n",
      "0.005441491492092609\n",
      "0.005718784872442484\n",
      "0.0048952847719192505\n",
      "0.0048249573446810246\n",
      "0.005320844706147909\n",
      "0.005193985998630524\n",
      "0.005183598026633263\n",
      "0.004443211015313864\n",
      "0.0049462392926216125\n",
      "0.004988531116396189\n",
      "0.005493355914950371\n",
      "0.005014871247112751\n",
      "0.0053536733612418175\n",
      "0.005134981125593185\n",
      "0.005093595013022423\n",
      "0.004838769324123859\n",
      "0.005104463081806898\n",
      "0.005012224894016981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [38:27<38:11, 163.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.18037683823529413\n",
      "验证集精度0.259375\n",
      "测试集精度0.2421875\n",
      "0.004975002259016037\n",
      "0.004545319359749556\n",
      "0.004607094451785088\n",
      "0.004423415753990412\n",
      "0.004045461304485798\n",
      "0.004243636038154364\n",
      "0.004597310908138752\n",
      "0.004813114646822214\n",
      "0.004895745776593685\n",
      "0.004141786601394415\n",
      "0.004758169874548912\n",
      "0.0063294777646660805\n",
      "0.0043510510586202145\n",
      "0.004584023263305426\n",
      "0.004949917085468769\n",
      "0.00507059833034873\n",
      "0.005572006572037935\n",
      "0.004609509836882353\n",
      "0.004862330853939056\n",
      "0.005182664375752211\n",
      "0.005031612701714039\n",
      "0.004410186316817999\n",
      "0.005341501906514168\n",
      "0.00510280579328537\n",
      "0.005274455528706312\n",
      "0.004553996026515961\n",
      "0.004899452440440655\n",
      "0.004489388316869736\n",
      "0.0045355516485869884\n",
      "0.004372616298496723\n",
      "0.004723069258034229\n",
      "0.005174847319722176\n",
      "0.005198549013584852\n",
      "0.004552494268864393\n",
      "0.004424098879098892\n",
      "0.004417701158672571\n",
      "0.005068094935268164\n",
      "0.004504166077822447\n",
      "0.004811221268028021\n",
      "0.005191379226744175\n",
      "0.004344325512647629\n",
      "0.0047724684700369835\n",
      "0.004581462126225233\n",
      "0.004490900784730911\n",
      "0.004549436271190643\n",
      "0.004500643815845251\n",
      "0.0050919088535010815\n",
      "0.004626190289855003\n",
      "0.004273786209523678\n",
      "0.005319837015122175\n",
      "0.004378355108201504\n",
      "0.004907199181616306\n",
      "0.004954920616000891\n",
      "0.0047211977653205395\n",
      "0.00420787651091814\n",
      "0.004546919371932745\n",
      "0.004919199272990227\n",
      "0.004201679490506649\n",
      "0.00427106162533164\n",
      "0.005263172555714846\n",
      "0.005070454441010952\n",
      "0.004156461451202631\n",
      "0.004339462146162987\n",
      "0.0042582410387694836\n",
      "0.004767919424921274\n",
      "0.005043158307671547\n",
      "0.004250658210366964\n",
      "0.004855412058532238\n",
      "0.0048047699965536594\n",
      "0.004395637661218643\n",
      "0.0037080682814121246\n",
      "0.004663898143917322\n",
      "0.005159453954547644\n",
      "0.004471858497709036\n",
      "0.004478504415601492\n",
      "0.005083942320197821\n",
      "0.004608249291777611\n",
      "0.005007781088352203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [40:24<32:24, 149.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.18895526960784315\n",
      "验证集精度0.2546875\n",
      "测试集精度0.2375\n",
      "0.0035899414215236902\n",
      "0.004651174880564213\n",
      "0.004674212075769901\n",
      "0.004349529277533293\n",
      "0.004727883730083704\n",
      "0.004451152868568897\n",
      "0.003658182453364134\n",
      "0.004966680891811848\n",
      "0.004092487972229719\n",
      "0.0040064845234155655\n",
      "0.00430822279304266\n",
      "0.004044626839458942\n",
      "0.003917714115232229\n",
      "0.005100220441818237\n",
      "0.004599700216203928\n",
      "0.0047051371075212955\n",
      "0.004301113076508045\n",
      "0.004911859519779682\n",
      "0.00443139486014843\n",
      "0.0046378145925700665\n",
      "0.004931415431201458\n",
      "0.0046145301312208176\n",
      "0.004063157830387354\n",
      "0.004459661897271872\n",
      "0.00505698099732399\n",
      "0.004610275384038687\n",
      "0.005010219290852547\n",
      "0.004327315371483564\n",
      "0.004638838116079569\n",
      "0.004946088418364525\n",
      "0.005348102655261755\n",
      "0.0047999112866818905\n",
      "0.0047435155138373375\n",
      "0.004582683090120554\n",
      "0.0036243251524865627\n",
      "0.004822692833840847\n",
      "0.004122134763747454\n",
      "0.004681244492530823\n",
      "0.004740973934531212\n",
      "0.004135643597692251\n",
      "0.004643207415938377\n",
      "0.004681713879108429\n",
      "0.0048317741602659225\n",
      "0.004249046556651592\n",
      "0.004985520150512457\n",
      "0.00480039743706584\n",
      "0.004981874022632837\n",
      "0.004565009381622076\n",
      "0.004672923590987921\n",
      "0.004573151469230652\n",
      "0.004835518542677164\n",
      "0.0043623922392725945\n",
      "0.004714338108897209\n",
      "0.004138401709496975\n",
      "0.005012958310544491\n",
      "0.004799916408956051\n",
      "0.004657838027924299\n",
      "0.004726014100015163\n",
      "0.004309115465730429\n",
      "0.0047338479198515415\n",
      "0.0045992061495780945\n",
      "0.004720369819551706\n",
      "0.004892257507890463\n",
      "0.0049352580681443214\n",
      "0.004323206841945648\n",
      "0.004130905494093895\n",
      "0.004549060948193073\n",
      "0.005006797611713409\n",
      "0.00476258946582675\n",
      "0.004563624504953623\n",
      "0.004054187797009945\n",
      "0.004767757840454578\n",
      "0.004326651804149151\n",
      "0.004231522791087627\n",
      "0.0039068530313670635\n",
      "0.0047326781786978245\n",
      "0.004365375265479088\n",
      "0.00515065249055624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [42:58<30:09, 150.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.18887867647058823\n",
      "验证集精度0.2640625\n",
      "测试集精度0.240625\n",
      "0.004287810530513525\n",
      "0.00430919136852026\n",
      "0.004282474052160978\n",
      "0.004280232358723879\n",
      "0.003791668452322483\n",
      "0.004145760089159012\n",
      "0.004534091800451279\n",
      "0.003701270092278719\n",
      "0.00453157490119338\n",
      "0.004214996472001076\n",
      "0.003998201340436935\n",
      "0.0037639779038727283\n",
      "0.004662397783249617\n",
      "0.004407708533108234\n",
      "0.004292916040867567\n",
      "0.004301493521779776\n",
      "0.004808047320693731\n",
      "0.004539468325674534\n",
      "0.003934685606509447\n",
      "0.0049422746524214745\n",
      "0.004210176877677441\n",
      "0.004481066949665546\n",
      "0.004395438823848963\n",
      "0.004323364235460758\n",
      "0.004151652101427317\n",
      "0.004576850216835737\n",
      "0.003805897431448102\n",
      "0.00448952428996563\n",
      "0.004088064190000296\n",
      "0.004464497324079275\n",
      "0.004455795045942068\n",
      "0.004447171464562416\n",
      "0.0040487307123839855\n",
      "0.003521805629134178\n",
      "0.00390300783328712\n",
      "0.004412515088915825\n",
      "0.0038271250668913126\n",
      "0.004073754884302616\n",
      "0.0038220032583922148\n",
      "0.004387072753161192\n",
      "0.004330604337155819\n",
      "0.004237595479935408\n",
      "0.004872264806181192\n",
      "0.003754968522116542\n",
      "0.0039999159052968025\n",
      "0.004298820625990629\n",
      "0.004768267273902893\n",
      "0.0037510886322706938\n",
      "0.00404584314674139\n",
      "0.003979334142059088\n",
      "0.0034953264985233545\n",
      "0.004101834259927273\n",
      "0.003995105624198914\n",
      "0.004362119361758232\n",
      "0.004469265230000019\n",
      "0.004567946307361126\n",
      "0.00420427368953824\n",
      "0.004193225875496864\n",
      "0.004784369375556707\n",
      "0.004407177679240704\n",
      "0.00452222628518939\n",
      "0.004262513946741819\n",
      "0.005015014670789242\n",
      "0.005008911248296499\n",
      "0.004380626138299704\n",
      "0.0040061757899820805\n",
      "0.004993665497750044\n",
      "0.004632396157830954\n",
      "0.003950098995119333\n",
      "0.004104037303477526\n",
      "0.004322016146034002\n",
      "0.004151634871959686\n",
      "0.004083547275513411\n",
      "0.004494224674999714\n",
      "0.004202640149742365\n",
      "0.00464630639180541\n",
      "0.004620094783604145\n",
      "0.004100024234503508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [46:08<29:50, 162.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.2028186274509804\n",
      "验证集精度0.29375\n",
      "测试集精度0.26875\n",
      "0.004496115725487471\n",
      "0.004743157885968685\n",
      "0.0042215860448777676\n",
      "0.004041654989123344\n",
      "0.004424975253641605\n",
      "0.003702264977619052\n",
      "0.004164904356002808\n",
      "0.003974806051701307\n",
      "0.004786181263625622\n",
      "0.004529808647930622\n",
      "0.004132622852921486\n",
      "0.004181254655122757\n",
      "0.0040478697046637535\n",
      "0.0037214369513094425\n",
      "0.003888517851009965\n",
      "0.004407566040754318\n",
      "0.003966761287301779\n",
      "0.00393335334956646\n",
      "0.004007907118648291\n",
      "0.004489771090447903\n",
      "0.00383806973695755\n",
      "0.004781848285347223\n",
      "0.0044449493288993835\n",
      "0.003890658961609006\n",
      "0.003955952823162079\n",
      "0.003732660785317421\n",
      "0.004272687714546919\n",
      "0.004320679232478142\n",
      "0.004497738089412451\n",
      "0.003834281349554658\n",
      "0.00410754419863224\n",
      "0.0044968402944505215\n",
      "0.004156880080699921\n",
      "0.004363616928458214\n",
      "0.004823740106076002\n",
      "0.003474294673651457\n",
      "0.0041983830742537975\n",
      "0.004646885674446821\n",
      "0.004496364388614893\n",
      "0.004341466352343559\n",
      "0.004234551452100277\n",
      "0.004171118140220642\n",
      "0.004176015499979258\n",
      "0.0040978239849209785\n",
      "0.004297590348869562\n",
      "0.004145888611674309\n",
      "0.00445494195446372\n",
      "0.004424241371452808\n",
      "0.004110799636691809\n",
      "0.00409667706117034\n",
      "0.004217447247356176\n",
      "0.004251563921570778\n",
      "0.004280759487301111\n",
      "0.004963277373462915\n",
      "0.0036123741883784533\n",
      "0.003646465018391609\n",
      "0.003927484154701233\n",
      "0.004002650734037161\n",
      "0.004491943400353193\n",
      "0.004660849459469318\n",
      "0.004190482199192047\n",
      "0.0044782995246350765\n",
      "0.00470901932567358\n",
      "0.004351458977907896\n",
      "0.0043414575047791\n",
      "0.0042355856858193874\n",
      "0.003681701375171542\n",
      "0.004863526206463575\n",
      "0.004052523523569107\n",
      "0.004024799447506666\n",
      "0.003819878678768873\n",
      "0.004814331419765949\n",
      "0.004741324577480555\n",
      "0.0038909453433007\n",
      "0.003920362796634436\n",
      "0.004974897485226393\n",
      "0.004426647908985615\n",
      "0.0045072780922055244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [48:42<26:39, 159.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.20818014705882354\n",
      "验证集精度0.3015625\n",
      "测试集精度0.278125\n",
      "0.0033762177918106318\n",
      "0.004013070836663246\n",
      "0.004064105451107025\n",
      "0.0039505138993263245\n",
      "0.004491075873374939\n",
      "0.0030728867277503014\n",
      "0.004202212207019329\n",
      "0.004187192302197218\n",
      "0.004567277617752552\n",
      "0.004453632049262524\n",
      "0.003935073968023062\n",
      "0.0039857495576143265\n",
      "0.004572625737637281\n",
      "0.004081431310623884\n",
      "0.0037317564710974693\n",
      "0.003946227952837944\n",
      "0.00409376947209239\n",
      "0.003397564636543393\n",
      "0.003922862466424704\n",
      "0.004318961873650551\n",
      "0.004377553705126047\n",
      "0.003709386335685849\n",
      "0.0037438508588820696\n",
      "0.004152817651629448\n",
      "0.0039720372296869755\n",
      "0.003691080491989851\n",
      "0.0041262623853981495\n",
      "0.004024463705718517\n",
      "0.0040033068507909775\n",
      "0.0041852546855807304\n",
      "0.0036975848488509655\n",
      "0.003979302942752838\n",
      "0.00332301645539701\n",
      "0.003853884991258383\n",
      "0.00426075141876936\n",
      "0.0040133800357580185\n",
      "0.00405633682385087\n",
      "0.004359699320048094\n",
      "0.0040481211617589\n",
      "0.003960965201258659\n",
      "0.004513666033744812\n",
      "0.004216680768877268\n",
      "0.003981450572609901\n",
      "0.0034884605556726456\n",
      "0.0038317821454256773\n",
      "0.004144752863794565\n",
      "0.003165632952004671\n",
      "0.004907903261482716\n",
      "0.004683570936322212\n",
      "0.004041203297674656\n",
      "0.003707741154357791\n",
      "0.003944313153624535\n",
      "0.004242015536874533\n",
      "0.003954910673201084\n",
      "0.004020721185952425\n",
      "0.004235089756548405\n",
      "0.004548364784568548\n",
      "0.0033448999747633934\n",
      "0.0040552448481321335\n",
      "0.004156173672527075\n",
      "0.004210308194160461\n",
      "0.0036495730746537447\n",
      "0.0037166494876146317\n",
      "0.004244494251906872\n",
      "0.004303538706153631\n",
      "0.004234408959746361\n",
      "0.003954159561544657\n",
      "0.004588624928146601\n",
      "0.0035711764357984066\n",
      "0.004449605941772461\n",
      "0.004073912277817726\n",
      "0.0038870377466082573\n",
      "0.0044250646606087685\n",
      "0.0040383003652095795\n",
      "0.003883983474224806\n",
      "0.0038956054486334324\n",
      "0.004186853300780058\n",
      "0.004306794609874487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [50:38<22:02, 146.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.22265625\n",
      "验证集精度0.315625\n",
      "测试集精度0.2875\n",
      "0.00391170522198081\n",
      "0.003921505995094776\n",
      "0.003942226525396109\n",
      "0.003967220429331064\n",
      "0.0036540597211569548\n",
      "0.0038462458178400993\n",
      "0.0034325665328651667\n",
      "0.004164521582424641\n",
      "0.003887058002874255\n",
      "0.0034612007439136505\n",
      "0.003554594237357378\n",
      "0.0036874290090054274\n",
      "0.004026140086352825\n",
      "0.003559087635949254\n",
      "0.00359084689989686\n",
      "0.0037389567587524652\n",
      "0.0033180895261466503\n",
      "0.003267463529482484\n",
      "0.003993416205048561\n",
      "0.0033328908029943705\n",
      "0.003975722473114729\n",
      "0.0038037432823330164\n",
      "0.003787919180467725\n",
      "0.003781364532187581\n",
      "0.004212064202874899\n",
      "0.0036600730381906033\n",
      "0.00351143442094326\n",
      "0.004452286753803492\n",
      "0.002827643882483244\n",
      "0.004160897806286812\n",
      "0.0037682654801756144\n",
      "0.004113666247576475\n",
      "0.003912375774234533\n",
      "0.003573412075638771\n",
      "0.00356588838621974\n",
      "0.0038775005377829075\n",
      "0.0044775595888495445\n",
      "0.003974612336605787\n",
      "0.004267657175660133\n",
      "0.004089245572686195\n",
      "0.004597934894263744\n",
      "0.004138754215091467\n",
      "0.004078803583979607\n",
      "0.003622626420110464\n",
      "0.004438876174390316\n",
      "0.0037224863190203905\n",
      "0.0042186398059129715\n",
      "0.004416860640048981\n",
      "0.003933797590434551\n",
      "0.003946411889046431\n",
      "0.004139490891247988\n",
      "0.004291396588087082\n",
      "0.003549006301909685\n",
      "0.004279515240341425\n",
      "0.004080618266016245\n",
      "0.004500938579440117\n",
      "0.0037104052025824785\n",
      "0.0043719797395169735\n",
      "0.004103485960513353\n",
      "0.0037971523124724627\n",
      "0.003916338086128235\n",
      "0.0033301955554634333\n",
      "0.0045633683912456036\n",
      "0.004727278836071491\n",
      "0.003541194135323167\n",
      "0.004391128197312355\n",
      "0.004087270237505436\n",
      "0.0038417328614741564\n",
      "0.003974869381636381\n",
      "0.003685658099129796\n",
      "0.004814406856894493\n",
      "0.0036607454530894756\n",
      "0.00451387045904994\n",
      "0.003801712766289711\n",
      "0.00438734982162714\n",
      "0.0037482185289263725\n",
      "0.004093626514077187\n",
      "0.004174178931862116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [53:00<19:22, 145.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.23705575980392157\n",
      "验证集精度0.3296875\n",
      "测试集精度0.296875\n",
      "0.0039461590349674225\n",
      "0.003470381023362279\n",
      "0.0030959765426814556\n",
      "0.00397104537114501\n",
      "0.0036878816317766905\n",
      "0.0038170639891177416\n",
      "0.0037376261316239834\n",
      "0.0040624067187309265\n",
      "0.00435420498251915\n",
      "0.003472820622846484\n",
      "0.004118574783205986\n",
      "0.004106651991605759\n",
      "0.0038161727134138346\n",
      "0.004357452969998121\n",
      "0.003398650325834751\n",
      "0.003283559810370207\n",
      "0.003490616800263524\n",
      "0.004202885087579489\n",
      "0.0035343121271580458\n",
      "0.003851122222840786\n",
      "0.0037830532528460026\n",
      "0.003806067630648613\n",
      "0.003479273058474064\n",
      "0.003064812859520316\n",
      "0.0034356017131358385\n",
      "0.003947660326957703\n",
      "0.0038368948735296726\n",
      "0.003520176513120532\n",
      "0.0034931229893118143\n",
      "0.0035975007340312004\n",
      "0.0042930906638503075\n",
      "0.0031356157269328833\n",
      "0.0031378052663058043\n",
      "0.0032670393120497465\n",
      "0.0034808614291250706\n",
      "0.003955826163291931\n",
      "0.003542807651683688\n",
      "0.0033780443482100964\n",
      "0.003552111331373453\n",
      "0.0037487486843019724\n",
      "0.0037407411728054285\n",
      "0.0037742024287581444\n",
      "0.004080821294337511\n",
      "0.0034961483906954527\n",
      "0.0035695035476237535\n",
      "0.004003352485597134\n",
      "0.0033969911746680737\n",
      "0.0034634501207619905\n",
      "0.003563045524060726\n",
      "0.003079519607126713\n",
      "0.003737511346116662\n",
      "0.004637834616005421\n",
      "0.0038631553761661053\n",
      "0.0035113822668790817\n",
      "0.0036048078909516335\n",
      "0.003509974805638194\n",
      "0.003675174666568637\n",
      "0.0033228895626962185\n",
      "0.0037327297031879425\n",
      "0.00404339237138629\n",
      "0.004123102407902479\n",
      "0.003718661144375801\n",
      "0.003864464582875371\n",
      "0.00397566007450223\n",
      "0.0038212102372199297\n",
      "0.002876863582059741\n",
      "0.003209440503269434\n",
      "0.0037675732746720314\n",
      "0.003227698151022196\n",
      "0.003777597565203905\n",
      "0.0036627245135605335\n",
      "0.0034319732803851366\n",
      "0.003820049576461315\n",
      "0.0039644911885261536\n",
      "0.004474216140806675\n",
      "0.004038242157548666\n",
      "0.004221952985972166\n",
      "0.0038967381697148085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [55:33<17:14, 147.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.24701286764705882\n",
      "验证集精度0.3484375\n",
      "测试集精度0.3140625\n",
      "0.0031472821719944477\n",
      "0.0036397057119756937\n",
      "0.003870731685310602\n",
      "0.003744377288967371\n",
      "0.002991184825077653\n",
      "0.0032927801366895437\n",
      "0.0032294096890836954\n",
      "0.003416914027184248\n",
      "0.0041223857551813126\n",
      "0.003752975957468152\n",
      "0.003145036520436406\n",
      "0.003151095937937498\n",
      "0.0037466257344931364\n",
      "0.003482297295704484\n",
      "0.0037077765446156263\n",
      "0.004102923907339573\n",
      "0.0034321853891015053\n",
      "0.0035669568460434675\n",
      "0.0032144386786967516\n",
      "0.003495360491797328\n",
      "0.003489787457510829\n",
      "0.003775018732994795\n",
      "0.003432726953178644\n",
      "0.0029953133780509233\n",
      "0.0029846185352653265\n",
      "0.003880702657625079\n",
      "0.003400009823963046\n",
      "0.003813481656834483\n",
      "0.004228337202221155\n",
      "0.004073853138834238\n",
      "0.0032868306152522564\n",
      "0.003559604985639453\n",
      "0.0035861795768141747\n",
      "0.0035459871869534254\n",
      "0.0038871231954544783\n",
      "0.003247156273573637\n",
      "0.003974737599492073\n",
      "0.003509064204990864\n",
      "0.0035782847553491592\n",
      "0.003890126943588257\n",
      "0.003554376307874918\n",
      "0.0039114076644182205\n",
      "0.0031988820992410183\n",
      "0.0035544270649552345\n",
      "0.003390113590285182\n",
      "0.0031124737579375505\n",
      "0.0037167202681303024\n",
      "0.0036379932425916195\n",
      "0.003247052663937211\n",
      "0.0041244071908295155\n",
      "0.003536555450409651\n",
      "0.0034496814478188753\n",
      "0.0031712865456938744\n",
      "0.003538180375471711\n",
      "0.003818367375060916\n",
      "0.004181084223091602\n",
      "0.0033409814350306988\n",
      "0.0035564368590712547\n",
      "0.003982067573815584\n",
      "0.0035853732842952013\n",
      "0.003668504301458597\n",
      "0.003679587971419096\n",
      "0.0032859116327017546\n",
      "0.0033723306842148304\n",
      "0.0035906885750591755\n",
      "0.004095535259693861\n",
      "0.003860178869217634\n",
      "0.0038406439125537872\n",
      "0.0037311064079403877\n",
      "0.0036675971932709217\n",
      "0.003376367501914501\n",
      "0.0034241648390889168\n",
      "0.003595557762309909\n",
      "0.0036528485361486673\n",
      "0.0037573562003672123\n",
      "0.003684633644297719\n",
      "0.004395920783281326\n",
      "0.004055276047438383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [59:58<18:16, 182.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.2817861519607843\n",
      "验证集精度0.3875\n",
      "测试集精度0.35625\n",
      "0.003190708113834262\n",
      "0.003519674064591527\n",
      "0.004246118012815714\n",
      "0.00333584938198328\n",
      "0.0033831982873380184\n",
      "0.0034101037308573723\n",
      "0.0038586906157433987\n",
      "0.003697439096868038\n",
      "0.0029851750005036592\n",
      "0.003880136413499713\n",
      "0.0034693581983447075\n",
      "0.003453405573964119\n",
      "0.0037683523260056973\n",
      "0.0038471873849630356\n",
      "0.0035100136883556843\n",
      "0.0035336874425411224\n",
      "0.0036775791086256504\n",
      "0.0035346774384379387\n",
      "0.0034379209391772747\n",
      "0.0039818971417844296\n",
      "0.0038330196402966976\n",
      "0.0032928583677858114\n",
      "0.003563506994396448\n",
      "0.003339142305776477\n",
      "0.0032017056364566088\n",
      "0.004255214706063271\n",
      "0.0030619583558291197\n",
      "0.004022851120680571\n",
      "0.003627668134868145\n",
      "0.0032406034879386425\n",
      "0.0034095929004251957\n",
      "0.004317725542932749\n",
      "0.0033807968720793724\n",
      "0.003252275986596942\n",
      "0.003490293398499489\n",
      "0.0039020339027047157\n",
      "0.003167038317769766\n",
      "0.003924892749637365\n",
      "0.004083707928657532\n",
      "0.0035979386884719133\n",
      "0.004390683025121689\n",
      "0.0037498923484236\n",
      "0.003023808356374502\n",
      "0.0033055944368243217\n",
      "0.003519758116453886\n",
      "0.0032552951015532017\n",
      "0.0033503943122923374\n",
      "0.0038335230201482773\n",
      "0.00335990684106946\n",
      "0.0036486356984823942\n",
      "0.0034985868260264397\n",
      "0.003646304365247488\n",
      "0.0035949144512414932\n",
      "0.0027849646285176277\n",
      "0.004063637927174568\n",
      "0.0032912164460867643\n",
      "0.003616699483245611\n",
      "0.0034114595036953688\n",
      "0.0036186676006764174\n",
      "0.003824964864179492\n",
      "0.003445928916335106\n",
      "0.0034879634622484446\n",
      "0.0030970966909080744\n",
      "0.0027949137147516012\n",
      "0.003433401696383953\n",
      "0.0036747681442648172\n",
      "0.0035197597462683916\n",
      "0.0036927431356161833\n",
      "0.0032705182675272226\n",
      "0.0038082872051745653\n",
      "0.0034060929901897907\n",
      "0.0034219734370708466\n",
      "0.003304314101114869\n",
      "0.003160197986289859\n",
      "0.0034733470529317856\n",
      "0.003402288071811199\n",
      "0.003150288248434663\n",
      "0.003223256440833211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [1:02:43<14:48, 177.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.2704503676470588\n",
      "验证集精度0.3703125\n",
      "测试集精度0.34375\n",
      "0.0029794287402182817\n",
      "0.0033431502524763346\n",
      "0.0032816403545439243\n",
      "0.0033059900160878897\n",
      "0.003274620743468404\n",
      "0.003116723382845521\n",
      "0.0034621763043105602\n",
      "0.00315238069742918\n",
      "0.0031713536009192467\n",
      "0.0032207234762609005\n",
      "0.0029991173651069403\n",
      "0.0031439627055078745\n",
      "0.0028581733349710703\n",
      "0.0032909305300563574\n",
      "0.0034103235229849815\n",
      "0.003028042148798704\n",
      "0.0035790186375379562\n",
      "0.0034312347415834665\n",
      "0.002958518685773015\n",
      "0.003288152627646923\n",
      "0.004040999803692102\n",
      "0.0030922049190849066\n",
      "0.002928386442363262\n",
      "0.003680140245705843\n",
      "0.0025494329165667295\n",
      "0.003542811842635274\n",
      "0.0033073979429900646\n",
      "0.003146327566355467\n",
      "0.0037139304913580418\n",
      "0.0035695608239620924\n",
      "0.0032024576794356108\n",
      "0.0036570208612829447\n",
      "0.0035258226562291384\n",
      "0.0032698949798941612\n",
      "0.0031669284217059612\n",
      "0.00291047478094697\n",
      "0.0036166731733828783\n",
      "0.0036843623965978622\n",
      "0.0031885693315416574\n",
      "0.003895984496921301\n",
      "0.004259833600372076\n",
      "0.0035651486832648516\n",
      "0.003334982553496957\n",
      "0.0032889896538108587\n",
      "0.0032472002785652876\n",
      "0.003675309242680669\n",
      "0.0036954309325665236\n",
      "0.003293045097962022\n",
      "0.0031537150498479605\n",
      "0.0035319349262863398\n",
      "0.003424667753279209\n",
      "0.002966927830129862\n",
      "0.0034668410662561655\n",
      "0.0034254295751452446\n",
      "0.0037404007744044065\n",
      "0.0035216710530221462\n",
      "0.0032073569018393755\n",
      "0.0035722549073398113\n",
      "0.0031488698441535234\n",
      "0.0033216725569218397\n",
      "0.004340655170381069\n",
      "0.0036257202737033367\n",
      "0.003799383295699954\n",
      "0.003612840548157692\n",
      "0.0030073514208197594\n",
      "0.003467939328402281\n",
      "0.003758605569601059\n",
      "0.003043309086933732\n",
      "0.0035854228772222996\n",
      "0.002995066111907363\n",
      "0.003073640400543809\n",
      "0.0032299102749675512\n",
      "0.003338067326694727\n",
      "0.0036562560126185417\n",
      "0.0031570910941809416\n",
      "0.0033148524817079306\n",
      "0.0032105103600770235\n",
      "0.003707056399434805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [1:05:05<11:06, 166.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.28722426470588236\n",
      "验证集精度0.375\n",
      "测试集精度0.35625\n",
      "0.002754055894911289\n",
      "0.00353199802339077\n",
      "0.003053215565159917\n",
      "0.0033677793107926846\n",
      "0.003661337075755\n",
      "0.0030704012606292963\n",
      "0.0036615568678826094\n",
      "0.0032991685438901186\n",
      "0.002924110274761915\n",
      "0.0027671707794070244\n",
      "0.0034942266065627337\n",
      "0.0036734568420797586\n",
      "0.0027680997736752033\n",
      "0.003006360959261656\n",
      "0.0034809524659067392\n",
      "0.0030998883303254843\n",
      "0.002753585111349821\n",
      "0.003227286273613572\n",
      "0.003417667467147112\n",
      "0.0033006451558321714\n",
      "0.0032056118361651897\n",
      "0.0031353377271443605\n",
      "0.003140584100037813\n",
      "0.003032804001122713\n",
      "0.003477068617939949\n",
      "0.002968695480376482\n",
      "0.0035417608451098204\n",
      "0.0035641684662550688\n",
      "0.003072375198826194\n",
      "0.0032656388357281685\n",
      "0.0038527529686689377\n",
      "0.0036733471788465977\n",
      "0.0034032436087727547\n",
      "0.0028208824805915356\n",
      "0.0033750412985682487\n",
      "0.0030628356616944075\n",
      "0.003192586125805974\n",
      "0.0031431333627551794\n",
      "0.0032563211861997843\n",
      "0.0032278650905936956\n",
      "0.0033656274899840355\n",
      "0.003117502899840474\n",
      "0.0032270473893731833\n",
      "0.0031714902725070715\n",
      "0.0030912801157683134\n",
      "0.003712280187755823\n",
      "0.003378237597644329\n",
      "0.0030151070095598698\n",
      "0.003267353167757392\n",
      "0.0032035810872912407\n",
      "0.002983628073707223\n",
      "0.0032922185491770506\n",
      "0.003175989491865039\n",
      "0.003297764342278242\n",
      "0.0033353755716234446\n",
      "0.003069970989599824\n",
      "0.0034039607271552086\n",
      "0.00291765620931983\n",
      "0.002923129592090845\n",
      "0.0035052925813943148\n",
      "0.0031206938438117504\n",
      "0.003494875505566597\n",
      "0.0035587274469435215\n",
      "0.003458040300756693\n",
      "0.002907011890783906\n",
      "0.0030155081767588854\n",
      "0.0027337982319295406\n",
      "0.0031018913723528385\n",
      "0.0032143641728907824\n",
      "0.0029534490313380957\n",
      "0.003180556930601597\n",
      "0.003492312040179968\n",
      "0.0029674777761101723\n",
      "0.0032473590690642595\n",
      "0.0030735337641090155\n",
      "0.002685945713892579\n",
      "0.0036630595568567514\n",
      "0.0033718303311616182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [1:09:05<09:26, 188.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.32230392156862747\n",
      "验证集精度0.4078125\n",
      "测试集精度0.375\n",
      "0.0028931195847690105\n",
      "0.0032469232100993395\n",
      "0.002867411356419325\n",
      "0.0028791960794478655\n",
      "0.0027090737130492926\n",
      "0.0032372595742344856\n",
      "0.003015673253685236\n",
      "0.0028132819570600986\n",
      "0.0035896531771868467\n",
      "0.002884852234274149\n",
      "0.0033838602248579264\n",
      "0.002883518347516656\n",
      "0.0035498258657753468\n",
      "0.003201675834134221\n",
      "0.002850718330591917\n",
      "0.0027073691599071026\n",
      "0.0028857116121798754\n",
      "0.0035027447156608105\n",
      "0.003693175269290805\n",
      "0.003034986788406968\n",
      "0.0031471392139792442\n",
      "0.0029724182095378637\n",
      "0.0033358039800077677\n",
      "0.0035199555568397045\n",
      "0.002957538003101945\n",
      "0.002698300639167428\n",
      "0.003201663726940751\n",
      "0.00363026256673038\n",
      "0.0032579610124230385\n",
      "0.0033047767356038094\n",
      "0.002820509485900402\n",
      "0.003248311346396804\n",
      "0.00295309629291296\n",
      "0.0028731722850352526\n",
      "0.0029609466437250376\n",
      "0.002771377796307206\n",
      "0.002909918548539281\n",
      "0.002742575015872717\n",
      "0.0029049727600067854\n",
      "0.0034414350520819426\n",
      "0.0032114596106112003\n",
      "0.0029264569748193026\n",
      "0.003015236696228385\n",
      "0.0032271721865981817\n",
      "0.002589951269328594\n",
      "0.003391848411411047\n",
      "0.0035693752579391003\n",
      "0.0027488218620419502\n",
      "0.0029263512697070837\n",
      "0.0023385353852063417\n",
      "0.0028166661504656076\n",
      "0.0033352880273014307\n",
      "0.0035402458161115646\n",
      "0.0032025135587900877\n",
      "0.002825914416462183\n",
      "0.0033582441974431276\n",
      "0.0025932379066944122\n",
      "0.0027186681982129812\n",
      "0.002988081658259034\n",
      "0.0028763064183294773\n",
      "0.002796758431941271\n",
      "0.002874111058190465\n",
      "0.0032938779331743717\n",
      "0.0033176110591739416\n",
      "0.0033792583271861076\n",
      "0.002320143859833479\n",
      "0.002929533366113901\n",
      "0.003285998245701194\n",
      "0.003306683385744691\n",
      "0.003161347471177578\n",
      "0.0027344594709575176\n",
      "0.0028916294686496258\n",
      "0.002673510694876313\n",
      "0.0028495662845671177\n",
      "0.0025545444805175066\n",
      "0.003186890622600913\n",
      "0.0030932545196264982\n",
      "0.00334532605484128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [1:11:14<05:41, 170.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.31686580882352944\n",
      "验证集精度0.415625\n",
      "测试集精度0.3875\n",
      "0.0023870188742876053\n",
      "0.003011861350387335\n",
      "0.002920102560892701\n",
      "0.003550885245203972\n",
      "0.0029926549177616835\n",
      "0.002721714321523905\n",
      "0.0033240816555917263\n",
      "0.00300432532094419\n",
      "0.002737960312515497\n",
      "0.002808853518217802\n",
      "0.0031238559167832136\n",
      "0.002613743068650365\n",
      "0.002630609553307295\n",
      "0.002661434467881918\n",
      "0.003219231264665723\n",
      "0.0027541981544345617\n",
      "0.0032778666354715824\n",
      "0.0027469026390463114\n",
      "0.002915901830419898\n",
      "0.0029981473926454782\n",
      "0.0028560806531459093\n",
      "0.002806843491271138\n",
      "0.0028249018359929323\n",
      "0.0032287794165313244\n",
      "0.002947601955384016\n",
      "0.0031637565698474646\n",
      "0.002581656677648425\n",
      "0.003134841797873378\n",
      "0.0033543547615408897\n",
      "0.002714365953579545\n",
      "0.003017766634002328\n",
      "0.00279386923648417\n",
      "0.0027657272294163704\n",
      "0.0028906676452606916\n",
      "0.0031629290897399187\n",
      "0.003172211581841111\n",
      "0.0026567259337753057\n",
      "0.003244205377995968\n",
      "0.0025666728615760803\n",
      "0.00329564418643713\n",
      "0.003103027818724513\n",
      "0.002652448834851384\n",
      "0.003619337920099497\n",
      "0.0027656801976263523\n",
      "0.00291478936560452\n",
      "0.0030527659691870213\n",
      "0.003244228195399046\n",
      "0.0033473060466349125\n",
      "0.002771563595160842\n",
      "0.0031131962314248085\n",
      "0.0036142657045274973\n",
      "0.0033139085862785578\n",
      "0.003216978395357728\n",
      "0.0027338783256709576\n",
      "0.0032515632919967175\n",
      "0.0030450215563178062\n",
      "0.003166783833876252\n",
      "0.0030250726267695427\n",
      "0.003474487690255046\n",
      "0.003223494393751025\n",
      "0.003063842887058854\n",
      "0.0027650645934045315\n",
      "0.0033464902080595493\n",
      "0.0035858475603163242\n",
      "0.003037487855181098\n",
      "0.003121460322290659\n",
      "0.0031725172884762287\n",
      "0.0029621559660881758\n",
      "0.0032270322553813457\n",
      "0.00333029730245471\n",
      "0.002656355733051896\n",
      "0.0032442801166325808\n",
      "0.0027354038320481777\n",
      "0.0034838467836380005\n",
      "0.0034548919647932053\n",
      "0.0031553031876683235\n",
      "0.003606838406994939\n",
      "0.002832168247550726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [1:13:22<02:38, 158.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.32138480392156865\n",
      "验证集精度0.434375\n",
      "测试集精度0.3921875\n",
      "0.002932942006736994\n",
      "0.002526561263948679\n",
      "0.002598114777356386\n",
      "0.003185140434652567\n",
      "0.0027263867668807507\n",
      "0.0029171458445489407\n",
      "0.0029024456162005663\n",
      "0.0025600690860301256\n",
      "0.0026465358678251505\n",
      "0.0025850487872958183\n",
      "0.0031239339150488377\n",
      "0.002861517947167158\n",
      "0.002989212516695261\n",
      "0.002519071102142334\n",
      "0.0023474444169551134\n",
      "0.0029933343175798655\n",
      "0.003179640742018819\n",
      "0.003168657887727022\n",
      "0.002871177392080426\n",
      "0.0028135499451309443\n",
      "0.0030094918329268694\n",
      "0.002479023300111294\n",
      "0.0030439698603004217\n",
      "0.003217275720089674\n",
      "0.0033955960534512997\n",
      "0.0031405386980623007\n",
      "0.002943863160908222\n",
      "0.003112506354227662\n",
      "0.002931327326223254\n",
      "0.0023139421828091145\n",
      "0.002681003650650382\n",
      "0.0027312664315104485\n",
      "0.002697567455470562\n",
      "0.0027721086516976357\n",
      "0.0027761561796069145\n",
      "0.0027475315146148205\n",
      "0.0027192928828299046\n",
      "0.0032971512991935015\n",
      "0.003257213393226266\n",
      "0.0031446698121726513\n",
      "0.0028889861423522234\n",
      "0.0028334895614534616\n",
      "0.0028600296936929226\n",
      "0.0030719998758286238\n",
      "0.0027226777747273445\n",
      "0.0030219540931284428\n",
      "0.00277517968788743\n",
      "0.0035349291283637285\n",
      "0.002684701466932893\n",
      "0.002656001830473542\n",
      "0.0030018945690244436\n",
      "0.003761450294405222\n",
      "0.0034519119653850794\n",
      "0.002994324080646038\n",
      "0.002838076325133443\n",
      "0.0028843646869063377\n",
      "0.002977245720103383\n",
      "0.0031139326747506857\n",
      "0.003734544850885868\n",
      "0.0029062023386359215\n",
      "0.003037607530131936\n",
      "0.0030714382883161306\n",
      "0.003042719792574644\n",
      "0.0029229805804789066\n",
      "0.0031846805941313505\n",
      "0.0031328448094427586\n",
      "0.002864301670342684\n",
      "0.0035292007960379124\n",
      "0.002877305494621396\n",
      "0.003077939385548234\n",
      "0.0029869440477341413\n",
      "0.0024880447890609503\n",
      "0.0032462829258292913\n",
      "0.00250938325189054\n",
      "0.002841079840436578\n",
      "0.003323409240692854\n",
      "0.0024588757660239935\n",
      "0.002793115796521306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:16:21<00:00, 152.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.3570772058823529\n",
      "验证集精度0.4265625\n",
      "测试集精度0.4140625\n",
      "训练集最终精度0.3570772058823529\n",
      "验证集最终精度0.4265625\n",
      "测试集最终精度0.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Teachermodel(MyModel_Config(train_original_labels))\n",
    "student_revise = Studentmodel_revise(bert_student, 'cuda:0')\n",
    "teacher_revise = Teachermodel_revise(teacher_model, \"cuda:0\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_revise.parameters(), lr=1e-5)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model.bert.embeddings, teacher_revise, student_revise, DIemb_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('csuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab6d371e845a933fefd78872ae9ed5c08b7429001c2088fe7b56efc961c495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
