{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_init import class_incremental, Data_Init\n",
    "from model_config import MyModel_Config\n",
    "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt   #jupyter要matplotlib.pyplot\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import random\n",
    "from train_eval import Model_Train\n",
    "import re\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''调整随机数'''\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''利用增量数据初始化处理数据集'''\n",
    "train_incremental = class_incremental('./data/snips/train.tsv', 'tsv', 64, 7, 5, True, 9999999) #最后的500表示每个类的数据个数限制\n",
    "train_original_datas, train_incremental_datas_list, train_original_labels, train_all_incremental_labels, labels, label_to_idx = train_incremental.prepare_for_incremental()\n",
    "train_Joint_datasets = train_incremental.Joint_incremental()\n",
    "\n",
    "#初始化验证集的原始类和增量类数据\n",
    "dev_incremental = class_incremental('./data/snips/dev.tsv', 'tsv', 64, 7, 5, True, 999999, 'eval', labels, label_to_idx)\n",
    "dev_original_datas, dev_incremental_datas_list, dev_original_labels, dev_all_incremental_labels = dev_incremental.prepare_for_incremental()\n",
    "dev_Joint_datasets = dev_incremental.Joint_incremental()\n",
    "\n",
    "#初始化测试集的原始类和增量类数据\n",
    "test_incremental = class_incremental('./data/snips/test.tsv', 'tsv', 64, 7, 5, True, 9999999, 'eval', labels, label_to_idx)\n",
    "test_original_datas, test_incremental_datas_list, test_original_labels, test_all_incremental_labels = test_incremental.prepare_for_incremental()\n",
    "test_Joint_datasets = test_incremental.Joint_incremental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义训练模型'''\n",
    "class Teachermodel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Teachermodel,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "\n",
    "        self.fc = nn.Linear(768, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "     \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    " \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型'''\n",
    "class Bert_student(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_student,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(config.bertmini_path)  \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.dropout=nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(256, config.num_classes ) \n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "    \n",
    "        encoder_out,pooled = self.bert(tokens,output_all_encoded_layers=False) \n",
    "        out=self.fc(encoder_out[:,0,:])\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Train_ipynb(object):\n",
    "    def __init__(self, isTPCIL=False): #\n",
    "        #self.epochs = MyModel_Config.epochs #训练几个epochs\n",
    "        self.device = 'cuda:0'\n",
    "        self.isTPCIL = isTPCIL\n",
    "        \n",
    "    '''测试集和验证集的精度计算,用于全体验证集或测试集的精度计算\n",
    "    model：要评估的模型\n",
    "    datapath：输入字符串如'./data/snips/valid.csv'，表明要测试的验证集或测试集路径\n",
    "    mode:输入字符串'csv'或'tsv' ，表明要测试的文件格式'''\n",
    "    def my_eval(self, model, datapath, loss_func, mode, label_to_idx_train):\n",
    "        device = self.device\n",
    "        tensor_datas, labels_idx = Data_Init(datapath, 64, mode, 'eval', label_to_idx_train).datas_to_tensors()#输出都是tensor形式\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval() #eval()将我们的模型置于评估模式，而不是训练模式。在这种情况下，评估模式关闭了训练中使用的dropout正则化。\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "        with torch.no_grad():\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                #虽然这里的probs没有经过softmax处理，但也可以用下面的这个argmax公式，因为softmax不会改变原本数值元素的大小排名\n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = accuracy / (idx*tensor_datas.batch_size + last_size)\n",
    "        accuracy = accuracy.item()\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "    \n",
    "    '''由于增量学习要求对相应的增量类和原始类数据进行精度的计算，所以如果直接输入验证集路径进去，会导致计算所有类精度，所以这里输入变为直接输入数据\n",
    "    model:要进行精度计算的模型\n",
    "tensor_datas:验证集/测试集的经过Dataloader封装的数据\n",
    "loss_function:用于计算验证集/测试集损失'''\n",
    "\n",
    "    def eval_for_incremental(self, model, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        model = model.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        model.eval() #关闭模型dropout\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "                \n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        model.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "#用法：\n",
    "#eval_for_incremental(model, tensor_datas, loss_function),用法在incremental_learning文件的类中\n",
    "\n",
    "    def eval_for_embeddingKD(self, teacher_embed_model, student_revise, tensor_datas, loss_function):\n",
    "        device = self.device\n",
    "        teacher_embed_model = teacher_embed_model.to(device)\n",
    "        student_revise = student_revise.to(device)\n",
    "\n",
    "        accuracy=0\n",
    "        loss_sum=0\n",
    "    \n",
    "        teacher_embed_model.eval() #关闭模型dropout\n",
    "        student_revise.eval()\n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for idx, datas in enumerate(tensor_datas):\n",
    "                tokens = datas[0].to(device)  #tokens输入到bert里得到[batch_size, seq_len, embedding_size]的embedding\n",
    "                labels_idx = datas[1].to(device)\n",
    "\n",
    "                teacher_embed = teacher_embed_model(tokens)\n",
    "                probs = student_revise(teacher_embed)\n",
    "\n",
    "                loss = loss_function(probs, labels_idx) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "            \n",
    "                accuracy += (labels_idx == torch.argmax(probs, dim=1)).sum()  #计算预测标签和真实标签相等的数量\n",
    "                loss_sum+=loss.item() #计算所有样本/batch的loss\n",
    "                \n",
    "                last_size = len(datas[1])  #用于保存最后一个batch有多少数据\n",
    "\n",
    "        accuracy = float(accuracy) / (idx*tensor_datas.batch_size + last_size)\n",
    "\n",
    "        student_revise.train()#从eval模式回到train模式\n",
    "\n",
    "        return accuracy, loss_sum\n",
    "\n",
    "\n",
    "    '''参数：\n",
    "    model：训练模型\n",
    "    loss_func:损失函数\n",
    "    optimizer:优化器\n",
    "    epochs:迭代次数\n",
    "    tensor_datas:要输入的Dataloader封装的数据，默认为MyModel_Config里面的数据\n",
    "    datapath_eval: 如果等于'none'说明不对验证集或测试集进行每个batch训练后的精度和损失计算；如果等于验证集或测试集路径，则进行计算\n",
    "    eval_mode：验证集或测试集的格式，为'csv'或'tsv'.\n",
    "    label_to_idx_train:训练集的标签字典，只有当datapath_eval不为none时候才设置初值'''\n",
    "    def my_train(self, model, loss_func, optimizer, epochs, tensor_datas, datapath_eval='none', eval_mode='csv', label_to_idx_train={}): #增加了需要自己输入的epochs\n",
    "        device = self.device\n",
    "        #epochs = self.epochs\n",
    "        model.train()\n",
    "\n",
    "        model = model.to(device)\n",
    "        losses = [] #存放所有样本一个epoch的损失\n",
    "        accuracies = []\n",
    "        iter = [] #用于绘图的横坐标\n",
    "\n",
    "        #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            '''对每个batch的训练'''\n",
    "            for idx, datas in enumerate(tensor_datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "                tokens = datas[0].to(device)\n",
    "                labels = datas[1].to(device)\n",
    "                #labels_one_hot = datas[1].to(device)  #one-hot形式标签，用于损失计算，[batch_size, labels_nums]\n",
    "                #labels = torch.topk(labels_one_hot, 1)[1].view(-1,1)   #要计算精度，就需要非one-hot形式的标签，转化为(batch_size,1)形式的标签\n",
    "        \n",
    "                optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "                if self.isTPCIL == False:\n",
    "                    probs = model(tokens).squeeze()  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                elif self.isTPCIL == True:\n",
    "                    _, probs = model(tokens)  #去除掉[batch_size, 1, len(classes)]中的1维度\n",
    "                    probs.squeeze()\n",
    "                loss = loss_func(probs, labels) #\"host_softmax\" not implemented for 'Long'错误出现，如果预测值和标签写反\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()#学习率递减\n",
    "            accuracy_train, loss_sum = self.eval_for_incremental(model, tensor_datas, loss_func)\n",
    "    \n",
    "            if datapath_eval != 'none': \n",
    "                if label_to_idx_train == {}:\n",
    "                    raise ValueError(\"要输出测试集精度模式下需要输入训练集对应的标签字典\")\n",
    "                accuracy_eval, loss_eval = self.my_eval(model, datapath_eval, loss_func, eval_mode, label_to_idx_train)\n",
    "                print('第'+str(epoch)+'的验证集失为：'+str(loss_eval))\n",
    "                print('第'+str(epoch)+'的验证集精度为：'+str(accuracy_eval))\n",
    "            \n",
    "            accuracies.append(accuracy_train) #accuracy上的数据在cuda上，需要放到cpu上才能作图，而loss.item()已经加到cpu上了\n",
    "            losses.append(loss_sum)\n",
    "            iter.append(epoch)\n",
    "            #print(\"the loss of  training data \"+ str(epoch) + \"  is-----------\" + str(loss_sum))\n",
    "            #print(\"the accuracy of training data   \"+ str(epoch) + \"  is-----------\" + str(accuracy_train))\n",
    "    \n",
    "        #plt.figure(1)\n",
    "        #plt.title(\"loss of epoch per————\"+str(loss_func)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"loss per epoch\")\n",
    "        #plt.ylabel(\"LOSS\")\n",
    "        #plt.plot(iter, losses)\n",
    "\n",
    "        #plt.figure(2)\n",
    "        #plt.title(\"accuracy of epoch per————\"+str(accuracy_train)+ \",\"+ str(epochs)+ \"epochs\")\n",
    "        #plt.xlabel(\"accuracy per epoch\")\n",
    "        #plt.ylabel(\"ACCURACY\")\n",
    "        #plt.plot(iter, accuracies)\n",
    "\n",
    "        #plt.show()\n",
    "        return accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:13<00:00, 55.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9859068627450981, 0.9905790441176471, 0.9931832107843137, 0.9954810049019608, 0.9931832107843137, 0.9967830882352942, 0.9983915441176471, 0.9983149509803921, 0.9990042892156863, 0.9993872549019608]\n",
      "验证集最终精度0.9875\n",
      "测试集最终精度0.98125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(teacher_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(teacher_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(teacher_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Student model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:59<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.934359681372549, 0.9654564950980392, 0.9760263480392157, 0.9816176470588235, 0.9832261029411765, 0.9862132352941176, 0.9872855392156863, 0.9892769607843137, 0.9896599264705882, 0.9919577205882353]\n",
      "验证集最终精度0.9859375\n",
      "测试集最终精度0.978125\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Student model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(student_model, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(student_model, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(student_model, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''teacher模型,embedding层的参数不可修改'''\n",
    "class Teachermodel_revise(nn.Module):\n",
    "    def __init__(self,teacher_model, device):\n",
    "        super(Teachermodel_revise,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.teacher_model_embedding = teacher_model.bert.embeddings\n",
    "        for param in self.teacher_model_embedding.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = True   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_classifier = nn.Sequential(teacher_model.dropout,\n",
    "                                                      teacher_model.fc)\n",
    "        for param in self.teacher_model_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        out = self.teacher_model_embedding(tokens)\n",
    "        \n",
    "        out = self.teacher_model_encoder(out, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_classifier(pooled_output)\n",
    "        \n",
    "        return probs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Teacher model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:06<07:16, 62.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8647/1812663237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m'''训练模型，得到精度'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_Train_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_model_reviese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fuc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_original_datas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maccuracy_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_Train_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_for_incremental\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_model_reviese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_original_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fuc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_Train_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_for_incremental\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_model_reviese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_original_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fuc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8647/3707996597.py\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(self, model, loss_func, optimizer, epochs, tensor_datas, datapath_eval, eval_mode, label_to_idx_train)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m#scheduler.step()#学习率递减\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_for_incremental\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdatapath_eval\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8647/3707996597.py\u001b[0m in \u001b[0;36meval_for_incremental\u001b[0;34m(self, model, tensor_datas, loss_function)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#计算预测标签和真实标签相等的数量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mloss_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#计算所有样本/batch的loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mlast_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#用于保存最后一个batch有多少数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存Teacher model'''\n",
    "print('*******************原始数据训练Teacher model**********************')\n",
    "teacher_model = Teachermodel(MyModel_Config(train_original_labels))\n",
    "teacher_model_reviese = Teachermodel_revise(teacher_model, 'cuda:0')\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(teacher_model_reviese, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(teacher_model_reviese, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(teacher_model_reviese, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''student模型,embedding层的参数不可修改'''\n",
    "class Studentmodel_revise(nn.Module):\n",
    "    def __init__(self,student_model, device):\n",
    "        super(Studentmodel_revise,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.student_model_embedding = student_model.bert.embeddings\n",
    "        for param in self.student_model_embedding.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.student_model_encoder = student_model.bert.encoder\n",
    "        for param in self.student_model_encoder.parameters():    \n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.student_model_remain = student_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.student_model_remain.parameters():    \n",
    "            param.requires_grad = True   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.student_model_classifier = nn.Sequential(student_model.dropout,\n",
    "                                                      student_model.fc)\n",
    "        for param in self.student_model_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        out = self.student_model_embedding(tokens)\n",
    "        \n",
    "        out = self.student_model_encoder(out, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.student_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.student_model_classifier(pooled_output)\n",
    "        \n",
    "        return probs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************原始数据训练Student model**********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:53<00:00, 11.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度变化[0.9080116421568627, 0.9607077205882353, 0.9668351715686274, 0.9743412990196079, 0.9822303921568627, 0.9859068627450981, 0.9880514705882353, 0.9881280637254902, 0.9901960784313726, 0.9916513480392157]\n",
      "验证集最终精度0.984375\n",
      "测试集最终精度0.9796875\n"
     ]
    }
   ],
   "source": [
    "'''利用原始数据训练并保存student model'''\n",
    "print('*******************原始数据训练Student model**********************')\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "student_model_reviese = Studentmodel_revise(student_model, 'cuda:0')\n",
    "optimizer = torch.optim.AdamW(student_model_reviese.parameters(), lr=1e-5)\n",
    "loss_fuc = nn.CrossEntropyLoss()\n",
    "\n",
    "'''训练模型，得到精度'''\n",
    "accuracy_train, loss_train = Model_Train_ipynb().my_train(student_model_reviese, loss_fuc, optimizer, 10, train_original_datas)\n",
    "accuracy_dev, loss_dev = Model_Train_ipynb().eval_for_incremental(student_model_reviese, dev_original_datas, loss_fuc)\n",
    "accuracy_test, loss_test = Model_Train_ipynb().eval_for_incremental(student_model_reviese, test_original_datas, loss_fuc)\n",
    "print('训练集精度变化'+str(accuracy_train))\n",
    "print('验证集最终精度'+str(accuracy_dev))\n",
    "print('测试集最终精度'+str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weight = teacher_model.fc.weight.detach().to('cpu')  #去除梯度\n",
    "concent_params = torch.zeros([last_layer_weight.shape[0], last_layer_weight.shape[0]])\n",
    "for i in range(len(last_layer_weight)):\n",
    "    for j in range(len(last_layer_weight)):\n",
    "        param = torch.matmul(last_layer_weight[i],last_layer_weight[j])\n",
    "        param = param / (torch.norm(last_layer_weight[i]) * torch.norm(last_layer_weight[j]))  #计算最后一层权重的关系\n",
    "        concent_params[i][j] = param\n",
    "        \n",
    "    max_val = torch.max(concent_params[i])\n",
    "    min_val = torch.min(concent_params[i])\n",
    "    concent_params[i] = (concent_params[i] - min_val + 1e-7) / (max_val-min_val)   #加上1e-7防止有0存在\n",
    "    \n",
    "labels = train_original_labels #绘图用到的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''相似度矩阵绘制'''\n",
    "def similar_matrix_plot(concent_params, num_classes, labels):#绘制混淆矩阵\n",
    "    matrix = concent_params.numpy()  #先放在numpy上才能作图\n",
    "    plt.figure(figsize=(15,15))  #设置画布大小\n",
    "    plt.imshow(matrix, cmap=plt.cm.Oranges)\n",
    "  \n",
    "    # 设置x轴坐标label\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels,fontsize=5)\n",
    "    plt.yticks(tick_marks, labels,fontsize=5)\n",
    "        # 显示colorbar\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('similarity matrix ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "similar_matrix_plot(concent_params, len(train_original_labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''通过teacher model和direclet samples训练生成DI的embeddings，用于蒸馏student model\n",
    "DIemb_Gen_model:用于生成DI embedding的模型\n",
    "dir_samples:用Dataloader包装的迪利克雷分布及其标签\n",
    "opitmizer:用于优化DIemb_Gen_model\n",
    "loss_func:KL散度\n",
    "loss_func2:交叉熵\n",
    "'''\n",
    "def train_DI_Embeddings_gen(DIemb_Gen_model, DIemb_datasets, optimizer, loss_func, loss_func2, temper=10, error=0.3, batch_size=64, max_iter=True):\n",
    "    device = 'cuda:0'\n",
    "    loss_num=999\n",
    "    DIemb_Gen_model = DIemb_Gen_model.to(device)\n",
    "    embeddings = torch.tensor([]).to(device)  #用于存放最终生成的tokens embeddings\n",
    "    embedding_labels = torch.tensor([]).to(device)\n",
    "\n",
    "    for _, data in tqdm(enumerate(DIemb_datasets)):\n",
    "            \n",
    "        dir_samples = data[0].to(device)\n",
    "        labels = data[1].long().to(device)\n",
    "\n",
    "        z = torch.randn(batch_size,30,768).to(device)   #噪声为[batch_size, seq_len, embedding_size]形式输入到改动了embedding层后的teacher model\n",
    "\n",
    "        tokensemb_gens = torch.tensor([]).to(device)\n",
    "        emb_probs = torch.tensor([]).to(device)\n",
    "        losses = torch.tensor([]) #保存对应的损失\n",
    "        count = 0\n",
    "        loss_num = 999\n",
    "        while loss_num > error:  \n",
    "            \n",
    "            if max_iter == True and count>=300:  #是否设置最大迭代次数1200\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            probs, emb_gens = DIemb_Gen_model(z)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs / temper, dim=1), dir_samples) + 0.6*loss_func2(probs, labels)\n",
    "\n",
    "            loss_num = loss.item()\n",
    "            \n",
    "            loss.requires_grad_(True) #这里应该是因为如果将最后一层的模型参数梯度关闭，则计算出来的loss也没有梯度，不能追踪，所以要将loss的梯度设置为True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_num = loss.item()\n",
    "            count += 1\n",
    "            \n",
    "            if count%2==0:\n",
    "                tokensemb_gens = torch.cat([tokensemb_gens, emb_gens], dim=0)\n",
    "                emb_probs = torch.cat([emb_probs, probs], dim=0)\n",
    "                losses = torch.cat([losses, torch.tensor([loss_num])])\n",
    "                #print(loss_num)\n",
    "        #print('训练过程中teacher model的预测情况'+str(torch.argmax(probs)))\n",
    "            \n",
    "        if max_iter == True and len(tokensemb_gens) > 0:\n",
    "            num = torch.argmin(losses).item()\n",
    "            tokensemb_gen = tokensemb_gens[num*batch_size : (num+1)*batch_size]  #选择loss最小的\n",
    "            emb_probs_batch = emb_probs[num*batch_size : (num+1)*batch_size]\n",
    "        \n",
    "        embeddings = torch.cat([embeddings, tokensemb_gen], dim=0)\n",
    "        emb_label = torch.argmax(emb_probs_batch, dim=1)  #找到对应的标签\n",
    "        embedding_labels = torch.cat([embedding_labels, emb_label], dim=0)\n",
    "            \n",
    "    return embeddings.detach(), embedding_labels.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''用于生成DI_embedding数据印象的模型'''\n",
    "class DIemb_Gen_model(nn.Module):\n",
    "    def __init__(self, teacher_model, device):\n",
    "        super(DIemb_Gen_model,self).__init__()\n",
    "        self.device = device\n",
    "        self.fc1 = nn.Linear(768,1024)\n",
    "        self.fc2 = nn.Linear(1024,768)       #用于训练网络生成符合条件的噪声\n",
    "        \n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = False   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_classifier = nn.Sequential(teacher_model.dropout,\n",
    "                                                      teacher_model.fc)\n",
    "        for param in self.teacher_model_classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = torch.relu(out)\n",
    "        emb_gen = self.fc2(out)\n",
    "        self.teacher_model_encoder.eval()\n",
    "        self.teacher_model_remain.eval()\n",
    "        \n",
    "        out = self.teacher_model_encoder(emb_gen, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_classifier(pooled_output)   \n",
    "        \n",
    "        return probs, emb_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:09<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "'''生成并打包迪利克雷分布采样进入Dataloader中,并且定义模型和损失函数,优化器'''\n",
    "dir_samples = torch.tensor([])\n",
    "dir_labels = torch.tensor([])\n",
    "DIemb_num = 10000\n",
    "for i in tqdm(range(len(train_original_labels))):  #标签的idx刚好和train_original_labels的下标顺序对应\n",
    "\n",
    "    for k in [1,5]:  #每种β生成1/2的数据\n",
    "        m = Dirichlet(k*concent_params[i])  #采样每个类的数据\n",
    "        \n",
    "        for j in range(int(DIemb_num/len(train_original_labels)/2)):\n",
    "\n",
    "            x = m.sample().view(1,-1)\n",
    "\n",
    "            dir_samples = torch.cat([dir_samples, x], dim=0)\n",
    "            dir_labels = torch.cat([dir_labels,torch.tensor([i]).long()], dim=0)\n",
    "            \n",
    "dirsample_datasets = TensorDataset(dir_samples, dir_labels)\n",
    "dirsample_datasets = DataLoader(dirsample_datasets, batch_size=64, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "model = DIemb_Gen_model(teacher_model, 'cuda:0')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   \\nx = torch.randn(128,30,768)\\nteacher_model = teacher_model.to('cpu')\\nteacher_model_encoder = teacher_model.bert.encoder\\nout = teacher_model_encoder(x, attention_mask=torch.tensor([1]))[-1]\\nteacher_model_remain = nn.Sequential(      #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\\n                        teacher_model.bert.pooler,\\n                        teacher_model.dropout,\\n                        teacher_model.fc)    #除去teacher model的embedding层的剩余层\\nteacher_model_remain(out)\\n\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "student_model = Bert_student(MyModel_Config(train_original_labels))\n",
    "encoder_layer = student_model.bert.encoder       #独立拿出encoder层\n",
    "encoder_layer\n",
    "emb_layer = student_model.bert.embeddings        #独立拿出embedding层\n",
    "emb_layer\n",
    "x = torch.randn(128,30,300)\n",
    "x = torch.argmax(x, dim=2).long()                  #随机生成tokens\n",
    "x.shape\n",
    "tokens_embedding = emb_layer(x)                 #将input_ids(tokens)输入到embedding层\n",
    "tokens_embedding.shape\n",
    "m = encoder_layer(tokens_embedding, attention_mask=torch.tensor([1]))    #将tokens embedding和attention mask输入到encoder层中\n",
    "len(m)   #这里由于encoder输出的是所有encoder的hidden embedding， 所以要取最后一个encoder的hidden embeddidng\n",
    "m[3]\n",
    "'''\n",
    "\n",
    "'''   \n",
    "x = torch.randn(128,30,768)\n",
    "teacher_model = teacher_model.to('cpu')\n",
    "teacher_model_encoder = teacher_model.bert.encoder\n",
    "out = teacher_model_encoder(x, attention_mask=torch.tensor([1]))[-1]\n",
    "teacher_model_remain = nn.Sequential(      #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "                        teacher_model.bert.pooler,\n",
    "                        teacher_model.dropout,\n",
    "                        teacher_model.fc)    #除去teacher model的embedding层的剩余层\n",
    "teacher_model_remain(out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/414511434    bert encoder中输入两个，一个是tokens embeddding，另外一个是attention mask 如果为1代表要被attention，如果为0代表是padding的，要被mask掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "白菜，牙刷，奶瓶，草，玉米，稻草，钉耙，红卷，白团，火把，钳子，萝卜，木桩3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/root/deepo/LYL/anaconda/ls/envs/csuse/lib/python3.7/site-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "156it [1:30:36, 34.85s/it]\n"
     ]
    }
   ],
   "source": [
    "'''训练生成tokens embedding'''\n",
    "embeddings_gen, embedding_labels = train_DI_Embeddings_gen(model, dirsample_datasets, optimizer, loss_func, loss_func2)\n",
    "embedding_gen = embeddings_gen.to('cpu')\n",
    "embedding_labels = embedding_labels.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIemb_datasets = TensorDataset(embedding_gen, embedding_labels)   #这里不用detach接下来就不能训练\n",
    "DIemb_datasets = DataLoader(DIemb_datasets, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([])\n",
    "for i, data in enumerate(DIemb_datasets):\n",
    "    labels = torch.cat([labels, data[1]], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1426, 1: 1425, 2: 1427, 3: 1427, 4: 1427, 5: 1425, 6: 1427}\n"
     ]
    }
   ],
   "source": [
    "'''标签更加均衡'''\n",
    "label_idx = {}\n",
    "for i in range(len(train_original_labels)):\n",
    "    label_idx[i] = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label_idx[labels[i].item()] += 1\n",
    "print(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760542/760542 [20:51<00:00, 607.93it/s]\n"
     ]
    }
   ],
   "source": [
    "'''读取OOD的wiki103数据'''\n",
    "import os\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = _read_wiki('./wiki103')\n",
    "\n",
    "'''将读取的wiki数据tokenize'''\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-pretrained')\n",
    "tokens = []\n",
    "datas_size = len(paragraphs)\n",
    "for l in tqdm(range(datas_size)):\n",
    "    for k in range(len(paragraphs[l])):\n",
    "        text = paragraphs[l][k]\n",
    "        text = tokenizer.tokenize(text)\n",
    "        token = tokenizer.convert_tokens_to_ids(text)\n",
    "        tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_num = 1000\n",
    "ood_datas = []\n",
    "temp = [[] for i in range(len(tokens))] #这样防止temp和tokens地址相同\n",
    "for i in range(len(tokens)):\n",
    "    temp[i] = tokens[i]\n",
    "for i in range(ood_num):  #Bert最长读512最少读2长度的tokens,所以要处理\n",
    "    if len(temp[i]) <98 and len(temp[i])>2:\n",
    "        while len(temp[i])<100:\n",
    "            temp[i].append(0)  #padding到100\n",
    "        ood_datas.append(temp[i])\n",
    "        \n",
    "print(len(ood_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练一个转移模型，使得teacher model 768的embedding可以迁移到student model 不一样的embedding空间中'''\n",
    "'''embed_transfer_model:'''\n",
    "class embed_transfer_model(nn.Module):\n",
    "    def __init__(self, teahcer_dim, student_dim):\n",
    "        super(embed_transfer_model,self).__init__()\n",
    "        \n",
    "        self.teacher_dim = teahcer_dim\n",
    "        self.student_dim = student_dim\n",
    "\n",
    "        self.transfer_model = nn.Sequential(nn.Linear(self.teacher_dim, 1024), nn.Tanh(), nn.Linear(1024, self.student_dim))\n",
    "\n",
    "\n",
    "    def forward(self, tokens_embedding):\n",
    "        \n",
    "        out = self.transfer_model(tokens_embedding)\n",
    "        \n",
    "        return out \n",
    "\n",
    "\n",
    "def embed_transfer_train(teacher_embed_model, student_embed_model, transfer_model, ood_datas, optimizer, loss_func, temper=10):\n",
    "    device = 'cuda:0'\n",
    "    teacher_embed_model.eval()\n",
    "    student_embed_model.eval()\n",
    "    transfer_model.train()\n",
    "    teacher_embed_model = teacher_embed_model.to(device)\n",
    "    student_embed_model = student_embed_model.to(device)\n",
    "    transfer_model = transfer_model.to(device)\n",
    "\n",
    "    for i, data in enumerate(ood_datas):\n",
    "        ood_tokens = data[0].to(device)\n",
    "        with torch.no_grad:\n",
    "            teacher_embed = teacher_embed_model(ood_tokens)\n",
    "            student_embed = student_embed_model(ood_tokens)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        teacher_transfer = transfer_model(teacher_embed)\n",
    "        loss = loss_func(torch.log(teacher_transfer / temper, dim=1), student_embed / temper, dim=1)  #KL散度\n",
    "        \n",
    "        loss_num = loss.item() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''尝试2019DI的zero-shot蒸馏student模型的训练函数\n",
    "参数：\n",
    "teacher_model:被提取的模型\n",
    "student_model:要提取出的模型\n",
    "datas:DI生成的数据，用Dataloader封装\n",
    "optimizer:优化器，只优化student_model的参数\n",
    "loss_func:采用KL散度，或是MSE等保持teacher和student的softmax输出的相似性\n",
    "temper:KL散度的温度系数,不能设置太高，经过实验探究，设置到4左右效果最好\n",
    "'''\n",
    "def train_KD_student(teacher_model_embedding, teacher_model, student_model, datas, optimizer, loss_func, loss_func2, temper, epochs , train_original_datas, dev_original_datas, test_original_datas):\n",
    "    device = 'cuda:0'\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model_embedding = teacher_model_embedding.to(device)\n",
    "    teacher_model_embedding.eval()\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    losses = [] #存放所有样本一个epoch的损失\n",
    "    accuracies = []\n",
    "    \n",
    "    max_acc_fin = 0 #记录最终最大精度测试集组并输出\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#每一轮epoch学习率递减\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        max_acc_test = 0\n",
    "        '''对每个batch的训练'''\n",
    "        for idx, data in enumerate(datas):  #idx表示第几个batch，datas为[batch_size, tokens, label]的数据\n",
    "            student_model.train()\n",
    "            tokens_embedding = data[0].to(device)\n",
    "            #labels = data[1].to(device)\n",
    "        \n",
    "            optimizer.zero_grad() #新batch训练时将梯度归0，防止梯度累积\n",
    "            \n",
    "        \n",
    "            probs_teacher = teacher_model(tokens_embedding)\n",
    "            \n",
    "            probs_student = student_model(tokens_embedding)\n",
    "            \n",
    "            loss = loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1))\n",
    "            #loss = 0.8*loss_func(F.log_softmax(probs_student / temper, dim=1), F.softmax(probs_teacher / temper, dim=1)) + 0.2*loss_func2(probs_student, labels)\n",
    "            loss.backward(retain_graph=True)  #这里不用loss.requires_grad_(True)的原因是优化器优化的参数中间步骤不包括梯度不动的teacher_model\n",
    "            optimizer.step()\n",
    "            #scheduler.step()#学习率递减\n",
    "            print(loss.item())\n",
    "            \n",
    "            student_model.eval()\n",
    "            accuracy_test, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, test_original_datas, loss_func2)\n",
    "            \n",
    "            if max_acc_test<accuracy_test:\n",
    "                max_acc_test = accuracy_test\n",
    "                accuracy_train, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, train_original_datas, loss_func2)\n",
    "                accuracy_dev, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model_embedding, student_model, dev_original_datas, loss_func2)\n",
    "        \n",
    "        print('训练集精度'+str(accuracy_train))\n",
    "        print('验证集精度'+str(accuracy_dev))\n",
    "        print('测试集精度'+str(max_acc_test))\n",
    "        \n",
    "        if max_acc_fin<max_acc_test:\n",
    "            max_acc_fin = max_acc_test\n",
    "            accuracy_train_fin = accuracy_train\n",
    "            accuracy_dev_fin = accuracy_dev\n",
    "\n",
    "        student_model.train()\n",
    "    \n",
    "    print('训练集最终精度'+str(accuracy_train_fin))\n",
    "    print('验证集最终精度'+str(accuracy_dev_fin))\n",
    "    print('测试集最终精度'+str(max_acc_fin))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义用于蒸馏的模型'''\n",
    "class Teachermodel_revise(nn.Module):\n",
    "    def __init__(self,teacher_model, device):\n",
    "        super(Teachermodel_revise,self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.teacher_model_encoder = teacher_model.bert.encoder\n",
    "        for param in self.teacher_model_encoder.parameters():    \n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.teacher_model_remain = teacher_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.teacher_model_remain.parameters():    \n",
    "            param.requires_grad = False   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.teacher_model_classifier = nn.Sequential(teacher_model.dropout,\n",
    "                                                      teacher_model.fc)\n",
    "        for param in self.teacher_model_classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, tokens_embedding):\n",
    "        \n",
    "        out = self.teacher_model_encoder(tokens_embedding, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.teacher_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.teacher_model_classifier(pooled_output) \n",
    "        \n",
    "        return probs\n",
    "\n",
    "\n",
    "\n",
    "'''student模型'''\n",
    "class Studentmodel_revise(nn.Module):\n",
    "    def __init__(self,student_model, device, teacher_dim=768, student_dim=768):\n",
    "        super(Studentmodel_revise,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        #self.fc1 = nn.Linear(teacher_dim, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, student_dim)\n",
    "\n",
    "        self.student_model_encoder = student_model.bert.encoder\n",
    "        for param in self.student_model_encoder.parameters():    \n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.student_model_remain = student_model.bert.pooler   #这里由于nn.Sequential只能接收单独输入，所以encoder需要两个输入[embedding, attention_mask]，但是sequential不能接受两个收入，就会报错\n",
    "\n",
    "        for param in self.student_model_remain.parameters():    \n",
    "            param.requires_grad = True   #冻结teahcer model所有剩余层的参数，不进行梯度更新\n",
    "\n",
    "        self.student_model_classifier = nn.Sequential(student_model.dropout,\n",
    "                                                      student_model.fc)\n",
    "        for param in self.student_model_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, tokens_embedding):\n",
    "        #out = self.fc1(tokens_embedding)\n",
    "        #out = torch.tanh(out)\n",
    "        #out = self.fc2(out)\n",
    "        \n",
    "        out = self.student_model_encoder(tokens_embedding, attention_mask=torch.tensor([1]).to(self.device)) #输入(batch_size, seq_len, embedding_size)的tokens embedding, 输出(batch_size, num_classes)的out\n",
    "        pooled_output = self.student_model_remain(out[-1])  #out[-1]代表最后一个encoder的输出,pooler层直接输出[CLS]的\n",
    "\n",
    "        probs = self.student_model_classifier(pooled_output)\n",
    "        \n",
    "        return probs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************\n",
      "0.13158700980392157\n",
      "0.0875\n",
      "0.1296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002294621430337429\n",
      "0.002808165503665805\n",
      "0.002870903117582202\n",
      "0.002098435303196311\n",
      "0.002165778772905469\n",
      "0.0021121411118656397\n",
      "0.0022091157734394073\n",
      "0.0018576157744973898\n",
      "0.0022950307466089725\n",
      "0.0020886436104774475\n",
      "0.0019181030802428722\n",
      "0.0019883806817233562\n",
      "0.00207287329249084\n",
      "0.0020598950795829296\n",
      "0.002165283542126417\n",
      "0.002098425757139921\n",
      "0.0019108945271000266\n",
      "0.001903923461213708\n",
      "0.0019100733334198594\n",
      "0.001956008840352297\n",
      "0.002020773943513632\n",
      "0.001951635000295937\n",
      "0.0019583450630307198\n",
      "0.0020010333973914385\n",
      "0.0018514749826863408\n",
      "0.0018320586532354355\n",
      "0.0018370221368968487\n",
      "0.0018354826606810093\n",
      "0.0020877078641206026\n",
      "0.0019262188579887152\n",
      "0.0018451432697474957\n",
      "0.0018345972057431936\n",
      "0.002025244291871786\n",
      "0.0020315994042903185\n",
      "0.0020125540904700756\n",
      "0.00203130510635674\n",
      "0.0018896075198426843\n",
      "0.0020646832417696714\n",
      "0.0019405055791139603\n",
      "0.0019253381760790944\n",
      "0.0020511855836957693\n",
      "0.0017814559396356344\n",
      "0.002005176618695259\n",
      "0.0019408114021643996\n",
      "0.0019182052928954363\n",
      "0.0019741165451705456\n",
      "0.0020568298641592264\n",
      "0.0019211561884731054\n",
      "0.0020320527255535126\n",
      "0.0018811628688126802\n",
      "0.001997819170355797\n",
      "0.0018599028699100018\n",
      "0.0019256800878793001\n",
      "0.0019033716525882483\n",
      "0.0019246941665187478\n",
      "0.0019550465513020754\n",
      "0.0018361476249992847\n",
      "0.0018581803888082504\n",
      "0.0018629947444424033\n",
      "0.0018368321470916271\n",
      "0.002034117467701435\n",
      "0.001933199935592711\n",
      "0.0018650214187800884\n",
      "0.0020154020749032497\n",
      "0.001772229210473597\n",
      "0.001845657592639327\n",
      "0.001913909218274057\n",
      "0.0018989728996530175\n",
      "0.001831953413784504\n",
      "0.0018861127318814397\n",
      "0.0019346876069903374\n",
      "0.001887349528260529\n",
      "0.0019467598758637905\n",
      "0.002021923428401351\n",
      "0.0019544195383787155\n",
      "0.001853369758464396\n",
      "0.0019488545367494226\n",
      "0.0019761635921895504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:45<1:20:07, 165.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.16329656862745098\n",
      "验证集精度0.171875\n",
      "测试集精度0.2078125\n",
      "0.0017733026761561632\n",
      "0.0018669422715902328\n",
      "0.001969577744603157\n",
      "0.0020070234313607216\n",
      "0.0020132928621023893\n",
      "0.0018711220473051071\n",
      "0.0018772059120237827\n",
      "0.0020095028448849916\n",
      "0.0018238931661471725\n",
      "0.001969842240214348\n",
      "0.002037785016000271\n",
      "0.001973749604076147\n",
      "0.0019962317310273647\n",
      "0.0018047218909487128\n",
      "0.0019160137744620442\n",
      "0.0017365956446155906\n",
      "0.0019035276491194963\n",
      "0.0019244584254920483\n",
      "0.0019075700547546148\n",
      "0.0019201717805117369\n",
      "0.0018604137003421783\n",
      "0.0020225399639457464\n",
      "0.0019929588306695223\n",
      "0.0021077138371765614\n",
      "0.0019443219061940908\n",
      "0.0017672536196187139\n",
      "0.0018568385858088732\n",
      "0.0019071848364546895\n",
      "0.0018199286423623562\n",
      "0.001855402602814138\n",
      "0.0019441628828644753\n",
      "0.00179872487206012\n",
      "0.0019375188276171684\n",
      "0.001903755939565599\n",
      "0.0021339692175388336\n",
      "0.0022152678575366735\n",
      "0.0021225910168141127\n",
      "0.0019161710515618324\n",
      "0.0017983305733650923\n",
      "0.0018378039821982384\n",
      "0.002024900633841753\n",
      "0.001998571213334799\n",
      "0.0017876715864986181\n",
      "0.0018806566949933767\n",
      "0.0018397108651697636\n",
      "0.0018981907051056623\n",
      "0.002039233921095729\n",
      "0.0020597074180841446\n",
      "0.0019085503881797194\n",
      "0.0019723146688193083\n",
      "0.0019032714189961553\n",
      "0.0018703988753259182\n",
      "0.0017698316369205713\n",
      "0.0018363820854574442\n",
      "0.0019684238359332085\n",
      "0.0019530542194843292\n",
      "0.0018042471492663026\n",
      "0.0018701665103435516\n",
      "0.0017507884185761213\n",
      "0.0018515882547944784\n",
      "0.001941870548762381\n",
      "0.001998980762436986\n",
      "0.0019641623366624117\n",
      "0.0019790816586464643\n",
      "0.001947876182384789\n",
      "0.0020541558042168617\n",
      "0.0018493874231353402\n",
      "0.0017204132163897157\n",
      "0.0018174933502450585\n",
      "0.00185915466863662\n",
      "0.0018938627326861024\n",
      "0.0019108600681647658\n",
      "0.0018599391914904118\n",
      "0.0018849624320864677\n",
      "0.0018375718500465155\n",
      "0.0019180532544851303\n",
      "0.001782888313755393\n",
      "0.0018799568060785532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [05:31<1:17:28, 166.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1439185049019608\n",
      "验证集精度0.1859375\n",
      "测试集精度0.184375\n",
      "0.0018918715650215745\n",
      "0.001880937721580267\n",
      "0.0019231644691899419\n",
      "0.0018856918904930353\n",
      "0.001895815716125071\n",
      "0.0019286706810817122\n",
      "0.0019905788358300924\n",
      "0.0019349521026015282\n",
      "0.0019004401983693242\n",
      "0.0018755319761112332\n",
      "0.002048221416771412\n",
      "0.0018943124450743198\n",
      "0.0020418930798768997\n",
      "0.0019529301207512617\n",
      "0.0018503624014556408\n",
      "0.0019852733239531517\n",
      "0.0019042756175622344\n",
      "0.0017532951897010207\n",
      "0.0018067078199237585\n",
      "0.0017339218175038695\n",
      "0.0018995838472619653\n",
      "0.0016857102746143937\n",
      "0.0017643095925450325\n",
      "0.0018585803918540478\n",
      "0.0017578924307599664\n",
      "0.0017351293936371803\n",
      "0.00180816522333771\n",
      "0.0017493461491540074\n",
      "0.0020025039557367563\n",
      "0.001912154839374125\n",
      "0.0019047645619139075\n",
      "0.0016592764295637608\n",
      "0.0017660250887274742\n",
      "0.0017955207731574774\n",
      "0.0017518908716738224\n",
      "0.0017102786805480719\n",
      "0.0017935959622263908\n",
      "0.0016563126118853688\n",
      "0.0018706006230786443\n",
      "0.0017025736160576344\n",
      "0.0017104740254580975\n",
      "0.001758192665874958\n",
      "0.0017310850089415908\n",
      "0.0019268138566985726\n",
      "0.0016729111084714532\n",
      "0.0017133003566414118\n",
      "0.0016696139937266707\n",
      "0.001556491362862289\n",
      "0.001778198522515595\n",
      "0.0017075134674087167\n",
      "0.0016966790426522493\n",
      "0.0016227051382884383\n",
      "0.001444190857000649\n",
      "0.0016308174235746264\n",
      "0.0016216133954003453\n",
      "0.0016084664966911077\n",
      "0.0017897149082273245\n",
      "0.001823008176870644\n",
      "0.0015308753354474902\n",
      "0.0016317191766574979\n",
      "0.0015370255568996072\n",
      "0.0016331879887729883\n",
      "0.0016935275634750724\n",
      "0.0017664491897448897\n",
      "0.0015266772825270891\n",
      "0.0015570357209071517\n",
      "0.0015200661728158593\n",
      "0.00158959929831326\n",
      "0.0014367230469360948\n",
      "0.0014707824448123574\n",
      "0.0015136238653212786\n",
      "0.0014995845267549157\n",
      "0.0014097539242357016\n",
      "0.001577774528414011\n",
      "0.0015563271008431911\n",
      "0.001482530147768557\n",
      "0.0014885019045323133\n",
      "0.0013658074894919991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [07:53<1:09:39, 154.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.13779105392156862\n",
      "验证集精度0.1625\n",
      "测试集精度0.196875\n",
      "0.001446288195438683\n",
      "0.0016463104402646422\n",
      "0.001551675726659596\n",
      "0.0016006085788831115\n",
      "0.0014923937851563096\n",
      "0.0014153897063806653\n",
      "0.001269833417609334\n",
      "0.0015237047336995602\n",
      "0.0016365132760256529\n",
      "0.0013954085297882557\n",
      "0.0013048435794189572\n",
      "0.0013494750019162893\n",
      "0.0013895538868382573\n",
      "0.001278470503166318\n",
      "0.0014052543556317687\n",
      "0.0013690799241885543\n",
      "0.0013813868863508105\n",
      "0.0014764119405299425\n",
      "0.0013775437837466598\n",
      "0.0014538938412442803\n",
      "0.001247693202458322\n",
      "0.001260683755390346\n",
      "0.0014172637602314353\n",
      "0.0014678628649562597\n",
      "0.0014183646999299526\n",
      "0.0013543289387598634\n",
      "0.0013921144418418407\n",
      "0.0014576518442481756\n",
      "0.0013192907208576798\n",
      "0.0016173651674762368\n",
      "0.0011716721346601844\n",
      "0.0012273311149328947\n",
      "0.001244699233211577\n",
      "0.0012524561025202274\n",
      "0.0013357859570533037\n",
      "0.0012277463683858514\n",
      "0.0012187676038593054\n",
      "0.001401017652824521\n",
      "0.001296331873163581\n",
      "0.0011965582380071282\n",
      "0.0011574685340747237\n",
      "0.00104482751339674\n",
      "0.001097333151847124\n",
      "0.0013578429352492094\n",
      "0.0012293764157220721\n",
      "0.0011568436166271567\n",
      "0.001217637094669044\n",
      "0.0011580234859138727\n",
      "0.0010895278537645936\n",
      "0.0013339200522750616\n",
      "0.001219170750118792\n",
      "0.001182568958029151\n",
      "0.0012841983698308468\n",
      "0.001583597855642438\n",
      "0.0013317310949787498\n",
      "0.0013551332522183657\n",
      "0.0014948236057534814\n",
      "0.0013106779661029577\n",
      "0.0014021386159583926\n",
      "0.00182403065264225\n",
      "0.0013326454209163785\n",
      "0.0013416508445516229\n",
      "0.0011671851389110088\n",
      "0.0011765611125156283\n",
      "0.0012847427278757095\n",
      "0.0012314629275351763\n",
      "0.0012468048371374607\n",
      "0.001281603006646037\n",
      "0.0014156330144032836\n",
      "0.0012358048697933555\n",
      "0.001186948618851602\n",
      "0.00139432807918638\n",
      "0.0012265960685908794\n",
      "0.0012378733372315764\n",
      "0.0012550471583381295\n",
      "0.0011101244017481804\n",
      "0.0011165922041982412\n",
      "0.001168099115602672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [11:16<1:15:21, 173.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.15701593137254902\n",
      "验证集精度0.1671875\n",
      "测试集精度0.20625\n",
      "0.0012154605938121676\n",
      "0.0012186935637146235\n",
      "0.0011517084203660488\n",
      "0.001116138300858438\n",
      "0.0012358069652691483\n",
      "0.001111461198888719\n",
      "0.0012083592591807246\n",
      "0.0011232581455260515\n",
      "0.0012365819420665503\n",
      "0.0010819616727530956\n",
      "0.0011834038887172937\n",
      "0.0010393911506980658\n",
      "0.001118500018492341\n",
      "0.0010705443564802408\n",
      "0.0011258736485615373\n",
      "0.0010336304549127817\n",
      "0.0010952440788969398\n",
      "0.0010578513611108065\n",
      "0.001103477436117828\n",
      "0.0011192484525963664\n",
      "0.0010855172295123339\n",
      "0.0011255699209868908\n",
      "0.0011041630059480667\n",
      "0.001002684235572815\n",
      "0.0010958969360217452\n",
      "0.0010390086099505424\n",
      "0.0010179274249821901\n",
      "0.0010998909128829837\n",
      "0.0009988321689888835\n",
      "0.0009643342928029597\n",
      "0.001101235393434763\n",
      "0.0010597897926345468\n",
      "0.000945794046856463\n",
      "0.0009991794358938932\n",
      "0.0009637438342906535\n",
      "0.0009925145423039794\n",
      "0.001173820928670466\n",
      "0.0010806317441165447\n",
      "0.0010490658460184932\n",
      "0.001037373673170805\n",
      "0.0009336874936707318\n",
      "0.00094683060888201\n",
      "0.0010079240892082453\n",
      "0.0009169540135189891\n",
      "0.000937249802518636\n",
      "0.000952047819737345\n",
      "0.00103502138517797\n",
      "0.0010042060166597366\n",
      "0.0014311147388070822\n",
      "0.0011971424100920558\n",
      "0.0010076714679598808\n",
      "0.0012813482899218798\n",
      "0.0012705684639513493\n",
      "0.001365359639748931\n",
      "0.0013028349494561553\n",
      "0.0012444730382412672\n",
      "0.0015307854628190398\n",
      "0.0014998323749750853\n",
      "0.0014492409536615014\n",
      "0.0014730623224750161\n",
      "0.0013110568979755044\n",
      "0.0013951933942735195\n",
      "0.001439844723790884\n",
      "0.0015315457712858915\n",
      "0.0013352057430893183\n",
      "0.0014869499718770385\n",
      "0.0014182880986481905\n",
      "0.0012763707200065255\n",
      "0.0013140594819560647\n",
      "0.0012772207846865058\n",
      "0.0012729987502098083\n",
      "0.001367936609312892\n",
      "0.0012605460360646248\n",
      "0.0012317164801061153\n",
      "0.0011727850651368499\n",
      "0.001348211895674467\n",
      "0.001177863567136228\n",
      "0.0011653895489871502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [13:01<1:02:03, 148.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.17356004901960784\n",
      "验证集精度0.1703125\n",
      "测试集精度0.2125\n",
      "0.001282883225940168\n",
      "0.0011008577421307564\n",
      "0.0011274100979790092\n",
      "0.0011701320763677359\n",
      "0.0010604881681501865\n",
      "0.0010417546145617962\n",
      "0.0012465867912396789\n",
      "0.0010937668848782778\n",
      "0.001418998814187944\n",
      "0.001045816927216947\n",
      "0.0012643765658140182\n",
      "0.0011926868464797735\n",
      "0.001218040706589818\n",
      "0.0012307654833421111\n",
      "0.001224543317221105\n",
      "0.001092276070266962\n",
      "0.0010180401150137186\n",
      "0.0010327397612854838\n",
      "0.0010315293911844492\n",
      "0.001083363313227892\n",
      "0.0010195294162258506\n",
      "0.0008356759790331125\n",
      "0.0008574646199122071\n",
      "0.000892427284270525\n",
      "0.0008504421566613019\n",
      "0.000852047058288008\n",
      "0.0009197610197588801\n",
      "0.0007351038511842489\n",
      "0.0007396478904411197\n",
      "0.0008512248168699443\n",
      "0.0007144231931306422\n",
      "0.000767124758567661\n",
      "0.0006636602338403463\n",
      "0.000731556152459234\n",
      "0.0006682549719698727\n",
      "0.000655900570563972\n",
      "0.0005845615523867309\n",
      "0.0006527715013362467\n",
      "0.0008612496312707663\n",
      "0.00050843704957515\n",
      "0.0005945175071246922\n",
      "0.0006677551427856088\n",
      "0.0005667372024618089\n",
      "0.0006176171591505408\n",
      "0.0005193089018575847\n",
      "0.0007046027458272874\n",
      "0.0004935828619636595\n",
      "0.0007319003925658762\n",
      "0.0004895279998891056\n",
      "0.0005635523702949286\n",
      "0.0013013235293328762\n",
      "0.0013066917890682817\n",
      "0.0010192934423685074\n",
      "0.0009272565366700292\n",
      "0.0011107976315543056\n",
      "0.0011783030349761248\n",
      "0.0012856151442974806\n",
      "0.0012498123105615377\n",
      "0.0011165512260049582\n",
      "0.001331843202933669\n",
      "0.0012265641707926989\n",
      "0.001048852689564228\n",
      "0.0013183284318074584\n",
      "0.0010939212515950203\n",
      "0.0011175473919138312\n",
      "0.0011442929971963167\n",
      "0.001066079130396247\n",
      "0.0010380883468315005\n",
      "0.0011057605734094977\n",
      "0.001131178461946547\n",
      "0.0010579132940620184\n",
      "0.0010963473469018936\n",
      "0.001011100597679615\n",
      "0.0008855160558596253\n",
      "0.0011043134145438671\n",
      "0.0011341676581650972\n",
      "0.0010321182198822498\n",
      "0.001003370271064341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [16:12<1:05:18, 163.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.21629901960784315\n",
      "验证集精度0.1921875\n",
      "测试集精度0.24375\n",
      "0.0009119900641962886\n",
      "0.0008152876398526132\n",
      "0.0009137296001426876\n",
      "0.0009337699739262462\n",
      "0.0009647951228544116\n",
      "0.0010231040650978684\n",
      "0.0008332409197464585\n",
      "0.0008825838449411094\n",
      "0.000944800500292331\n",
      "0.0007725100149400532\n",
      "0.0007950359140522778\n",
      "0.0011940737022086978\n",
      "0.0008162993472069502\n",
      "0.0010358612053096294\n",
      "0.0008613436948508024\n",
      "0.0009154125582426786\n",
      "0.0007967472774907947\n",
      "0.0008410823647864163\n",
      "0.0006981976912356913\n",
      "0.001081431983038783\n",
      "0.0008195140981115401\n",
      "0.0010744375176727772\n",
      "0.0008546665194444358\n",
      "0.0009681942756287754\n",
      "0.0009393498185090721\n",
      "0.0009389833430759609\n",
      "0.0009352655615657568\n",
      "0.0008312473655678332\n",
      "0.000919892976526171\n",
      "0.0007587431464344263\n",
      "0.00075082469265908\n",
      "0.000810333585832268\n",
      "0.0008611303055658937\n",
      "0.0009518400765955448\n",
      "0.0006897628190927207\n",
      "0.0009925843914970756\n",
      "0.0008282179478555918\n",
      "0.000869253184646368\n",
      "0.000869081704877317\n",
      "0.0008148669730871916\n",
      "0.0007947507547214627\n",
      "0.00066104851430282\n",
      "0.0007672972860746086\n",
      "0.0006058794679120183\n",
      "0.000767877500038594\n",
      "0.000829333730507642\n",
      "0.0007752070087008178\n",
      "0.0008213195251300931\n",
      "0.0007906919927336276\n",
      "0.0006898833671584725\n",
      "0.0006194472662173212\n",
      "0.0007230051560327411\n",
      "0.0007241801940836012\n",
      "0.0008078162209130824\n",
      "0.000807408825494349\n",
      "0.0007126425625756383\n",
      "0.0006377838435582817\n",
      "0.0006215246394276619\n",
      "0.000798645953182131\n",
      "0.0007160844979807734\n",
      "0.0008481122204102576\n",
      "0.0006298357038758695\n",
      "0.0007453832076862454\n",
      "0.0007337652496062219\n",
      "0.0007161264074966311\n",
      "0.0007147497963160276\n",
      "0.0006054515251889825\n",
      "0.0008285432704724371\n",
      "0.0005757894250564277\n",
      "0.0006066230125725269\n",
      "0.0004895806778222322\n",
      "0.0006383855943568051\n",
      "0.0006130828987807035\n",
      "0.0006385866436176002\n",
      "0.000612499366980046\n",
      "0.0004780690942425281\n",
      "0.0005796807818114758\n",
      "0.0005578139680437744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [17:57<55:14, 144.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.20212928921568626\n",
      "验证集精度0.23125\n",
      "测试集精度0.234375\n",
      "0.0004927662666887045\n",
      "0.0005274752038531005\n",
      "0.0006473188404925168\n",
      "0.000517668086104095\n",
      "0.000504783820360899\n",
      "0.0005574742099270225\n",
      "0.0005493341013789177\n",
      "0.0006170346168801188\n",
      "0.00044939230429008603\n",
      "0.0005861280951648951\n",
      "0.00045817840145900846\n",
      "0.0004952791496179998\n",
      "0.0004890032578259706\n",
      "0.0005021779797971249\n",
      "0.0004731588123831898\n",
      "0.0004652633797377348\n",
      "0.0005173195386305451\n",
      "0.0004059686616528779\n",
      "0.0005211313255131245\n",
      "0.0005059869727119803\n",
      "0.00042631797259673476\n",
      "0.00042770971776917577\n",
      "0.0003861218865495175\n",
      "0.0004649858456104994\n",
      "0.00041155601502396166\n",
      "0.0004081567167304456\n",
      "0.0004459229239728302\n",
      "0.0003945523640140891\n",
      "0.0003731662000063807\n",
      "0.00038730056257918477\n",
      "0.00027518533170223236\n",
      "0.00025834765983745456\n",
      "0.00043864676263183355\n",
      "0.0003147268434986472\n",
      "0.0003728846204467118\n",
      "0.00042770113213919103\n",
      "0.0003542824415490031\n",
      "0.00032383232610300183\n",
      "0.00028665681020356715\n",
      "0.0003337949456181377\n",
      "0.00039707898395136\n",
      "0.00033504757448099554\n",
      "0.00038484501419588923\n",
      "0.0003321217081975192\n",
      "0.0002807231794577092\n",
      "0.00028813787503167987\n",
      "0.00026383274234831333\n",
      "0.0002550201606936753\n",
      "0.00031906733056530356\n",
      "0.00030688894912600517\n",
      "0.0002540468121878803\n",
      "0.00032943449332378805\n",
      "0.00038538960507139564\n",
      "0.0002530836791265756\n",
      "0.0003013801760971546\n",
      "0.0002938950201496482\n",
      "0.0003458163409959525\n",
      "0.0002865171409212053\n",
      "0.00033765757689252496\n",
      "0.00031795407994650304\n",
      "0.00031279813265427947\n",
      "0.00033095901017077267\n",
      "0.00028456663130782545\n",
      "0.0002157553390134126\n",
      "0.0003052313404623419\n",
      "0.00032105177524499595\n",
      "0.00033871334744617343\n",
      "0.00026056705974042416\n",
      "0.00028232313343323767\n",
      "0.0002663292398210615\n",
      "0.0002266734081786126\n",
      "0.0002233256964245811\n",
      "0.0002967675682157278\n",
      "0.00031462215702049434\n",
      "0.0003650035650935024\n",
      "0.00029877183260396123\n",
      "0.000311538198729977\n",
      "0.0003436364349909127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [20:18<52:32, 143.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.18857230392156862\n",
      "验证集精度0.2140625\n",
      "测试集精度0.23125\n",
      "0.00022460143372882158\n",
      "0.00031907466473057866\n",
      "0.0002732329594437033\n",
      "0.0002914424694608897\n",
      "0.00029396318132057786\n",
      "0.00021067664783913642\n",
      "0.000281160871963948\n",
      "0.00026427439297549427\n",
      "0.00031083953217603266\n",
      "0.00032433393062092364\n",
      "0.00021153470152057707\n",
      "0.0002471313055139035\n",
      "0.00021681726502720267\n",
      "0.00021902445587329566\n",
      "0.000192089777556248\n",
      "0.00018576107686385512\n",
      "0.00018424565496388823\n",
      "0.0002090214256895706\n",
      "0.00021900671708863229\n",
      "0.0002038156962953508\n",
      "0.00029034740873612463\n",
      "0.00027229636907577515\n",
      "0.00021988950902596116\n",
      "0.00035376063897274435\n",
      "0.00026642423472367227\n",
      "0.0003198513004463166\n",
      "0.0003130611148662865\n",
      "0.0002856044447980821\n",
      "0.0002610893570818007\n",
      "0.00026971808983944356\n",
      "0.00027871952624991536\n",
      "0.0001964166876859963\n",
      "0.0002082411083392799\n",
      "0.000255167338764295\n",
      "0.00023244433396030217\n",
      "0.0002257714804727584\n",
      "0.0002525114978197962\n",
      "0.00028283928986638784\n",
      "0.00025460703182034194\n",
      "0.00030866623274050653\n",
      "0.0003131808480247855\n",
      "0.00021749420557171106\n",
      "0.00036070653004571795\n",
      "0.00021531737002078444\n",
      "0.0002258528838865459\n",
      "0.0002195418783230707\n",
      "0.0002234678395325318\n",
      "0.00020166348258499056\n",
      "0.00024729548022150993\n",
      "0.00017287427908740938\n",
      "0.00020307399972807616\n",
      "0.00026702313334681094\n",
      "0.00017575202218722552\n",
      "0.000227484037168324\n",
      "0.00020701867470052093\n",
      "0.00022628268925473094\n",
      "0.00024265205138362944\n",
      "0.00024035893147811294\n",
      "0.00024959444999694824\n",
      "0.00019560348300728947\n",
      "0.00019812512618955225\n",
      "0.00022581139637622982\n",
      "0.00018868396000470966\n",
      "0.0002316298196092248\n",
      "0.00019229916506446898\n",
      "0.0001489627902628854\n",
      "0.00019264683942310512\n",
      "0.00024940870935097337\n",
      "0.00018678922788240016\n",
      "0.0002068302856059745\n",
      "0.0002123031299561262\n",
      "0.00015452584193553776\n",
      "0.0001819278550101444\n",
      "0.0001859820040408522\n",
      "0.00021666525572072715\n",
      "0.00020966694864910096\n",
      "0.00017899928207043558\n",
      "0.00022874520800542086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [23:29<55:21, 158.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.19921875\n",
      "验证集精度0.225\n",
      "测试集精度0.215625\n",
      "0.0001783807238098234\n",
      "0.00021075726544950157\n",
      "0.00016895290173124522\n",
      "0.00017383319209329784\n",
      "0.00018663881928659976\n",
      "0.0002598766586743295\n",
      "0.0001743671455187723\n",
      "0.0001475725875934586\n",
      "0.0002248748205602169\n",
      "0.0003070879029110074\n",
      "0.00021506991470232606\n",
      "0.00019592819444369525\n",
      "0.00019789602083619684\n",
      "0.00020890029554720968\n",
      "0.00018911603547167033\n",
      "0.00013752076483797282\n",
      "0.0001398178283125162\n",
      "0.00021840163390152156\n",
      "0.0002661800244823098\n",
      "0.0002929530164692551\n",
      "0.00019133355817757547\n",
      "0.00024837348610162735\n",
      "0.00019381397578399628\n",
      "0.0004011283745057881\n",
      "0.00024553362163715065\n",
      "0.00026770291151478887\n",
      "0.0003207478148397058\n",
      "0.00039892824133858085\n",
      "0.00022054243891034275\n",
      "0.00026195927057415247\n",
      "0.0002286514063598588\n",
      "0.00022060811170376837\n",
      "0.00018043261661659926\n",
      "0.000197386703803204\n",
      "0.0002748895494733006\n",
      "0.00027075520483776927\n",
      "0.0002347426925553009\n",
      "0.000294232479063794\n",
      "0.0003079442249145359\n",
      "0.00022516836179420352\n",
      "0.00022466636437457055\n",
      "0.00023087274166755378\n",
      "0.00019260862609371543\n",
      "0.00020152000070083886\n",
      "0.0002003992849495262\n",
      "0.0001802987972041592\n",
      "0.0002084917650790885\n",
      "0.00021295889746397734\n",
      "0.00019786851771641523\n",
      "0.00021514121908694506\n",
      "0.0002433532354189083\n",
      "0.00017914330237545073\n",
      "0.0002068453177344054\n",
      "0.0001846378727350384\n",
      "0.0002156890695914626\n",
      "0.00021053191449027508\n",
      "0.00017533492064103484\n",
      "0.00023421227524522692\n",
      "0.00015626133244950324\n",
      "0.00014437954814638942\n",
      "0.00016527734987903386\n",
      "0.00016809433873277158\n",
      "0.00016718365077394992\n",
      "0.0002368047134950757\n",
      "0.00020072456391062587\n",
      "0.00015474570682272315\n",
      "0.00017161569849122316\n",
      "0.00021280496730469167\n",
      "0.0001383305061608553\n",
      "0.00017402607772964984\n",
      "0.00019527394033502787\n",
      "0.00015387358143925667\n",
      "0.00013450034020934254\n",
      "0.00015570278628729284\n",
      "0.00017423837562091649\n",
      "0.00015522446483373642\n",
      "0.0001473425218136981\n",
      "0.00018175324657931924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [26:03<52:16, 156.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.15762867647058823\n",
      "验证集精度0.19375\n",
      "测试集精度0.1796875\n",
      "0.00014359477791003883\n",
      "0.00016929082630667835\n",
      "0.0001878920738818124\n",
      "0.00014987342001404613\n",
      "0.00016845707432366908\n",
      "0.00013157377543393523\n",
      "0.00014361242938321084\n",
      "0.00017335769371129572\n",
      "0.00013384765770751983\n",
      "0.00014881497190799564\n",
      "0.0001319764123763889\n",
      "0.0001584625570103526\n",
      "0.00012056573905283585\n",
      "0.00015659761265851557\n",
      "0.00013109894644003361\n",
      "0.00017943154671229422\n",
      "9.652198787080124e-05\n",
      "0.00012746242282446474\n",
      "0.00013241948909126222\n",
      "0.0001350013044429943\n",
      "0.0001345086348010227\n",
      "0.0001298913557548076\n",
      "0.00015290791634470224\n",
      "9.893217065837234e-05\n",
      "0.00012770963076036423\n",
      "0.00016863862401805818\n",
      "0.00011778240877902135\n",
      "0.00012876495020464063\n",
      "0.00013459452020470053\n",
      "9.477252751821652e-05\n",
      "0.00011242263281019405\n",
      "0.00015886833716649562\n",
      "0.00016099019558168948\n",
      "0.00014063909475225955\n",
      "0.00013581151142716408\n",
      "0.00012946681817993522\n",
      "0.00014215164992492646\n",
      "0.000142903154483065\n",
      "0.00013173405022826046\n",
      "0.00014097889652475715\n",
      "0.00022172252647578716\n",
      "0.0008014953345991671\n",
      "0.0013460975605994463\n",
      "0.0008170655346475542\n",
      "0.0006158406031318009\n",
      "0.0007573200855404139\n",
      "0.0008851993479765952\n",
      "0.0006395833916030824\n",
      "0.0009718701476231217\n",
      "0.0006204371456988156\n",
      "0.0006499552982859313\n",
      "0.0006153662106953561\n",
      "0.000641465827357024\n",
      "0.0006590933189727366\n",
      "0.0007991885649971664\n",
      "0.0005665509379468858\n",
      "0.0005933617358095944\n",
      "0.0006915511912666261\n",
      "0.0005783618544228375\n",
      "0.0007157592917792499\n",
      "0.00048471882473677397\n",
      "0.0005542817525565624\n",
      "0.00045155565021559596\n",
      "0.00042879109969362617\n",
      "0.00043805132736451924\n",
      "0.000569030933547765\n",
      "0.0005665668286383152\n",
      "0.0005360186914913356\n",
      "0.0005496065132319927\n",
      "0.0006481075542978942\n",
      "0.0006436614203266799\n",
      "0.0006119016325101256\n",
      "0.0006127452943474054\n",
      "0.00048727207467891276\n",
      "0.000551636447198689\n",
      "0.0006445718463510275\n",
      "0.0006001513684168458\n",
      "0.0004966034321114421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [29:14<52:57, 167.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14008884803921567\n",
      "验证集精度0.1625\n",
      "测试集精度0.1953125\n",
      "0.00048058415995910764\n",
      "0.00036857917439192533\n",
      "0.00048082941793836653\n",
      "0.0005013636546209455\n",
      "0.0005983831360936165\n",
      "0.00044360433821566403\n",
      "0.0003427778137847781\n",
      "0.0003637419722508639\n",
      "0.00044109279406256974\n",
      "0.00040845488547347486\n",
      "0.0005535650998353958\n",
      "0.0003323545097373426\n",
      "0.00043007911881431937\n",
      "0.00035785645013675094\n",
      "0.00033518316922709346\n",
      "0.000367289234418422\n",
      "0.0003260505327489227\n",
      "0.00037300711846910417\n",
      "0.0003135950828436762\n",
      "0.0003785683074966073\n",
      "0.00024733631289564073\n",
      "0.00033216032898053527\n",
      "0.0004744573379866779\n",
      "0.0005936062661930919\n",
      "0.0004523242241702974\n",
      "0.00034504683571867645\n",
      "0.0003695487102959305\n",
      "0.0003923265030607581\n",
      "0.00035859530908055604\n",
      "0.00032144688884727657\n",
      "0.00039443274727091193\n",
      "0.00031217659125104547\n",
      "0.00036015541991218925\n",
      "0.00023409115965478122\n",
      "0.000410568987717852\n",
      "0.00040291977347806096\n",
      "0.0005086325691081583\n",
      "0.0004615347133949399\n",
      "0.0004997075302526355\n",
      "0.00034195597982034087\n",
      "0.0004762818571180105\n",
      "0.0004587216826621443\n",
      "0.0002719495678320527\n",
      "0.00031139058410190046\n",
      "0.0002696366864256561\n",
      "0.0003461705637164414\n",
      "0.0002999277785420418\n",
      "0.0002782883238978684\n",
      "0.00032405450474470854\n",
      "0.0002962485596071929\n",
      "0.0003164876252412796\n",
      "0.0003502978361211717\n",
      "0.00027258016052655876\n",
      "0.00022297987015917897\n",
      "0.0002595446421764791\n",
      "0.00028335381648503244\n",
      "0.00028323213336989284\n",
      "0.00031990668503567576\n",
      "0.0003196041798219085\n",
      "0.000269746728008613\n",
      "0.00023039379448164254\n",
      "0.00038047655834816396\n",
      "0.0002452530025038868\n",
      "0.0003017653652932495\n",
      "0.0001963885297300294\n",
      "0.00025448447559028864\n",
      "0.0002394908806309104\n",
      "0.00022328765771817416\n",
      "0.0002633994445204735\n",
      "0.00021167073282413185\n",
      "0.0002464105491526425\n",
      "0.00030946845072321594\n",
      "0.0002466306905262172\n",
      "0.00023968459572643042\n",
      "0.00018249740242026746\n",
      "0.00015080285083968192\n",
      "0.0002671723486855626\n",
      "0.00017986704187933356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [30:58<44:26, 148.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.17815563725490197\n",
      "验证集精度0.15\n",
      "测试集精度0.2109375\n",
      "0.00020934858184773475\n",
      "0.00018218214972876012\n",
      "0.00015997821174096316\n",
      "0.00019500112102832645\n",
      "0.00016302704170811921\n",
      "0.00018260881188325584\n",
      "0.00016446036170236766\n",
      "0.00018778227968141437\n",
      "0.00021347374422475696\n",
      "0.00017872323223855346\n",
      "0.00016048135876189917\n",
      "0.0001539485965622589\n",
      "0.00014585928875021636\n",
      "0.0001432020217180252\n",
      "0.00015809507749509066\n",
      "0.00016112726007122546\n",
      "0.000112207664642483\n",
      "0.0001656212261877954\n",
      "0.0001869107218226418\n",
      "0.00017684808699414134\n",
      "0.00026055643684230745\n",
      "0.000310442759655416\n",
      "0.0002767444821074605\n",
      "0.0002927401219494641\n",
      "0.00030095456168055534\n",
      "0.0002665459178388119\n",
      "0.00024111014499794692\n",
      "0.0003014564863406122\n",
      "0.00024716294137760997\n",
      "0.00026866645202971995\n",
      "0.0003078713780269027\n",
      "0.00018507671484258026\n",
      "0.0002623658801894635\n",
      "0.00018929773068521172\n",
      "0.00020546946325339377\n",
      "0.00017678654694464058\n",
      "0.00016078370390459895\n",
      "0.00022858419106341898\n",
      "0.00022461506887339056\n",
      "0.00016692491772118956\n",
      "0.00022990339493844658\n",
      "0.00019139627693220973\n",
      "0.00013182165275793523\n",
      "0.00016341324953828007\n",
      "0.0001522430102340877\n",
      "0.00019466664525680244\n",
      "0.00017912180919665843\n",
      "0.0001924034731928259\n",
      "0.00014267937513068318\n",
      "0.00015475644613616168\n",
      "0.0001234113733517006\n",
      "0.0001534990151412785\n",
      "0.00015206841635517776\n",
      "0.00015312604955397546\n",
      "0.00013377409777604043\n",
      "0.00020886676793452352\n",
      "0.0001680774730630219\n",
      "0.00017335437587462366\n",
      "0.0002650811802595854\n",
      "0.00017140373529400676\n",
      "0.00020732007396873087\n",
      "0.0002169730287278071\n",
      "0.00016011527623049915\n",
      "0.0001558921067044139\n",
      "0.00017444560944568366\n",
      "0.00019537874322850257\n",
      "0.00016810915258247405\n",
      "0.00018329198064748198\n",
      "0.00018027452460955828\n",
      "0.00017875168123282492\n",
      "0.00015877900295890868\n",
      "0.00028016825672239065\n",
      "0.0002664279891178012\n",
      "0.0001988887961488217\n",
      "0.0001722995948512107\n",
      "0.00018197784083895385\n",
      "0.00015682404045946896\n",
      "0.000195163709577173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [33:20<41:24, 146.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.13832720588235295\n",
      "验证集精度0.1390625\n",
      "测试集精度0.178125\n",
      "0.000185651850188151\n",
      "0.00016005888755898923\n",
      "0.00017215019033756107\n",
      "0.00017026372370310128\n",
      "0.00014776308671571314\n",
      "0.00016672673518769443\n",
      "0.00012508621148299426\n",
      "0.00013436339213512838\n",
      "0.00017379589553456753\n",
      "0.00023505245917476714\n",
      "0.0001940058427862823\n",
      "0.00014627665223088115\n",
      "0.00015303441614378244\n",
      "0.00018374320643488318\n",
      "0.00017836730694398284\n",
      "0.0001399078028043732\n",
      "0.00012547048390842974\n",
      "0.0001081519658328034\n",
      "0.0001860194024629891\n",
      "0.00011389944847906008\n",
      "0.0001050021528499201\n",
      "0.00010901827045017853\n",
      "0.0001964356197277084\n",
      "0.00012218971096444875\n",
      "0.00012254469038452953\n",
      "0.00015499505389016122\n",
      "0.00014053242921363562\n",
      "0.00016412808327004313\n",
      "0.0001440150081180036\n",
      "0.0001367017684970051\n",
      "0.00015348519082181156\n",
      "0.00014727706729900092\n",
      "0.00019429771055001765\n",
      "0.0002418967487756163\n",
      "0.0001559318625368178\n",
      "0.0001223270664922893\n",
      "0.00014378156629391015\n",
      "0.00012794783106073737\n",
      "0.00014622134040109813\n",
      "0.00020342647621873766\n",
      "0.00023218058049678802\n",
      "0.00019381359743420035\n",
      "0.00016217742813751101\n",
      "0.00026292778784409165\n",
      "0.00014763398212380707\n",
      "0.00019851401157211512\n",
      "0.00016744066670071334\n",
      "0.0002134992100764066\n",
      "0.00027404807042330503\n",
      "0.0002960431738756597\n",
      "0.0002590317162685096\n",
      "0.0002481522678863257\n",
      "0.00022404878109227866\n",
      "0.00025613303296267986\n",
      "0.0002250893012387678\n",
      "0.00023224631149787456\n",
      "0.0001925309479702264\n",
      "0.0002029464958468452\n",
      "0.00015344303392339498\n",
      "0.00020852846500929445\n",
      "0.00021228900004643947\n",
      "0.0002584915200714022\n",
      "0.0002434563502902165\n",
      "0.00029045710107311606\n",
      "0.00018087240459863096\n",
      "0.00014407042181119323\n",
      "0.00024357938673347235\n",
      "0.00018610668485052884\n",
      "0.00025497889146208763\n",
      "0.0001754214463289827\n",
      "0.00027248761034570634\n",
      "0.0002228101366199553\n",
      "0.00023307939409278333\n",
      "0.00024889849009923637\n",
      "0.00018881764844991267\n",
      "0.00013235106598585844\n",
      "0.00011848958092741668\n",
      "0.000136194983497262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [36:55<44:33, 167.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14414828431372548\n",
      "验证集精度0.1609375\n",
      "测试集精度0.1796875\n",
      "0.0001128742951550521\n",
      "0.00013507124094758183\n",
      "0.00018825092411134392\n",
      "0.0002772695734165609\n",
      "0.00014975568046793342\n",
      "0.00010414863209007308\n",
      "0.00014007906429469585\n",
      "0.00012081867316737771\n",
      "0.0002457864466123283\n",
      "0.00012046939809806645\n",
      "0.00013308311463333666\n",
      "0.00011817814083769917\n",
      "0.0001295222609769553\n",
      "0.0001468989794375375\n",
      "8.998130942927673e-05\n",
      "0.00013991938612889498\n",
      "0.00011655205162242055\n",
      "0.00010371271491749212\n",
      "0.00010062159708468243\n",
      "0.0001212146453326568\n",
      "0.00010202158591710031\n",
      "0.00017793553706724197\n",
      "0.0001643841969780624\n",
      "0.00011989090126007795\n",
      "0.00013615174975711852\n",
      "0.00014119013212621212\n",
      "0.00013899656187277287\n",
      "0.0001544711267342791\n",
      "0.00010679770639399067\n",
      "0.00011955022637266666\n",
      "8.95018019946292e-05\n",
      "0.00012367288582026958\n",
      "8.411881572101265e-05\n",
      "0.00016846071230247617\n",
      "0.00032128806924447417\n",
      "0.00019067447283305228\n",
      "0.00020113508799113333\n",
      "0.000152075313962996\n",
      "0.00013349682558327913\n",
      "0.00016596671775914729\n",
      "0.00020069483434781432\n",
      "0.00014872121391817927\n",
      "0.00015189606347121298\n",
      "9.971058170776814e-05\n",
      "0.00025895540602505207\n",
      "0.00017550804477650672\n",
      "0.00022773758973926306\n",
      "0.00019917944155167788\n",
      "0.00011072860797867179\n",
      "0.00013225589646026492\n",
      "0.00019633318879641593\n",
      "0.00012780023098457605\n",
      "0.0001752904790919274\n",
      "0.00015283210086636245\n",
      "0.00015257898485288024\n",
      "0.00012197125033708289\n",
      "0.0001082632879843004\n",
      "0.00013960557407699525\n",
      "0.0001871469576144591\n",
      "0.0001899496273836121\n",
      "0.00011214371625101194\n",
      "0.0001655166852287948\n",
      "0.00018473976524546742\n",
      "0.00020013521134387702\n",
      "0.00016506017709616572\n",
      "0.00013799668522551656\n",
      "0.0001364983181701973\n",
      "0.00017750794359017164\n",
      "0.0002003336849156767\n",
      "0.00015414580411743373\n",
      "0.0001719546562526375\n",
      "0.00014714221470057964\n",
      "0.00014089277829043567\n",
      "0.00013561075320467353\n",
      "0.0001039023554767482\n",
      "9.508313814876601e-05\n",
      "0.00016840289754327387\n",
      "0.00016353835235349834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [39:16<39:49, 159.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.15571384803921567\n",
      "验证集精度0.1375\n",
      "测试集精度0.171875\n",
      "0.00014463995466940105\n",
      "9.543166379444301e-05\n",
      "0.00012378521205391735\n",
      "0.0001321088057011366\n",
      "0.00014349535922519863\n",
      "0.00019511116261128336\n",
      "0.00010696816025301814\n",
      "0.00012900154979433864\n",
      "8.889402670320123e-05\n",
      "0.00010878042667172849\n",
      "0.00011227608047192916\n",
      "0.00010518142516957596\n",
      "0.00012730553862638772\n",
      "0.00011963264842052013\n",
      "9.398157999385148e-05\n",
      "0.00013243786816019565\n",
      "9.643768862588331e-05\n",
      "7.97373941168189e-05\n",
      "0.0001136930295615457\n",
      "0.00011877293582074344\n",
      "0.00011844682740047574\n",
      "0.00012121427425881848\n",
      "9.191984281642362e-05\n",
      "0.0001168901872006245\n",
      "0.00010438403842272237\n",
      "0.00010687984467949718\n",
      "0.00010404105705674738\n",
      "0.00011404749238863587\n",
      "0.00010481263598194346\n",
      "0.0001018606053548865\n",
      "9.670563304098323e-05\n",
      "8.830893057165667e-05\n",
      "0.00011072022607550025\n",
      "0.0001284920726902783\n",
      "0.0001180790932266973\n",
      "0.00010818947339430451\n",
      "8.715755393495783e-05\n",
      "0.00011246652866248041\n",
      "0.00011000547965522856\n",
      "7.827508670743555e-05\n",
      "0.0001150841562775895\n",
      "0.0001259262498933822\n",
      "0.0001799592428142205\n",
      "0.00011494362843222916\n",
      "0.00011925414582947269\n",
      "0.00010234207729808986\n",
      "9.318328375229612e-05\n",
      "9.854399104369804e-05\n",
      "8.859865920385346e-05\n",
      "0.0001563479600008577\n",
      "9.52917689573951e-05\n",
      "0.00011363363591954112\n",
      "8.179480937542394e-05\n",
      "0.0001165115027106367\n",
      "0.00013998763461131603\n",
      "0.00010879995534196496\n",
      "0.00010052522702608258\n",
      "0.00011156065011164173\n",
      "9.406857134308666e-05\n",
      "9.379223047289997e-05\n",
      "0.00010376283171353862\n",
      "0.0001232132490258664\n",
      "0.00015146848454605788\n",
      "0.00010537313210079446\n",
      "0.00010649960313457996\n",
      "9.663078526500612e-05\n",
      "0.00011711163824656978\n",
      "9.87007879302837e-05\n",
      "0.0001378352753818035\n",
      "0.0002070876507787034\n",
      "9.99797775875777e-05\n",
      "8.813214662950486e-05\n",
      "9.559593308949843e-05\n",
      "0.00019832930411212146\n",
      "0.00011243330664001405\n",
      "0.0001337257563136518\n",
      "0.00010549307626206428\n",
      "0.0001939213980222121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [42:15<38:32, 165.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.11764705882352941\n",
      "验证集精度0.128125\n",
      "测试集精度0.165625\n",
      "9.98676914605312e-05\n",
      "0.00014658454165328294\n",
      "0.00011661498137982562\n",
      "0.00016059594054240733\n",
      "0.0003492209652904421\n",
      "0.000472869083750993\n",
      "0.00029670793446712196\n",
      "0.00023513245105277747\n",
      "0.0002396416530245915\n",
      "0.00025351118529215455\n",
      "0.0003075012064073235\n",
      "0.0002741125354077667\n",
      "0.00021471433865372092\n",
      "0.00021843185822945088\n",
      "0.0001590423344168812\n",
      "0.00018207785615231842\n",
      "0.00016997414059005678\n",
      "0.00013630380271933973\n",
      "0.0001220946287503466\n",
      "0.0001555219350848347\n",
      "0.00010183730046264827\n",
      "0.00012977721053175628\n",
      "0.00021187827223911881\n",
      "0.00018241161887999624\n",
      "0.0001504316460341215\n",
      "0.00016770423098932952\n",
      "0.00011409328726585954\n",
      "0.00020643594325520098\n",
      "0.00017065877909772098\n",
      "0.0001650162012083456\n",
      "0.00032758869929239154\n",
      "0.0002780059876386076\n",
      "0.00029086502036079764\n",
      "0.0003047142527066171\n",
      "0.00046074576675891876\n",
      "0.0002762534422799945\n",
      "0.00043771532364189625\n",
      "0.00032632314832881093\n",
      "0.0003209504939150065\n",
      "0.00025433869450353086\n",
      "0.00025220910902135074\n",
      "0.00024226040113717318\n",
      "0.0002783203381113708\n",
      "0.00022728928888682276\n",
      "0.0002382871025474742\n",
      "0.00017585080058779567\n",
      "0.0001511509472038597\n",
      "0.0002231029502581805\n",
      "0.00017291883705183864\n",
      "0.00016577694623265415\n",
      "0.00018146724323742092\n",
      "0.0001516578340670094\n",
      "0.00015693972818553448\n",
      "0.00017127572209574282\n",
      "0.0001411150733474642\n",
      "0.0001479045022279024\n",
      "0.0001759706501616165\n",
      "0.0001136866703745909\n",
      "0.00013309709902387112\n",
      "0.00014955199731048197\n",
      "0.00013377194409258664\n",
      "0.00015616683231201023\n",
      "0.00014362421643454581\n",
      "0.00018376113439444453\n",
      "0.00013311035581864417\n",
      "0.00014198133430909365\n",
      "0.00013025905354879797\n",
      "0.00012723922554869205\n",
      "0.00014946375449653715\n",
      "0.00013038693577982485\n",
      "0.0001483811647631228\n",
      "0.00013320648577064276\n",
      "0.00015879793500062078\n",
      "0.00019281209097243845\n",
      "0.00016629209858365357\n",
      "0.00015337397053372115\n",
      "0.00012637031613849103\n",
      "0.00019109094864688814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [44:25<33:27, 154.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.11780024509803921\n",
      "验证集精度0.1171875\n",
      "测试集精度0.159375\n",
      "0.0001149915115092881\n",
      "0.0002552028454374522\n",
      "9.33735427679494e-05\n",
      "9.18393925530836e-05\n",
      "0.00019105018873233348\n",
      "0.00015486108895856887\n",
      "0.0001808900124160573\n",
      "0.00015494192484766245\n",
      "0.000163385717314668\n",
      "0.00013617862714454532\n",
      "0.0001315236440859735\n",
      "0.00018995719437953085\n",
      "0.00012233582674525678\n",
      "0.00015554219135083258\n",
      "9.213646990247071e-05\n",
      "0.00010596563515719026\n",
      "0.00010215879592578858\n",
      "0.00012301612878218293\n",
      "0.00011862478277180344\n",
      "0.00010076731268782169\n",
      "0.0001448224065825343\n",
      "8.715087460586801e-05\n",
      "0.00011366951366653666\n",
      "0.00011086400627391413\n",
      "0.00010227713210042566\n",
      "0.000122613666462712\n",
      "0.00014328071847558022\n",
      "0.00013307214248925447\n",
      "0.0001612892810953781\n",
      "0.00013725980534218252\n",
      "0.00012594721920322627\n",
      "0.0001076710395864211\n",
      "0.00011115257075289264\n",
      "0.00012263037206139416\n",
      "0.00015524189802818\n",
      "0.00014433062460739166\n",
      "9.059013245860115e-05\n",
      "9.051802044268698e-05\n",
      "8.992741641122848e-05\n",
      "9.85879305517301e-05\n",
      "9.728625445859507e-05\n",
      "0.00010745901090558618\n",
      "0.0001024195589707233\n",
      "7.505402027163655e-05\n",
      "0.00010684366134228185\n",
      "9.925301856128499e-05\n",
      "8.96850397111848e-05\n",
      "0.00012192925350973383\n",
      "0.00013194195344112813\n",
      "0.00015252662706188858\n",
      "0.0001540336961625144\n",
      "0.00019660040561575443\n",
      "0.00011559896665858105\n",
      "0.00012643075024243444\n",
      "0.00010901653149630874\n",
      "0.00012727819557767361\n",
      "0.0001249002234544605\n",
      "0.00015846171299926937\n",
      "0.00014013494364917278\n",
      "0.00013279903214424849\n",
      "0.00010329183714929968\n",
      "9.29668967728503e-05\n",
      "0.00011884075502166525\n",
      "0.0001055441825883463\n",
      "8.679356687935069e-05\n",
      "0.0001092040547518991\n",
      "0.00010113886673934758\n",
      "0.00012123760097892955\n",
      "9.200492786476389e-05\n",
      "0.00013309424684848636\n",
      "9.021037112688646e-05\n",
      "0.00011094387446064502\n",
      "7.25591235095635e-05\n",
      "0.00014040821406524628\n",
      "9.661346848588437e-05\n",
      "0.00016069106641225517\n",
      "0.00028938852483406663\n",
      "0.00022048549726605415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [47:47<33:48, 169.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.11887254901960784\n",
      "验证集精度0.1390625\n",
      "测试集精度0.1796875\n",
      "0.0002136651601176709\n",
      "9.808127651922405e-05\n",
      "0.00011933218047488481\n",
      "0.00016947741096373647\n",
      "0.00019941515347454697\n",
      "0.00011881349928444251\n",
      "0.0001265895989490673\n",
      "0.00014090086915530264\n",
      "0.00013549791765399277\n",
      "0.0001223155704792589\n",
      "0.00015649115084670484\n",
      "0.0001517979399068281\n",
      "0.00012726332352031022\n",
      "9.620127821108326e-05\n",
      "9.217116894433275e-05\n",
      "9.582103666616604e-05\n",
      "0.00011371362052159384\n",
      "0.00011231278767809272\n",
      "0.00011462510155979544\n",
      "0.00015006051398813725\n",
      "0.00010905740782618523\n",
      "0.00013303177547641098\n",
      "0.00012020645954180509\n",
      "0.00010530170402489603\n",
      "0.00011652993271127343\n",
      "0.00012382958084344864\n",
      "9.290393791161478e-05\n",
      "8.24474700493738e-05\n",
      "0.00010620028479024768\n",
      "9.720199159346521e-05\n",
      "8.029444143176079e-05\n",
      "7.862812344683334e-05\n",
      "0.00010702922736527398\n",
      "9.170552220894024e-05\n",
      "0.00010109788127010688\n",
      "7.527170237153769e-05\n",
      "0.00011869768059113994\n",
      "0.00010496885079191998\n",
      "8.01138739916496e-05\n",
      "8.594457904109731e-05\n",
      "8.455525676254183e-05\n",
      "9.751930338097736e-05\n",
      "8.907901064958423e-05\n",
      "7.140883826650679e-05\n",
      "9.828413021750748e-05\n",
      "8.855441410560161e-05\n",
      "0.00010387895599706098\n",
      "9.991579281631857e-05\n",
      "6.963646592339501e-05\n",
      "6.722033867845312e-05\n",
      "0.00010531750740483403\n",
      "0.00010788083454826847\n",
      "0.0001027925027301535\n",
      "0.00011500376422191039\n",
      "7.523719978053123e-05\n",
      "0.00013740590657107532\n",
      "0.00011969867045991123\n",
      "0.00011260582687100396\n",
      "0.00011058172094635665\n",
      "0.0001147394796134904\n",
      "0.0001299209543503821\n",
      "0.00011346363316988572\n",
      "8.206095662899315e-05\n",
      "0.00011251850082771853\n",
      "0.00012638431508094072\n",
      "0.00011577629629755393\n",
      "0.00013152309111319482\n",
      "0.00014462445687968284\n",
      "9.514801786281168e-05\n",
      "9.11645547603257e-05\n",
      "9.409138874616474e-05\n",
      "0.00010163911065319553\n",
      "0.00011293444549664855\n",
      "0.00012099529703846201\n",
      "0.00010634225327521563\n",
      "0.00010928900155704468\n",
      "9.200950444210321e-05\n",
      "0.00011497730884002522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [49:20<26:45, 145.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.12867647058823528\n",
      "验证集精度0.190625\n",
      "测试集精度0.1578125\n",
      "9.742642578203231e-05\n",
      "0.0001717972627375275\n",
      "0.00010302513692295179\n",
      "0.00010709519847296178\n",
      "7.790864765411243e-05\n",
      "9.194146696245298e-05\n",
      "0.0001438436593161896\n",
      "9.174716979032382e-05\n",
      "9.416568354936317e-05\n",
      "9.773750934982672e-05\n",
      "9.34342315304093e-05\n",
      "7.755977276246995e-05\n",
      "0.00012698063801508397\n",
      "0.00012110259558539838\n",
      "9.889455395750701e-05\n",
      "8.600790897617117e-05\n",
      "9.956290887203068e-05\n",
      "9.95468653854914e-05\n",
      "0.00012518881703726947\n",
      "0.00011256174911977723\n",
      "8.244048513006419e-05\n",
      "0.00010516757902223617\n",
      "8.111329952953383e-05\n",
      "6.802303687436506e-05\n",
      "9.26286811591126e-05\n",
      "9.564277570461854e-05\n",
      "8.760355558479205e-05\n",
      "9.136384323937818e-05\n",
      "9.939351730281487e-05\n",
      "0.0001022892611217685\n",
      "6.690950249321759e-05\n",
      "6.936215504538268e-05\n",
      "8.607611380284652e-05\n",
      "7.330344669753686e-05\n",
      "7.67854435252957e-05\n",
      "8.838037319947034e-05\n",
      "7.29071834939532e-05\n",
      "9.395505912834778e-05\n",
      "7.331211963901296e-05\n",
      "7.236303645186126e-05\n",
      "7.948813436087221e-05\n",
      "7.691467180848122e-05\n",
      "9.738474909681827e-05\n",
      "0.00010592270700726658\n",
      "6.240555376280099e-05\n",
      "7.383633055724204e-05\n",
      "8.938102837419137e-05\n",
      "0.00011563348380150273\n",
      "7.636097870999947e-05\n",
      "7.187740266090259e-05\n",
      "0.00010867058881558478\n",
      "8.143684681272134e-05\n",
      "9.562457853462547e-05\n",
      "8.623627218184993e-05\n",
      "9.892255184240639e-05\n",
      "7.443746289936826e-05\n",
      "7.449744589393958e-05\n",
      "9.856975520960987e-05\n",
      "0.00010995808406732976\n",
      "0.00011003436520695686\n",
      "9.027272608364001e-05\n",
      "6.962357292650267e-05\n",
      "0.00010330389341106638\n",
      "8.724496728973463e-05\n",
      "0.00011510105105116963\n",
      "0.00014750896662008017\n",
      "0.00010601530084386468\n",
      "7.546848064521328e-05\n",
      "7.578978693345562e-05\n",
      "0.00014000122610013932\n",
      "7.743824244244024e-05\n",
      "9.17051438591443e-05\n",
      "9.443584713153541e-05\n",
      "0.00011004799307556823\n",
      "9.12416580831632e-05\n",
      "8.050955511862412e-05\n",
      "0.0001106843410525471\n",
      "7.458581967512146e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [51:29<23:28, 140.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.12009803921568628\n",
      "验证集精度0.1546875\n",
      "测试集精度0.121875\n",
      "7.103590905899182e-05\n",
      "0.00010296601249137893\n",
      "9.030655928654596e-05\n",
      "0.0001021162752294913\n",
      "7.896039460320026e-05\n",
      "7.486174581572413e-05\n",
      "8.854267071001232e-05\n",
      "6.604460213566199e-05\n",
      "8.377882477361709e-05\n",
      "7.373666448984295e-05\n",
      "0.00011030315363314003\n",
      "9.128391684498638e-05\n",
      "9.209908603224903e-05\n",
      "8.146353502525017e-05\n",
      "7.552222814410925e-05\n",
      "6.287447467911988e-05\n",
      "9.082732140086591e-05\n",
      "6.874011887703091e-05\n",
      "8.30029821372591e-05\n",
      "6.340638356050476e-05\n",
      "6.255646439967677e-05\n",
      "6.890490476507694e-05\n",
      "9.420845162821934e-05\n",
      "8.905857248464599e-05\n",
      "8.679118764121085e-05\n",
      "7.174874190241098e-05\n",
      "8.120949496515095e-05\n",
      "7.076461770338938e-05\n",
      "9.403677540831268e-05\n",
      "9.981849871110171e-05\n",
      "8.034505299292505e-05\n",
      "9.177502215607092e-05\n",
      "8.715024887351319e-05\n",
      "0.00013395131099969149\n",
      "0.00016276973474305123\n",
      "9.92355344351381e-05\n",
      "7.863173232180998e-05\n",
      "0.00010630293400026858\n",
      "0.00013256836973596364\n",
      "0.00017229511286132038\n",
      "0.00014147131878416985\n",
      "8.326423267135397e-05\n",
      "0.0001517694181529805\n",
      "0.00011282746709184721\n",
      "0.00011032479233108461\n",
      "9.761114051798359e-05\n",
      "9.759359818417579e-05\n",
      "0.00016065637464635074\n",
      "0.00010362838656874374\n",
      "0.00015027530025690794\n",
      "0.0001859525073086843\n",
      "0.00023181150027085096\n",
      "0.00014232072862796485\n",
      "0.00012659138883464038\n",
      "0.0001566745777381584\n",
      "0.00012249672727193683\n",
      "0.000137843526317738\n",
      "0.00013817069702781737\n",
      "0.00013237175880931318\n",
      "7.871656998759136e-05\n",
      "0.00017179835413116962\n",
      "0.0001271541405003518\n",
      "0.00017981926794163883\n",
      "0.00016265735030174255\n",
      "0.00014221172023098916\n",
      "0.0002440005773678422\n",
      "0.00011607041960814968\n",
      "0.0002245075738755986\n",
      "0.00023678112484049052\n",
      "0.0002208182995673269\n",
      "0.0001559234078740701\n",
      "0.0001145673159044236\n",
      "0.0001376750587951392\n",
      "0.0001314776309300214\n",
      "0.00016686767048668116\n",
      "0.00012032855011057109\n",
      "0.00010566780110821128\n",
      "0.0001432214048691094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [54:52<23:56, 159.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.11075367647058823\n",
      "验证集精度0.1671875\n",
      "测试集精度0.159375\n",
      "0.00010844153439393267\n",
      "8.461855759378523e-05\n",
      "0.00011682418698910624\n",
      "0.00012419064296409488\n",
      "0.000126452578115277\n",
      "0.00014043859846424311\n",
      "0.00012007522309431806\n",
      "0.00029991380870342255\n",
      "0.00037754481309093535\n",
      "0.0005364029202610254\n",
      "0.00040775496745482087\n",
      "0.00037265144055709243\n",
      "0.0003272283065598458\n",
      "0.00023988661996554583\n",
      "0.0002727042301557958\n",
      "0.00026429040008224547\n",
      "0.00034156476613134146\n",
      "0.00044315477134659886\n",
      "0.00021806586300954223\n",
      "0.00018974645354319364\n",
      "0.00021129479864612222\n",
      "0.0002058253885479644\n",
      "0.00015770536265335977\n",
      "0.00015391313354484737\n",
      "0.0001638176036067307\n",
      "0.0001299375289818272\n",
      "0.00013238386600278318\n",
      "0.00016864087956491858\n",
      "0.00018214462033938617\n",
      "0.0001515811018180102\n",
      "0.00015214116137940437\n",
      "0.00020793979638256133\n",
      "0.00012636304018087685\n",
      "0.00014820296200923622\n",
      "9.792869241209701e-05\n",
      "0.00013377137656789273\n",
      "0.0001370051031699404\n",
      "9.927775681717321e-05\n",
      "0.00010195877257501706\n",
      "0.00013316384865902364\n",
      "0.00013005317305214703\n",
      "0.0001241086720256135\n",
      "0.00010980511433444917\n",
      "0.00010766860214062035\n",
      "0.0001649294572416693\n",
      "0.00024530215887352824\n",
      "0.00019516510656103492\n",
      "0.00026718899607658386\n",
      "0.0003405186871532351\n",
      "0.00023886992130428553\n",
      "0.00034747779136523604\n",
      "0.0003384779847692698\n",
      "0.0003524580388329923\n",
      "0.00022002821788191795\n",
      "0.0001376184227410704\n",
      "0.0001552687754156068\n",
      "0.0002752941509243101\n",
      "0.0002308083203388378\n",
      "0.00015684511163271964\n",
      "0.00011793021985795349\n",
      "0.00014165784523356706\n",
      "0.0002169676881749183\n",
      "0.0002083110302919522\n",
      "0.000256286293733865\n",
      "0.0001801851758500561\n",
      "0.0001429641415597871\n",
      "0.00013232148194219917\n",
      "0.00010494276648387313\n",
      "0.00014098903920967132\n",
      "0.00019450575928203762\n",
      "0.00016644684365019202\n",
      "0.0002312393335159868\n",
      "0.00014757538156118244\n",
      "0.00018412039207760245\n",
      "0.00014184725296217948\n",
      "0.00010643505811458454\n",
      "0.0001944634277606383\n",
      "0.00016418607265222818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [56:24<18:34, 139.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.0858609068627451\n",
      "验证集精度0.096875\n",
      "测试集精度0.1109375\n",
      "0.00012672104639932513\n",
      "0.00010767957428470254\n",
      "0.0001207016539410688\n",
      "0.00014297252346295863\n",
      "0.00011037242074962705\n",
      "0.00012969390081707388\n",
      "9.935008711181581e-05\n",
      "8.693002018844709e-05\n",
      "8.822200470604002e-05\n",
      "0.00011231603275518864\n",
      "8.157345291692764e-05\n",
      "7.862985512474552e-05\n",
      "7.825912325643003e-05\n",
      "8.24478265712969e-05\n",
      "0.00013463590585161\n",
      "9.289018635172397e-05\n",
      "0.00011198548600077629\n",
      "0.00012493183021433651\n",
      "8.170751243596897e-05\n",
      "0.00013520731590688229\n",
      "8.864108531270176e-05\n",
      "9.556604345561936e-05\n",
      "7.951263251015916e-05\n",
      "8.140769205056131e-05\n",
      "6.584153743460774e-05\n",
      "8.09872435638681e-05\n",
      "9.646294347476214e-05\n",
      "6.712622416671365e-05\n",
      "8.091997733572498e-05\n",
      "7.798135629855096e-05\n",
      "8.126115426421165e-05\n",
      "9.766247967490926e-05\n",
      "6.969434616621584e-05\n",
      "6.35118194622919e-05\n",
      "7.847632514312863e-05\n",
      "8.508468454238027e-05\n",
      "8.026465366128832e-05\n",
      "9.817408135859296e-05\n",
      "5.961045098956674e-05\n",
      "8.542659634258598e-05\n",
      "8.704130596015602e-05\n",
      "6.689935980830342e-05\n",
      "8.464205166092142e-05\n",
      "8.542477007722482e-05\n",
      "9.164713264908642e-05\n",
      "7.727120828349143e-05\n",
      "8.211199019569904e-05\n",
      "0.00010951889998978004\n",
      "9.02258834685199e-05\n",
      "9.017164848046377e-05\n",
      "8.954885561252013e-05\n",
      "0.00012287944264244288\n",
      "9.271511225961149e-05\n",
      "0.00018026937323156744\n",
      "0.00016533320012968034\n",
      "0.00010369216033723205\n",
      "0.00017033239419106394\n",
      "0.00030943393358029425\n",
      "0.00011798940977314487\n",
      "0.00018194316362496465\n",
      "0.00019372414681129158\n",
      "0.00021400519472081214\n",
      "0.00021293500321917236\n",
      "0.00018310877203475684\n",
      "0.00021533496328629553\n",
      "0.00015530917153228074\n",
      "0.00016719634004402906\n",
      "0.00012543474440462887\n",
      "0.00012739757949020714\n",
      "0.00014408081187866628\n",
      "0.00013195430801715702\n",
      "0.0001329140068264678\n",
      "0.00013196883082855493\n",
      "0.0002670424000825733\n",
      "0.0001995596830965951\n",
      "0.00011022239050362259\n",
      "0.00012340385001152754\n",
      "0.00018782421830110252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [59:47<18:28, 158.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.12775735294117646\n",
      "验证集精度0.13125\n",
      "测试集精度0.115625\n",
      "0.0001302399323321879\n",
      "0.00012215232709422708\n",
      "0.00019086728570982814\n",
      "0.00010693234798964113\n",
      "9.207156108459458e-05\n",
      "9.901129669742659e-05\n",
      "0.00010343626490794122\n",
      "0.00010346515773562714\n",
      "0.00011083236313425004\n",
      "0.00017782275972422212\n",
      "9.620303171686828e-05\n",
      "0.00010301291331415996\n",
      "0.00011667029320960864\n",
      "0.00011710758553817868\n",
      "9.428559133084491e-05\n",
      "8.76059420988895e-05\n",
      "0.00010871731501538306\n",
      "9.136361040873453e-05\n",
      "0.0001191946939798072\n",
      "8.17198961158283e-05\n",
      "8.436611824436113e-05\n",
      "0.00010979668149957433\n",
      "0.00012897404667455703\n",
      "0.0001180563704110682\n",
      "0.000139969153678976\n",
      "0.0001672598154982552\n",
      "8.498841634718701e-05\n",
      "8.246499783126637e-05\n",
      "8.348112896783277e-05\n",
      "9.392776701133698e-05\n",
      "0.00012142611376475543\n",
      "8.462351252092049e-05\n",
      "0.00010107106936629862\n",
      "8.479541429551318e-05\n",
      "8.31484139780514e-05\n",
      "0.00010769368964247406\n",
      "0.00010135622869711369\n",
      "8.773503213888034e-05\n",
      "0.0001139432642958127\n",
      "8.811384032014757e-05\n",
      "7.765837654005736e-05\n",
      "7.297878619283438e-05\n",
      "0.000108522035588976\n",
      "0.00010748808563221246\n",
      "0.00010200920951319858\n",
      "0.00010861511691473424\n",
      "8.177182462532073e-05\n",
      "7.887766696512699e-05\n",
      "0.00011549011833267286\n",
      "7.64694923418574e-05\n",
      "8.40792345115915e-05\n",
      "8.41631626826711e-05\n",
      "8.598661952419207e-05\n",
      "6.6251857788302e-05\n",
      "0.0001053024097927846\n",
      "0.00010047316027339548\n",
      "0.00011134796659462154\n",
      "0.0001197967940242961\n",
      "9.81043849606067e-05\n",
      "8.577665721531957e-05\n",
      "9.2238602519501e-05\n",
      "9.020281868288293e-05\n",
      "7.454452861566097e-05\n",
      "7.11403408786282e-05\n",
      "8.523729775333777e-05\n",
      "0.00013096208567731082\n",
      "8.001390233403072e-05\n",
      "8.45011745695956e-05\n",
      "9.552182018524036e-05\n",
      "0.0001259787823073566\n",
      "0.00011145693133585155\n",
      "8.389863069169223e-05\n",
      "8.677451842231676e-05\n",
      "0.00010800447489600629\n",
      "8.018875814741477e-05\n",
      "8.734974835533649e-05\n",
      "9.392553329234943e-05\n",
      "7.951837324071676e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [1:01:31<14:13, 142.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.11397058823529412\n",
      "验证集精度0.10625\n",
      "测试集精度0.1125\n",
      "9.179032349493355e-05\n",
      "7.684321462875232e-05\n",
      "7.763770554447547e-05\n",
      "0.00010209867468802258\n",
      "7.662869029445574e-05\n",
      "9.308182052336633e-05\n",
      "0.0001008873077807948\n",
      "7.058768824208528e-05\n",
      "8.149716450134292e-05\n",
      "9.42653205129318e-05\n",
      "8.427059219684452e-05\n",
      "7.427840318996459e-05\n",
      "8.402319508604705e-05\n",
      "9.104722994379699e-05\n",
      "8.803660603007302e-05\n",
      "7.05650745658204e-05\n",
      "7.793769327690825e-05\n",
      "6.991920236032456e-05\n",
      "7.020406337687746e-05\n",
      "7.449523400282487e-05\n",
      "0.00011068796447943896\n",
      "0.00011061875557061285\n",
      "7.539707439718768e-05\n",
      "7.640479452675208e-05\n",
      "7.094803731888533e-05\n",
      "7.688160258112475e-05\n",
      "8.78510472830385e-05\n",
      "9.351734479423612e-05\n",
      "0.00011023514525732026\n",
      "7.201624976005405e-05\n",
      "8.662968321004882e-05\n",
      "8.366889233002439e-05\n",
      "7.787589856889099e-05\n",
      "7.837549492251128e-05\n",
      "8.109547343337908e-05\n",
      "7.947778794914484e-05\n",
      "9.668016718933359e-05\n",
      "6.408069748431444e-05\n",
      "6.206327088875696e-05\n",
      "6.831991049693897e-05\n",
      "0.00013586475688498467\n",
      "6.487464997917414e-05\n",
      "6.500286690425128e-05\n",
      "0.00010915719758486375\n",
      "7.38814051146619e-05\n",
      "0.0001186849913210608\n",
      "0.00012613183935172856\n",
      "0.00011089777399320155\n",
      "8.851613529259339e-05\n",
      "8.159796561812982e-05\n",
      "7.637157250428572e-05\n",
      "9.599752229405567e-05\n",
      "9.77324161794968e-05\n",
      "0.00012430832430254668\n",
      "0.00017116140224970877\n",
      "0.00011563138832570985\n",
      "0.00013104570098221302\n",
      "9.27808869164437e-05\n",
      "0.0001076945336535573\n",
      "9.476518607698381e-05\n",
      "0.00010410173126729205\n",
      "7.025548256933689e-05\n",
      "9.306426363764331e-05\n",
      "6.707573629682884e-05\n",
      "7.159812230383977e-05\n",
      "8.866098505677655e-05\n",
      "0.00012771686306223273\n",
      "8.554996747989208e-05\n",
      "8.936972153605893e-05\n",
      "9.240979125024751e-05\n",
      "0.00010913956793956459\n",
      "9.058203431777656e-05\n",
      "0.00013689935440197587\n",
      "0.00010028295946540311\n",
      "0.00014064056449569762\n",
      "9.885380859486759e-05\n",
      "0.00013368716463446617\n",
      "0.00012706317647825927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [1:04:42<13:03, 156.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14667585784313725\n",
      "验证集精度0.1625\n",
      "测试集精度0.1375\n",
      "0.0001341306633548811\n",
      "0.00010358329018345103\n",
      "0.00015773398627061397\n",
      "9.451570804230869e-05\n",
      "0.0001079952999134548\n",
      "0.0001390407414874062\n",
      "0.00015839333354961127\n",
      "0.00018598376482259482\n",
      "0.0001471255236538127\n",
      "0.00012075337872374803\n",
      "0.00016643738490529358\n",
      "0.0001523743849247694\n",
      "0.00012259441427886486\n",
      "0.00012185101513750851\n",
      "0.0001118047657655552\n",
      "0.00012391156633384526\n",
      "8.332413563039154e-05\n",
      "0.00012952419638168067\n",
      "8.684567001182586e-05\n",
      "7.675959204789251e-05\n",
      "0.00010353230754844844\n",
      "0.00013745726027991623\n",
      "0.0001329902879660949\n",
      "0.00010376568388892338\n",
      "9.716049680719152e-05\n",
      "0.00010636469960445538\n",
      "0.0001274342357646674\n",
      "0.00015875507961027324\n",
      "8.700196485733613e-05\n",
      "0.0001013212458929047\n",
      "9.529359522275627e-05\n",
      "0.00011755826562875882\n",
      "0.00012130457616876811\n",
      "9.838262485573068e-05\n",
      "0.00014574835950043052\n",
      "9.476693230681121e-05\n",
      "0.0001253714581253007\n",
      "0.0001217259414261207\n",
      "9.059988224180415e-05\n",
      "0.00010263358853990212\n",
      "0.00012268310820218176\n",
      "0.00013698618568014354\n",
      "0.00020663741452153772\n",
      "0.0001463538792449981\n",
      "8.7023749074433e-05\n",
      "9.453990787733346e-05\n",
      "0.00011751057900255546\n",
      "0.00011335044109728187\n",
      "8.728434477234259e-05\n",
      "9.611379209673032e-05\n",
      "7.56828740122728e-05\n",
      "9.956642315955833e-05\n",
      "8.624158363090828e-05\n",
      "0.00011176818225067109\n",
      "7.431362610077485e-05\n",
      "0.000127165432786569\n",
      "9.332263289252296e-05\n",
      "8.080639236140996e-05\n",
      "8.096479723462835e-05\n",
      "7.199670653790236e-05\n",
      "7.189619645942003e-05\n",
      "7.787881622789428e-05\n",
      "7.908121187938377e-05\n",
      "8.097447425825521e-05\n",
      "8.406685083173215e-05\n",
      "8.59304636833258e-05\n",
      "8.973784861154854e-05\n",
      "0.00011468290904304013\n",
      "7.735931285424158e-05\n",
      "8.406917186221108e-05\n",
      "6.881101580802351e-05\n",
      "7.309086504392326e-05\n",
      "0.00011991048813797534\n",
      "8.433249604422599e-05\n",
      "7.456490129698068e-05\n",
      "8.52577795740217e-05\n",
      "8.570566569687799e-05\n",
      "5.860098099219613e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [1:07:16<10:23, 155.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1760876225490196\n",
      "验证集精度0.1734375\n",
      "测试集精度0.1546875\n",
      "8.078856626525521e-05\n",
      "7.133249164326116e-05\n",
      "8.912292832974344e-05\n",
      "6.726904393872246e-05\n",
      "6.633250450249761e-05\n",
      "7.409105455735698e-05\n",
      "7.707197801209986e-05\n",
      "6.461871089413762e-05\n",
      "6.899111031088978e-05\n",
      "9.642425720812753e-05\n",
      "6.624520756304264e-05\n",
      "9.217137994710356e-05\n",
      "7.851470581954345e-05\n",
      "9.095396671909839e-05\n",
      "9.80408804025501e-05\n",
      "8.946906746132299e-05\n",
      "6.151859270175919e-05\n",
      "7.161930261645466e-05\n",
      "7.499427010770887e-05\n",
      "6.643094820901752e-05\n",
      "8.087744936347008e-05\n",
      "7.298730633920059e-05\n",
      "0.0001033436565194279\n",
      "7.777188875479624e-05\n",
      "8.424993575317785e-05\n",
      "8.266729855677113e-05\n",
      "0.00011302694474579766\n",
      "0.00014570113853551447\n",
      "0.00013389036757871509\n",
      "8.178140706149861e-05\n",
      "9.102449257625267e-05\n",
      "0.00010443297651363537\n",
      "0.00010311921505490318\n",
      "0.0001344747724942863\n",
      "0.00013730337377637625\n",
      "0.00011714479478541762\n",
      "0.00014663062756881118\n",
      "0.00015249087300617248\n",
      "0.00010314498649677262\n",
      "0.00015544382040388882\n",
      "0.00010830691462615505\n",
      "8.037159568630159e-05\n",
      "7.57853122195229e-05\n",
      "9.708918514661491e-05\n",
      "8.14717059256509e-05\n",
      "0.0001104916154872626\n",
      "7.137432839954272e-05\n",
      "6.81065212120302e-05\n",
      "8.448621520074084e-05\n",
      "7.789510709699243e-05\n",
      "7.07661165506579e-05\n",
      "8.936859376262873e-05\n",
      "0.00013936345931142569\n",
      "0.00010689414921216667\n",
      "0.00011221999011468142\n",
      "0.0001010097621474415\n",
      "0.00010409270907985047\n",
      "0.00012265366967767477\n",
      "0.0001420140324626118\n",
      "0.00011872613686136901\n",
      "9.640444477554411e-05\n",
      "7.954143802635372e-05\n",
      "8.14441082184203e-05\n",
      "8.32768200780265e-05\n",
      "8.346721006091684e-05\n",
      "0.00010862435010494664\n",
      "8.983104635262862e-05\n",
      "8.776754111750051e-05\n",
      "0.00010862389171961695\n",
      "8.730781701160595e-05\n",
      "9.813702490646392e-05\n",
      "7.556602213298902e-05\n",
      "8.117627294268459e-05\n",
      "7.847658707760274e-05\n",
      "7.221597479656339e-05\n",
      "8.950103801907972e-05\n",
      "9.776144725037739e-05\n",
      "8.239424641942605e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [1:11:04<08:52, 177.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.1488970588235294\n",
      "验证集精度0.171875\n",
      "测试集精度0.1453125\n",
      "0.00010616023791953921\n",
      "9.350755135528743e-05\n",
      "7.964643009472638e-05\n",
      "7.055675814626738e-05\n",
      "7.108732825145125e-05\n",
      "7.990807353053242e-05\n",
      "8.253777195932344e-05\n",
      "7.519905921071768e-05\n",
      "6.160906923469156e-05\n",
      "7.812240073690191e-05\n",
      "6.668094283668324e-05\n",
      "8.044879359658808e-05\n",
      "8.251666440628469e-05\n",
      "6.707054853904992e-05\n",
      "9.029531793203205e-05\n",
      "6.907799252076074e-05\n",
      "8.704209176357836e-05\n",
      "6.285983545240015e-05\n",
      "7.310536602744833e-05\n",
      "9.389234037371352e-05\n",
      "7.603586709592491e-05\n",
      "7.56390654714778e-05\n",
      "7.452224235748872e-05\n",
      "6.291809404501691e-05\n",
      "7.032549910945818e-05\n",
      "9.231127478415146e-05\n",
      "7.292325608432293e-05\n",
      "8.204714686144143e-05\n",
      "6.239907088456675e-05\n",
      "6.134014984127134e-05\n",
      "8.419920050073415e-05\n",
      "7.225709850899875e-05\n",
      "7.79637266532518e-05\n",
      "7.681395800318569e-05\n",
      "6.701598613290116e-05\n",
      "6.0323676734697074e-05\n",
      "7.642144191777334e-05\n",
      "6.226528057595715e-05\n",
      "0.00010886898962780833\n",
      "8.962958963820711e-05\n",
      "8.755330054555088e-05\n",
      "8.105436427285895e-05\n",
      "8.671850810060278e-05\n",
      "7.485443347832188e-05\n",
      "0.00014791167632211\n",
      "9.288299770560116e-05\n",
      "8.766764221945778e-05\n",
      "7.846877269912511e-05\n",
      "0.00010700771235860884\n",
      "9.370270709041506e-05\n",
      "0.0001583580597070977\n",
      "9.261794184567407e-05\n",
      "0.00010227904567727819\n",
      "7.688684854656458e-05\n",
      "6.728412699885666e-05\n",
      "8.389788854401559e-05\n",
      "0.00011205043119844049\n",
      "6.867796764709055e-05\n",
      "7.273127266671509e-05\n",
      "7.237536192405969e-05\n",
      "0.00011838676437037066\n",
      "9.075197885977104e-05\n",
      "7.189088501036167e-05\n",
      "7.657057722099125e-05\n",
      "0.00013070969725959003\n",
      "6.640749052166939e-05\n",
      "8.555917156627402e-05\n",
      "7.125209231162444e-05\n",
      "9.56958465394564e-05\n",
      "8.033698395593092e-05\n",
      "9.33406554395333e-05\n",
      "6.644247332587838e-05\n",
      "8.050035103224218e-05\n",
      "6.845574534963816e-05\n",
      "7.0312584284693e-05\n",
      "7.280983845703304e-05\n",
      "7.214883953565732e-05\n",
      "7.454851584043354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [1:14:02<05:55, 177.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.16689644607843138\n",
      "验证集精度0.1609375\n",
      "测试集精度0.1546875\n",
      "6.98689982527867e-05\n",
      "8.796928887022659e-05\n",
      "7.5498093792703e-05\n",
      "7.172786718001589e-05\n",
      "8.545644232071936e-05\n",
      "7.292870577657595e-05\n",
      "6.257268250919878e-05\n",
      "6.845845928182825e-05\n",
      "6.84997794451192e-05\n",
      "7.631377957295626e-05\n",
      "6.860877329017967e-05\n",
      "7.847483357181773e-05\n",
      "6.943960033822805e-05\n",
      "7.258768891915679e-05\n",
      "6.698680226691067e-05\n",
      "7.901948265498504e-05\n",
      "6.703825056320056e-05\n",
      "7.713380182394758e-05\n",
      "5.964842057437636e-05\n",
      "6.790496263420209e-05\n",
      "0.00010847717931028455\n",
      "7.457107858499512e-05\n",
      "6.777119415346533e-05\n",
      "6.837406544946134e-05\n",
      "7.489967538276687e-05\n",
      "7.265430758707225e-05\n",
      "7.684840238653123e-05\n",
      "5.88136535952799e-05\n",
      "7.375262066489086e-05\n",
      "5.5698696087347344e-05\n",
      "7.70971819292754e-05\n",
      "5.5497948778793216e-05\n",
      "8.939789404394105e-05\n",
      "6.827666948083788e-05\n",
      "5.817286000819877e-05\n",
      "7.291330257430673e-05\n",
      "5.835605043102987e-05\n",
      "6.298804510151967e-05\n",
      "6.323923298623413e-05\n",
      "7.317305426113307e-05\n",
      "6.15076714893803e-05\n",
      "6.874710379634053e-05\n",
      "7.127338176360354e-05\n",
      "7.779607403790578e-05\n",
      "6.294361082836986e-05\n",
      "6.380234844982624e-05\n",
      "7.742985326331109e-05\n",
      "7.758758874842897e-05\n",
      "5.831272937939502e-05\n",
      "6.619918713113293e-05\n",
      "9.918954310705885e-05\n",
      "7.008437387412414e-05\n",
      "5.8697718486655504e-05\n",
      "7.364471821347252e-05\n",
      "7.437699241563678e-05\n",
      "0.00010726084292400628\n",
      "6.887593917781487e-05\n",
      "7.576550706289709e-05\n",
      "6.13245356362313e-05\n",
      "6.760545511497185e-05\n",
      "7.869570981711149e-05\n",
      "9.101346950046718e-05\n",
      "0.0002991837100125849\n",
      "0.0004042332584504038\n",
      "0.00019704461738001555\n",
      "0.00012609684199560434\n",
      "0.00016553291061427444\n",
      "0.0001537462667329237\n",
      "0.0002451034670230001\n",
      "0.00016340504225809127\n",
      "8.885344868758693e-05\n",
      "0.00010414092685095966\n",
      "0.0001267123589059338\n",
      "0.00012088210496585816\n",
      "8.703433559276164e-05\n",
      "0.00015937723219394684\n",
      "0.00013389518426265568\n",
      "0.00011948103201575577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [1:17:12<03:01, 181.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14200367647058823\n",
      "验证集精度0.14375\n",
      "测试集精度0.13125\n",
      "0.00014213932445272803\n",
      "0.0001544508704682812\n",
      "0.0001329017395619303\n",
      "0.00015812860510777682\n",
      "0.00011836274643428624\n",
      "9.799891267903149e-05\n",
      "8.777437324170023e-05\n",
      "7.740601722616702e-05\n",
      "0.0001202407875098288\n",
      "6.980830221436918e-05\n",
      "0.0001570767053635791\n",
      "9.314985800301656e-05\n",
      "9.017797856358811e-05\n",
      "9.383007272845134e-05\n",
      "9.56834337557666e-05\n",
      "8.065919246291742e-05\n",
      "0.00011158169945701957\n",
      "7.805472705513239e-05\n",
      "8.136688848026097e-05\n",
      "6.784151628380641e-05\n",
      "8.455669012619182e-05\n",
      "0.00012454844545572996\n",
      "8.381906809518114e-05\n",
      "8.66916889208369e-05\n",
      "7.412892591673881e-05\n",
      "7.096332410583273e-05\n",
      "7.597958028782159e-05\n",
      "0.00010270931670675054\n",
      "7.993982580956072e-05\n",
      "7.93428989709355e-05\n",
      "7.943848322611302e-05\n",
      "7.058894698275253e-05\n",
      "7.440781337209046e-05\n",
      "0.00010084100358653814\n",
      "8.730931585887447e-05\n",
      "6.122510239947587e-05\n",
      "6.845136522315443e-05\n",
      "7.852890848880634e-05\n",
      "7.705299503868446e-05\n",
      "8.108437759801745e-05\n",
      "0.00011163877934450284\n",
      "8.626070484751835e-05\n",
      "8.209646330215037e-05\n",
      "0.00011663365876302123\n",
      "8.318547043018043e-05\n",
      "7.469307456631213e-05\n",
      "6.986463267821819e-05\n",
      "7.937883492559195e-05\n",
      "7.41004987503402e-05\n",
      "7.670238119317219e-05\n",
      "8.419489313382655e-05\n",
      "9.442951704841107e-05\n",
      "6.872722588013858e-05\n",
      "8.61209409777075e-05\n",
      "7.372846448561177e-05\n",
      "0.000128249273984693\n",
      "0.0001086528500309214\n",
      "0.00011562297731870785\n",
      "8.530095510650426e-05\n",
      "7.930018182378262e-05\n",
      "8.479451935272664e-05\n",
      "0.00012039007560815662\n",
      "8.843142131809145e-05\n",
      "8.335097663803026e-05\n",
      "9.042571036843583e-05\n",
      "0.0001046238248818554\n",
      "8.415160846197978e-05\n",
      "8.519137918483466e-05\n",
      "7.497772458009422e-05\n",
      "9.053773828782141e-05\n",
      "8.244810305768624e-05\n",
      "8.591281221015379e-05\n",
      "6.754234345862642e-05\n",
      "7.042298238957301e-05\n",
      "7.804371853126213e-05\n",
      "0.000123498379252851\n",
      "7.72442581364885e-05\n",
      "0.00011908575834240764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:21:00<00:00, 162.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度0.14866727941176472\n",
      "验证集精度0.1671875\n",
      "测试集精度0.1484375\n",
      "训练集最终精度0.21629901960784315\n",
      "验证集最终精度0.1921875\n",
      "测试集最终精度0.24375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''定义用zero-shot KD训练的student模型和损失函数和优化器'''\n",
    "\n",
    "print('*******************利用DI训练student model，加上student与teachermodel对DI的softmax输出KL散度做损失****************************')\n",
    "\n",
    "bert_student = Teachermodel(MyModel_Config(train_original_labels))\n",
    "student_revise = Studentmodel_revise(bert_student, 'cuda:0')\n",
    "teacher_revise = Teachermodel_revise(teacher_model, \"cuda:0\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_revise.parameters(), lr=1e-4)\n",
    "loss_func = nn.KLDivLoss()\n",
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy_train, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, train_original_datas, loss_func2)\n",
    "accuracy_dev, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, dev_original_datas, loss_func2)\n",
    "accuracy_test, _ = Model_Train_ipynb().eval_for_embeddingKD(teacher_model.bert.embeddings, student_revise, test_original_datas, loss_func2)\n",
    "print(accuracy_train)\n",
    "print(accuracy_dev)\n",
    "print(accuracy_test)\n",
    "\n",
    "train_KD_student(teacher_model.bert.embeddings, teacher_revise, student_revise, DIemb_datasets, optimizer, loss_func, loss_func2, 5, 30, train_original_datas, dev_original_datas, test_original_datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('csuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07ab6d371e845a933fefd78872ae9ed5c08b7429001c2088fe7b56efc961c495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
